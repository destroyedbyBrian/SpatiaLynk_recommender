{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dcfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "import json\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbeddings: \n",
    "\tdef __init__(self,\n",
    "\t\t\tusers_file: str,\n",
    "\t\t\tuser_poi_interactions_file: str,\n",
    "\t\t\tpoi_tree_file: str):\n",
    "\t\tself.users_df = pd.read_csv(users_file)\n",
    "\t\tself.interactions_df = pd.read_csv(user_poi_interactions_file)\n",
    "\t\twith open(poi_tree_file, 'r') as f:\n",
    "\t\t\tself.poi_tree = json.load(f)\n",
    "\n",
    "\t\tself.X_A = None\n",
    "\t\tself.X_T = None\n",
    "\t\tself.X = None \n",
    "\n",
    "\t\tself.age_encoder = None\n",
    "\t\tself.mlb_interests = None\n",
    "\t\tself.mlb_transport = None\n",
    "\t\tself.price_encoder = None\n",
    "\t\t\n",
    "\t\t# NMF components\n",
    "\t\tself.X_T_model = None\n",
    "\t\tself.X_T_scaler = None\n",
    "\t\tself.poi_to_idx = None\n",
    "\n",
    "\tdef build_X_A(self) -> np.ndarray:\n",
    "\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building X_A: Direct User Attribute Matrix\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\n",
    "\t\tfeatures_list = []\n",
    "\n",
    "\t\t# ===== AGE ======\n",
    "\t\tself.age_encoder = LabelEncoder()\n",
    "\t\tage_encoded = self.age_encoder.fit_transform(self.users_df['age_group'])\n",
    "\t\tage_onehot = np.eye(len(self.age_encoder.classes_))[age_encoded]\n",
    "\t\tfeatures_list.append(age_onehot)\n",
    "\t\tprint(f\"Age groups: {len(self.age_encoder.classes_)} dimensions\")\n",
    "\n",
    "\t\t# ===== INTEREST ======\n",
    "\t\tinterests_list = [[i.strip() for i in row.split(';')] for row in self.users_df['interests']]\n",
    "\t\tself.mlb_interests = MultiLabelBinarizer()\n",
    "\t\tinterests_onehot = self.mlb_interests.fit_transform(interests_list)\n",
    "\t\tfeatures_list.append(interests_onehot)\n",
    "\t\tprint(f\"Interests: {len(self.mlb_interests.classes_)} dimensions\")\n",
    "\n",
    "\t\t# ===== TRANSPORTATION MODE ======\n",
    "\t\ttransport_list = [[t.strip() for t in row.split(';')] for row in self.users_df['transportation_modes']]\n",
    "\t\tself.mlb_transport = MultiLabelBinarizer()\n",
    "\t\ttransport_onehot = self.mlb_transport.fit_transform(transport_list)\n",
    "\t\tfeatures_list.append(transport_onehot)\n",
    "\t\tprint(f\"Transport modes: {len(self.mlb_transport.classes_)} dimensions\")\n",
    "\t\t\n",
    "\t\t# ===== PRICE SENSITIVITY ======\n",
    "\t\tself.price_encoder = LabelEncoder()\n",
    "\t\tprice_encoded = self.price_encoder.fit_transform(self.users_df['price_sensitivity'])\n",
    "\t\tprice_onehot = np.eye(len(self.price_encoder.classes_))[price_encoded]\n",
    "\t\tfeatures_list.append(price_onehot)\n",
    "\t\tprint(f\"Price sensitivity: {len(self.price_encoder.classes_)} dimensions\")\n",
    "\n",
    "\t\tself.X_A = np.hstack(features_list)\n",
    "\t\tprint(f\"\\nX_A shape: {self.X_A.shape}\")\n",
    "\t\treturn self.X_A\n",
    "\t\n",
    "\tdef build_X_T(self, embedding_dim: int = 32) -> np.ndarray:\n",
    "\t\t\"\"\"Build matrix factorization embeddings from interactions...\"\"\"\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building X_T: Inverse User Attribute Matrix\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\t\n",
    "\t\tunique_users = self.users_df['uudi'].tolist()\n",
    "\t\tall_poi_ids = list(self.poi_tree['level_0'].keys())\n",
    "\t\t\n",
    "\t\tuser_to_idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "\t\tself.poi_to_idx = {pid: idx for idx, pid in enumerate(all_poi_ids)}\n",
    "\n",
    "\t\tn_users = len(unique_users)\n",
    "\t\tn_pois = len(all_poi_ids)\n",
    "\t\tprint(f\"Building interaction matrix: {n_users} users × {n_pois} POIs\")\n",
    "\n",
    "\t\t# Aggregate interactions\n",
    "\t\tuser_poi_scores = {}\n",
    "\t\tfor _, row in self.interactions_df.iterrows():\n",
    "\t\t\tuser_id = row['user_id']\n",
    "\t\t\tpoi_id = row['poi_id']\n",
    "\t\t\t\n",
    "\t\t\tif user_id not in user_to_idx or poi_id not in self.poi_to_idx:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tkey = (user_id, poi_id)\n",
    "\t\t\tif row['interaction_type'] == 'visit':\n",
    "\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 1.0\n",
    "\t\t\telif row['interaction_type'] == 'rating':\n",
    "\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + (row['value'] / 5.0)\n",
    "\t\t\telif row['interaction_type'] == 'search':\n",
    "\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 0.3\n",
    "\t\t\n",
    "\t\t# Build sparse matrix\n",
    "\t\trow_indices = [user_to_idx[u] for u, p in user_poi_scores.keys()]\n",
    "\t\tcol_indices = [self.poi_to_idx[p] for u, p in user_poi_scores.keys()]\n",
    "\t\tvalues = list(user_poi_scores.values())\n",
    "\t\t\n",
    "\t\tinteraction_matrix = csr_matrix(\n",
    "\t\t\t(values, (row_indices, col_indices)),\n",
    "\t\t\tshape=(n_users, n_pois)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tprint(f\"Matrix density: {interaction_matrix.nnz / (n_users * n_pois) * 100:.2f}%\")\n",
    "\t\t\n",
    "\t\t# NMF\n",
    "\t\tprint(f\"Performing NMF (dim={embedding_dim})...\")\n",
    "\t\tnmf = NMF(n_components=embedding_dim, init='random', random_state=42, max_iter=200)\n",
    "\t\tX_T = nmf.fit_transform(interaction_matrix)\n",
    "\t\t\n",
    "\t\t# Normalize and SAVE SCALER\n",
    "\t\tself.X_T_scaler = StandardScaler()\n",
    "\t\tX_T = self.X_T_scaler.fit_transform(X_T)\n",
    "\t\t\n",
    "\t\tprint(f\"X_T shape: {X_T.shape}\")\n",
    "\t\tprint(f\"Reconstruction error: {nmf.reconstruction_err_:.4f}\")\n",
    "\t\t\n",
    "\t\tself.X_T = X_T\n",
    "\t\tself.X_T_model = nmf\n",
    "\t\t\n",
    "\t\treturn X_T\n",
    "\t\n",
    "\tdef build_user_embeddings(self) -> np.ndarray:\n",
    "\t\t\"\"\"Concatenate X_A and X_T\"\"\"\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building Complete User Embeddings\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\t\n",
    "\t\tX_A = self.build_X_A()\n",
    "\t\tX_T = self.build_X_T(embedding_dim=32)\n",
    "\t\t\n",
    "\t\t# Concatenate and STORE\n",
    "\t\tself.X = np.hstack([X_A, X_T])\n",
    "\t\tprint(f\"\\nFinal embedding shape: {self.X.shape}\")\n",
    "\t\tprint(f\"  X_A: {X_A.shape[1]} dims | X_T: {X_T.shape[1]} dims\")\n",
    "\t\t\n",
    "\t\treturn self.X\n",
    "\t\n",
    "\tdef save_embeddings_csv(self, output_file: str = '../Sources/Files v3/user_embeddings.csv'):\n",
    "\t\tif self.X is None:\n",
    "\t\t\traise ValueError(\"Run build_user_embeddings() first\")\n",
    "\t\t\n",
    "\t\tdf = pd.DataFrame(\n",
    "\t\t\tself.X,\n",
    "\t\t\tindex=self.users_df['uudi'],\n",
    "\t\t\tcolumns=[f'dim_{i}' for i in range(self.X.shape[1])]\n",
    "\t\t)\n",
    "\t\tdf.to_csv(output_file)\n",
    "\t\tprint(f\"Saved embeddings CSV to {output_file}\")\n",
    "\n",
    "\tdef save_state(self, output_file: str = '../Sources/Embeddings v3/user_embeddings.pkl'):\n",
    "\t\t\"\"\"Save everything needed for inference (encoders, models, mappings)\"\"\"\n",
    "\t\tdata = {\n",
    "\t\t\t# Matrices\n",
    "\t\t\t'X_A': self.X_A,\n",
    "\t\t\t'X_T': self.X_T, \n",
    "\t\t\t'X': self.X,\n",
    "\t\t\t\n",
    "\t\t\t# Encoders for new users\n",
    "\t\t\t'age_encoder': self.age_encoder,\n",
    "\t\t\t'mlb_interests': self.mlb_interests,\n",
    "\t\t\t'mlb_transport': self.mlb_transport,\n",
    "\t\t\t'price_encoder': self.price_encoder,\n",
    "\t\t\t\n",
    "\t\t\t# NMF components \n",
    "\t\t\t'nmf_model': self.X_T_model,\n",
    "\t\t\t'X_T_scaler': self.X_T_scaler, \n",
    "\t\t\t'poi_to_idx': self.poi_to_idx,\n",
    "\t\t\t\n",
    "\t\t\t# Metadata\n",
    "\t\t\t'user_ids': self.users_df['uudi'].tolist()\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\twith open(output_file, 'wb') as f:  \n",
    "\t\t\tpickle.dump(data, f)\n",
    "\t\tprint(f\"Saved state to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Building Complete User Embeddings\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Building X_A: Direct User Attribute Matrix\n",
      "============================================================\n",
      "Age groups: 5 dimensions\n",
      "Interests: 25 dimensions\n",
      "Transport modes: 6 dimensions\n",
      "Price sensitivity: 3 dimensions\n",
      "\n",
      "X_A shape: (21, 39)\n",
      "\n",
      "============================================================\n",
      "Building X_T: Inverse User Attribute Matrix\n",
      "============================================================\n",
      "Building interaction matrix: 21 users × 4696 POIs\n",
      "Matrix density: 0.26%\n",
      "Performing NMF (dim=32)...\n",
      "X_T shape: (21, 32)\n",
      "Reconstruction error: 0.0033\n",
      "\n",
      "Final embedding shape: (21, 71)\n",
      "  X_A: 39 dims | X_T: 32 dims\n",
      "Saved embeddings CSV to ../Sources/Files/user_embeddings.csv\n",
      "Saved state to ../Sources/Embeddings v3/user_embedding_state.pkl\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\t\tuser_preferences_file = \"../Sources/Files/user_preferences.csv\"\n",
    "\t\tuser_poi_interactions_file = \"../Sources/Files/user_poi_interactions.csv\"\n",
    "\t\tpoi_tree_file = \"../Sources/Files/poi_tree_with_uuids.json\"\n",
    "\n",
    "\t\tlearner = UserEmbeddings(\n",
    "\t\t\tusers_file=user_preferences_file,\n",
    "\t\t\tuser_poi_interactions_file=user_poi_interactions_file,\n",
    "\t\t\tpoi_tree_file=poi_tree_file\n",
    "\t\t)\n",
    "\n",
    "\t\t# Build user embeddings\n",
    "\t\tlearner.build_user_embeddings()\n",
    "\t\t\n",
    "\t\t# Save embeddings\n",
    "\t\tlearner.save_embeddings_csv('../Sources/Embeddings v3 csv/user_embeddings.csv')\n",
    "\t\tlearner.save_state('../Sources/Embeddings v3/user_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd359d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bd321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
