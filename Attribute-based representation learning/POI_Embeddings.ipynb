{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab98201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer\n",
    "from typing import List, Dict, Tuple\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.decomposition import TruncatedSVD, NMF\n",
    "from scipy.sparse import csr_matrix\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class POIEmbeddings:\n",
    "\tdef __init__(self,\n",
    "\t\t\t\tusers_file: str,\n",
    "\t\t\t\tuser_poi_interactions_file: str,\n",
    "\t\t\t\tpoi_tree_file: str\n",
    "\t\t\t\t):\n",
    "\t\tself.users_df = pd.read_csv(users_file)\n",
    "\t\tself.interactions_df = pd.read_csv(user_poi_interactions_file)\n",
    "\n",
    "\t\twith open(poi_tree_file, 'r') as f:\n",
    "\t\t\tself.poi_tree = json.load(f)\n",
    "\t\n",
    "\t\tself.user_embeddings = {}\n",
    "\t\tself.poi_embeddings = {}\n",
    "\t\tself.encoders = {}\n",
    "\n",
    "\tdef build_Y_A_level(self, level: int) -> Tuple[np.ndarray, List[str], List[str]]:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild direct POI attribute matrix Y_A^l for level l\n",
    "\t\t\"\"\"\n",
    "\t\tprint(f\"\\n{'=' * 60}\")\n",
    "\t\tprint(f\"Building Y_A^{level}: Direct POI Attribute Matrix (Level {level})\")\n",
    "\t\tprint(f\"{'=' * 60}\")\n",
    "\t\t\n",
    "\t\tlevel_names = {0: 'Building', 1: 'Street', 2: 'District', 3: 'Region'}\n",
    "\t\tprint(f\"Granularity: {level_names.get(level, 'Unknown')}\")\n",
    "\t\t\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\tpois_at_level = self.poi_tree[level_key]\n",
    "\t\t\n",
    "\t\tpoi_ids = list(pois_at_level.keys())\n",
    "\t\tn_pois = len(poi_ids)\n",
    "\t\t\n",
    "\t\tprint(f\"Number of nodes at level {level}: {n_pois}\")\n",
    "\t\t\n",
    "\t\tfeatures_list = []\n",
    "\t\tfeature_names = []\n",
    "\t\t\n",
    "\t\t# Store encoders/scalers for later use (inference time)\n",
    "\t\tif level not in self.encoders:\n",
    "\t\t\tself.encoders[level] = {'Y_A': {}, 'Y_T': {}, 'users': {}}\n",
    "\t\telse:\n",
    "\t\t\t# Ensure sub-keys exist (in case level was partially initialized)\n",
    "\t\t\tself.encoders[level].setdefault('Y_A', {})\n",
    "\t\t\tself.encoders[level].setdefault('Y_T', {})\n",
    "\t\t\tself.encoders[level].setdefault('users', {})\n",
    "\t\t\n",
    "\t\t# ================================================================\n",
    "\t\t# COMMON FEATURES (All Levels): spatial, textual\n",
    "\t\t# ================================================================\n",
    "\t\t\n",
    "\t\t# 1. Spatial Features (lat, lon) - Available at ALL levels\n",
    "\t\tspatial_features = self._extract_spatial_features(pois_at_level, poi_ids)\n",
    "\t\tspatial_scaler = StandardScaler()\n",
    "\t\tspatial_normalized = spatial_scaler.fit_transform(spatial_features)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['spatial_scaler'] = spatial_scaler\n",
    "\t\tfeatures_list.append(spatial_normalized)\n",
    "\t\tfeature_names.extend(['spatial_lat_norm', 'spatial_lon_norm'])\n",
    "\t\tprint(f\"  [1] Spatial features: 2 dimensions (lat, lon normalized)\")\n",
    "\t\t\n",
    "\t\tif level == 0:\n",
    "\t\t\tself._build_level0_features(pois_at_level, poi_ids, features_list, feature_names, level)\n",
    "\t\telif level == 1:\n",
    "\t\t\tself._build_level1_features(pois_at_level, poi_ids, features_list, feature_names, level)\n",
    "\t\telif level == 2:\n",
    "\t\t\tself._build_level2_features(pois_at_level, poi_ids, features_list, feature_names, level)\n",
    "\t\telif level == 3:\n",
    "\t\t\tself._build_level3_features(pois_at_level, poi_ids, features_list, feature_names, level)\n",
    "\t\t\n",
    "\t\t# ================================================================\n",
    "\t\t# TEXTUAL FEATURES (All Levels) - TF-IDF\n",
    "\t\t# ================================================================\n",
    "\t\ttext_features, text_feature_names = self._extract_textual_features(\n",
    "\t\t\tpois_at_level, poi_ids, level\n",
    "\t\t)\n",
    "\t\tfeatures_list.append(text_features)\n",
    "\t\tfeature_names.extend(text_feature_names)\n",
    "\t\t\n",
    "\t\tY_A_level = np.hstack(features_list)\n",
    "\t\t\n",
    "\t\treturn Y_A_level, poi_ids, feature_names\n",
    "\n",
    "\n",
    "\tdef _extract_spatial_features(self, pois_at_level: Dict, poi_ids: List[str]) -> np.ndarray:\n",
    "\t\t\"\"\"Extract spatial (lat, lon) features from POI data\"\"\"\n",
    "\t\tspatial_features = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tspatial = poi_data['spatial']\n",
    "\t\t\t\n",
    "\t\t\t# Handle different representations\n",
    "\t\t\tif isinstance(spatial, str):\n",
    "\t\t\t\tspatial = eval(spatial)\n",
    "\t\t\telif isinstance(spatial, list):\n",
    "\t\t\t\tspatial = tuple(spatial)\n",
    "\t\t\t\n",
    "\t\t\tspatial_features.append([spatial[0], spatial[1]])  # (lat, lon)\n",
    "\t\t\n",
    "\t\treturn np.array(spatial_features, dtype=np.float32)\n",
    "\n",
    "\n",
    "\tdef _build_level0_features(self, pois_at_level: Dict, poi_ids: List[str],\n",
    "\t\t\t\t\t\t\tfeatures_list: List, feature_names: List, level: int):\n",
    "\t\t# Category (one-hot)\n",
    "\t\tcategories = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tcat = poi_data.get('data', {}).get('category', 'unknown')\n",
    "\t\t\tcategories.append(str(cat).lower().strip())\n",
    "\t\t\n",
    "\t\tcategory_encoder = LabelEncoder()\n",
    "\t\tcategory_encoded = category_encoder.fit_transform(categories)\n",
    "\t\tn_categories = len(category_encoder.classes_)\n",
    "\t\tcategory_onehot = np.eye(n_categories, dtype=np.float32)[category_encoded]\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['category_encoder'] = category_encoder\n",
    "\t\tfeatures_list.append(category_onehot)\n",
    "\t\tfeature_names.extend([f'category_{cls}' for cls in category_encoder.classes_])\n",
    "\t\tprint(f\"  [2] Category features: {n_categories} dimensions (one-hot)\")\n",
    "\t\t\n",
    "\t\t# 3. Price (normalized)\n",
    "\t\tprices = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tprice_str = poi_data.get('data', {}).get('price', None)\n",
    "\t\t\tavg_price = self._parse_price(price_str)\n",
    "\t\t\tprices.append(avg_price)\n",
    "\t\t\n",
    "\t\tprices = np.array(prices, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tprice_scaler = StandardScaler()\n",
    "\t\tprices_normalized = price_scaler.fit_transform(prices)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['price_scaler'] = price_scaler\n",
    "\t\tfeatures_list.append(prices_normalized)\n",
    "\t\tfeature_names.append('price_norm')\n",
    "\t\tprint(f\"  [3] Price feature: 1 dimension (normalized)\")\n",
    "\t\tprint(f\"      Range: [{prices.min():.2f}, {prices.max():.2f}], mean: {prices.mean():.2f}\")\n",
    "\t\t\n",
    "\t\t# 4. Popularity (normalized)\n",
    "\t\tpopularities = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tpop_val = poi_data.get('data', {}).get('popularity', 3.0)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tpopularity = float(pop_val)\n",
    "\t\t\texcept (ValueError, TypeError):\n",
    "\t\t\t\tpopularity = 3.0\n",
    "\t\t\tpopularities.append(popularity)\n",
    "\t\t\n",
    "\t\tpopularities = np.array(popularities, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tpopularity_scaler = StandardScaler()\n",
    "\t\tpopularities_normalized = popularity_scaler.fit_transform(popularities)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['popularity_scaler'] = popularity_scaler\n",
    "\t\tfeatures_list.append(popularities_normalized)\n",
    "\t\tfeature_names.append('popularity_norm')\n",
    "\t\tprint(f\"  [4] Popularity feature: 1 dimension (normalized)\")\n",
    "\t\t\n",
    "\t\t# 5. Characteristics (multi-hot)\n",
    "\t\tcharacteristics_list = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tchar_str = poi_data.get('data', {}).get('characteristic', \n",
    "\t\t\t\t\tpoi_data.get('data', {}).get('characteristics', ''))\n",
    "\t\t\ttags = self._parse_characteristics(char_str)\n",
    "\t\t\tcharacteristics_list.append(tags)\n",
    "\t\t\n",
    "\t\tmlb_chars = MultiLabelBinarizer()\n",
    "\t\tchars_multihot = mlb_chars.fit_transform(characteristics_list).astype(np.float32)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['characteristics_encoder'] = mlb_chars\n",
    "\t\tfeatures_list.append(chars_multihot)\n",
    "\t\tfeature_names.extend([f'char_{cls}' for cls in mlb_chars.classes_])\n",
    "\t\tprint(f\"  [5] Characteristics features: {len(mlb_chars.classes_)} dimensions (multi-hot)\")\n",
    "\n",
    "\n",
    "\tdef _build_level1_features(self, pois_at_level: Dict, poi_ids: List[str],\n",
    "\t\t\t\t\t\t\tfeatures_list: List, feature_names: List, level: int):\n",
    "\t\t# Category (one-hot)\n",
    "\t\tcategories = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tcat = poi_data.get('data', {}).get('category', 'mixed')\n",
    "\t\t\tcategories.append(str(cat).lower().strip())\n",
    "\t\t\n",
    "\t\tcategory_encoder = LabelEncoder()\n",
    "\t\tcategory_encoded = category_encoder.fit_transform(categories)\n",
    "\t\tn_categories = len(category_encoder.classes_)\n",
    "\t\tcategory_onehot = np.eye(n_categories, dtype=np.float32)[category_encoded]\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['category_encoder'] = category_encoder\n",
    "\t\tfeatures_list.append(category_onehot)\n",
    "\t\tfeature_names.extend([f'category_{cls}' for cls in category_encoder.classes_])\n",
    "\t\tprint(f\"  [2] Category features: {n_categories} dimensions (one-hot)\")\n",
    "\t\t\n",
    "\t\t# Number of entities (normalized)\n",
    "\t\tnum_entities = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tcount = poi_data.get('data', {}).get('num_entities', 1)\n",
    "\t\t\ttry:\n",
    "\t\t\t\tcount = int(count)\n",
    "\t\t\texcept (ValueError, TypeError):\n",
    "\t\t\t\tcount = 1\n",
    "\t\t\tnum_entities.append(count)\n",
    "\t\t\n",
    "\t\tnum_entities = np.array(num_entities, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tentities_scaler = StandardScaler()\n",
    "\t\tentities_normalized = entities_scaler.fit_transform(num_entities)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['num_entities_scaler'] = entities_scaler\n",
    "\t\tfeatures_list.append(entities_normalized)\n",
    "\t\tfeature_names.append('num_entities_norm')\n",
    "\t\tprint(f\"  [3] Num entities feature: 1 dimension (normalized)\")\n",
    "\n",
    "\n",
    "\tdef _build_level2_features(self, pois_at_level: Dict, poi_ids: List[str],\n",
    "\t\t\t\t\t\t\tfeatures_list: List, feature_names: List, level: int):\n",
    "\t\tnum_streets = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tcount = poi_data.get('data', {}).get('num_level1_nodes', \n",
    "\t\t\t\t\tpoi_data.get('data', {}).get('num_streets', 1))\n",
    "\t\t\ttry:\n",
    "\t\t\t\tcount = int(count)\n",
    "\t\t\texcept (ValueError, TypeError):\n",
    "\t\t\t\tcount = 1\n",
    "\t\t\tnum_streets.append(count)\n",
    "\t\t\n",
    "\t\tnum_streets = np.array(num_streets, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tstreets_scaler = StandardScaler()\n",
    "\t\tstreets_normalized = streets_scaler.fit_transform(num_streets)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['num_level1_nodes_scaler'] = streets_scaler\n",
    "\t\tfeatures_list.append(streets_normalized)\n",
    "\t\tfeature_names.append('num_level1_nodes_norm')\n",
    "\t\tprint(f\"  [2] Num streets (level1 nodes) feature: 1 dimension (normalized)\")\n",
    "\n",
    "\n",
    "\tdef _build_level3_features(self, pois_at_level: Dict, poi_ids: List[str],\n",
    "\t\t\t\t\t\t\tfeatures_list: List, feature_names: List, level: int):\n",
    "\t\tnum_districts = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\tcount = poi_data.get('data', {}).get('num_districts', \n",
    "\t\t\t\t\tpoi_data.get('data', {}).get('num_level2_nodes', 1))\n",
    "\t\t\ttry:\n",
    "\t\t\t\tcount = int(count)\n",
    "\t\t\texcept (ValueError, TypeError):\n",
    "\t\t\t\tcount = 1\n",
    "\t\t\tnum_districts.append(count)\n",
    "\t\t\n",
    "\t\tnum_districts = np.array(num_districts, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tdistricts_scaler = StandardScaler()\n",
    "\t\tdistricts_normalized = districts_scaler.fit_transform(num_districts)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['num_districts_scaler'] = districts_scaler\n",
    "\t\tfeatures_list.append(districts_normalized)\n",
    "\t\tfeature_names.append('num_districts_norm')\n",
    "\t\tprint(f\"  [2] Num districts feature: 1 dimension (normalized)\")\n",
    "\n",
    "\tdef _extract_textual_features(self, pois_at_level: Dict, poi_ids: List[str],\n",
    "\t\t\t\t\t\t\t\tlevel: int) -> Tuple[np.ndarray, List[str]]:\n",
    "\t\ttexts = []\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tpoi_data = pois_at_level[poi_id]\n",
    "\t\t\ttext = poi_data.get('textual', '')\n",
    "\t\t\tif text is None:\n",
    "\t\t\t\ttext = ''\n",
    "\t\t\ttexts.append(str(text).lower())\n",
    "\t\t\n",
    "\t\tmax_text_features = {0: 100, 1: 75, 2: 50, 3: 30}.get(level, 50)\n",
    "\t\t\n",
    "\t\ttfidf_vectorizer = TfidfVectorizer(\n",
    "\t\t\tmax_features=max_text_features,\n",
    "\t\t\tstop_words='english',\n",
    "\t\t\tngram_range=(1, 2),\n",
    "\t\t\tmin_df=2,\n",
    "\t\t\tmax_df=0.95\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\ttext_features = tfidf_vectorizer.fit_transform(texts).toarray().astype(np.float32)\n",
    "\t\t\tfeature_names = [f'text_{word}' for word in tfidf_vectorizer.get_feature_names_out()]\n",
    "\t\t\tactual_features = text_features.shape[1]\n",
    "\t\texcept ValueError:\n",
    "\t\t\tprint(f\"      Warning: TF-IDF vocabulary empty, using zero features\")\n",
    "\t\t\ttext_features = np.zeros((len(poi_ids), 1), dtype=np.float32)\n",
    "\t\t\tfeature_names = ['text_empty']\n",
    "\t\t\tactual_features = 1\n",
    "\t\t\ttfidf_vectorizer = None\n",
    "\t\t\n",
    "\t\tself.encoders[level]['Y_A']['tfidf_vectorizer'] = tfidf_vectorizer\n",
    "\t\tprint(f\"  [T] Textual features: {actual_features} dimensions (TF-IDF)\")\n",
    "\t\t\n",
    "\t\treturn text_features, feature_names\n",
    "\n",
    "\tdef _parse_price(self, price_str) -> float:\n",
    "\t\t\"\"\"\n",
    "\t\tParse price string to float value\n",
    "\t\t\n",
    "\t\tHandles formats:\n",
    "\t\t- \"25.99\" -> 25.99\n",
    "\t\t- \"25.85 - 30.99\" -> 28.42 (average)\n",
    "\t\t- None/empty -> 25.0 (default)\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tprice_str: Price string from POI data\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tFloat price value\n",
    "\t\t\"\"\"\n",
    "\t\tif price_str is None or price_str == '' or pd.isna(price_str):\n",
    "\t\t\treturn 25.0  # Default mid-range price\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tprice_str = str(price_str).strip()\n",
    "\t\t\t\n",
    "\t\t\t# Handle range format \"25.85 - 30.99\"\n",
    "\t\t\tif '-' in price_str:\n",
    "\t\t\t\tparts = price_str.split('-')\n",
    "\t\t\t\tif len(parts) == 2:\n",
    "\t\t\t\t\tlow = float(parts[0].strip())\n",
    "\t\t\t\t\thigh = float(parts[1].strip())\n",
    "\t\t\t\t\treturn (low + high) / 2\n",
    "\t\t\t\n",
    "\t\t\t# Single value\n",
    "\t\t\treturn float(price_str)\n",
    "\t\t\n",
    "\t\texcept (ValueError, TypeError):\n",
    "\t\t\treturn 25.0  # Default on parse error\n",
    "\n",
    "\tdef _parse_characteristics(self, char_str) -> List[str]:\n",
    "\t\t\"\"\"\n",
    "\t\tParse characteristics string to list of tags\n",
    "\t\t\n",
    "\t\tHandles formats:\n",
    "\t\t- \"#food, #restaurant, #local\" -> ['food', 'restaurant', 'local']\n",
    "\t\t- \"food; restaurant; local\" -> ['food', 'restaurant', 'local']\n",
    "\t\t- Empty/None -> []\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tchar_str: Characteristics string from POI data\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tList of cleaned tag strings\n",
    "\t\t\"\"\"\n",
    "\t\tif char_str is None or char_str == '' or pd.isna(char_str):\n",
    "\t\t\treturn []\n",
    "\t\t\n",
    "\t\tchar_str = str(char_str)\n",
    "\t\t\n",
    "\t\t# Handle different separators\n",
    "\t\tif ',' in char_str:\n",
    "\t\t\tparts = char_str.split(',')\n",
    "\t\telif ';' in char_str:\n",
    "\t\t\tparts = char_str.split(';')\n",
    "\t\telse:\n",
    "\t\t\tparts = [char_str]\n",
    "\t\t\n",
    "\t\t# Clean each tag\n",
    "\t\ttags = []\n",
    "\t\tfor part in parts:\n",
    "\t\t\t# Remove hashtags, whitespace, and normalize\n",
    "\t\t\ttag = part.strip().replace('#', '').lower()\n",
    "\t\t\t# Remove empty tags and very short ones\n",
    "\t\t\tif tag and len(tag) > 1:\n",
    "\t\t\t\ttags.append(tag)\n",
    "\t\t\n",
    "\t\treturn tags\n",
    "\t\n",
    "\tdef build_Y_T_level(self, level: int, embedding_dim: int = 32) -> Tuple[np.ndarray, List[str]]:\n",
    "\t\tprint(f\"\\n{'='*60}\")\n",
    "\t\tprint(f\"Building Y_T^{level}: Inverse/Derived POI Attribute Matrix (Level {level})\")\n",
    "\t\tprint(f\"{'='*60}\")\n",
    "\n",
    "\t\tlevel_names = {0: 'Building', 1: 'Street', 2: 'District', 3: 'Region'}\n",
    "\t\tprint(f\"Granularity: {level_names.get(level, 'Unknown')}\")\n",
    "\t\t\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\tpois_at_level = self.poi_tree[level_key]\n",
    "\t\tpoi_ids = list(pois_at_level.keys())\n",
    "\t\t\n",
    "\t\tn_pois = len(poi_ids)\n",
    "\t\tn_users = len(self.users_df)\n",
    "\t\t\n",
    "\t\tprint(f\"Number of POIs at level {level}: {n_pois}\")\n",
    "\t\tprint(f\"Number of users: {n_users}\")\n",
    "\t\t\n",
    "\t\t# Create index mappings\n",
    "\t\tpoi_to_idx = {pid: idx for idx, pid in enumerate(poi_ids)}\n",
    "\t\tuser_id_col = 'uuid' if 'uuid' in self.users_df.columns else 'uudi'\n",
    "\t\tuser_to_idx = {uid: idx for idx, uid in enumerate(self.users_df[user_id_col])}\n",
    "\t\t\n",
    "\t\t# Ensure encoder structure exists\n",
    "\t\tif level not in self.encoders:\n",
    "\t\t\tself.encoders[level] = {'Y_A': {}, 'Y_T': {}, 'users': {}}\n",
    "\t\telse:\n",
    "\t\t\tself.encoders[level].setdefault('Y_A', {})\n",
    "\t\t\tself.encoders[level].setdefault('Y_T', {})\n",
    "\t\t\tself.encoders[level].setdefault('users', {})\n",
    "\t\t\n",
    "\t\t# Step 1: Build User Preference Features (stores in level['users'])\n",
    "\t\tprint(f\"\\n  [Step 1] Building user preference features...\")\n",
    "\t\tuser_pref_features, user_pref_names = self._build_user_preference_features(level)\n",
    "\t\tprint(f\"    User preference matrix shape: {user_pref_features.shape}\")\n",
    "\t\t\n",
    "\t\t# Step 2: Build Interaction Matrix\n",
    "\t\tprint(f\"\\n  [Step 2] Building POI-User interaction matrix...\")\n",
    "\t\tinteraction_matrix, interaction_stats = self._build_poi_user_interaction_matrix(\n",
    "\t\t\tpoi_ids, poi_to_idx, user_to_idx, level\n",
    "\t\t)\n",
    "\t\tprint(f\"    Interaction matrix shape: {interaction_matrix.shape}\")\n",
    "\t\tprint(f\"    Density: {interaction_stats['density']:.2f}%\")\n",
    "\t\t\n",
    "\t\t# Step 3: Derive Features...\n",
    "\t\tprint(f\"\\n  [Step 3] Deriving POI features from user preferences...\")\n",
    "\t\tderived_features = []\n",
    "\t\t\n",
    "\t\t# 3a. Aggregated preferences\n",
    "\t\tpoi_user_pref_agg = self._aggregate_user_preferences_to_pois(\n",
    "\t\t\tinteraction_matrix, user_pref_features, user_pref_names\n",
    "\t\t)\n",
    "\t\tderived_features.append(poi_user_pref_agg['features'])\n",
    "\t\t\n",
    "\t\t# 3b. Diversity features\n",
    "\t\tdiversity_features = self._compute_user_diversity_features(\n",
    "\t\t\tinteraction_matrix, user_pref_features\n",
    "\t\t)\n",
    "\t\tderived_features.append(diversity_features['features'])\n",
    "\t\t\n",
    "\t\t# 3c. Pattern features\n",
    "\t\tpattern_features = self._compute_interaction_pattern_features(\n",
    "\t\t\tpoi_ids, poi_to_idx, level\n",
    "\t\t)\n",
    "\t\tderived_features.append(pattern_features['features'])\n",
    "\t\t\n",
    "\t\tprint(f\"    Aggregated user preferences: {poi_user_pref_agg['features'].shape[1]} dims\")\n",
    "\t\tprint(f\"    User diversity features: {diversity_features['features'].shape[1]} dims\")\n",
    "\t\tprint(f\"    Interaction pattern features: {pattern_features['features'].shape[1]} dims\")\n",
    "\t\t\n",
    "\t\t# Step 4: Latent embeddings via NMF\n",
    "\t\tprint(f\"\\n  [Step 4] Computing latent embeddings via NMF...\")\n",
    "\t\tlatent_result = self._compute_latent_embeddings(\n",
    "\t\t\tinteraction_matrix, embedding_dim\n",
    "\t\t)\n",
    "\t\tderived_features.append(latent_result['features'])\n",
    "\t\tprint(f\"    Latent embeddings: {latent_result['features'].shape[1]} dims\")\n",
    "\t\tprint(f\"    Reconstruction error: {latent_result['reconstruction_error']:.4f}\")\n",
    "\t\t\n",
    "\t\t# Store NMF model in Y_T\n",
    "\t\tif 'nmf_model' in latent_result:\n",
    "\t\t\tself.encoders[level]['Y_T']['nmf_model'] = latent_result['nmf_model']\n",
    "\t\t\n",
    "\t\t# Step 5: Concatenate and normalize\n",
    "\t\tY_T_level = np.hstack(derived_features)\n",
    "\t\t\n",
    "\t\tfinal_scaler = StandardScaler()\n",
    "\t\tY_T_level = final_scaler.fit_transform(Y_T_level)\n",
    "\t\t\n",
    "\t\t# FIXED: Store in Y_T sub-dictionary\n",
    "\t\tself.encoders[level]['Y_T']['scaler'] = final_scaler\n",
    "\t\tself.encoders[level]['Y_T']['poi_to_idx'] = poi_to_idx\n",
    "\t\tself.encoders[level]['Y_T']['user_to_idx'] = user_to_idx\n",
    "\n",
    "\t\treturn Y_T_level, poi_ids\n",
    "\n",
    "\n",
    "\tdef _build_user_preference_features(self, level: int) -> Tuple[np.ndarray, List[str]]:\n",
    "\t\tfeatures_list = []\n",
    "\t\tfeature_names = []\n",
    "\t\t\n",
    "\t\tuser_id_col = 'uuid' if 'uuid' in self.users_df.columns else 'uudi'\n",
    "\t\tn_users = len(self.users_df)\n",
    "\t\t\n",
    "\t\t# 1. Interests (multi-hot encoding)\n",
    "\t\tinterests_list = []\n",
    "\t\tfor _, row in self.users_df.iterrows():\n",
    "\t\t\tinterests_str = row.get('interests', '')\n",
    "\t\t\tif pd.isna(interests_str) or interests_str == '':\n",
    "\t\t\t\tinterests = []\n",
    "\t\t\telse:\n",
    "\t\t\t\tinterests = [i.strip().lower() for i in str(interests_str).split(';')]\n",
    "\t\t\tinterests_list.append(interests)\n",
    "\t\t\n",
    "\t\tmlb_interests = MultiLabelBinarizer()\n",
    "\t\tinterests_encoded = mlb_interests.fit_transform(interests_list).astype(np.float32)\n",
    "\t\t\n",
    "\t\tself.encoders[level]['users']['interests_encoder'] = mlb_interests\n",
    "\t\tfeatures_list.append(interests_encoded)\n",
    "\t\tfeature_names.extend([f'interest_{cls}' for cls in mlb_interests.classes_])\n",
    "\t\t\n",
    "\t\t# 2. Age group (one-hot encoding)\n",
    "\t\tage_groups = self.users_df['age_group'].fillna('unknown').astype(str).str.lower().tolist()\n",
    "\t\tage_encoder = LabelEncoder()\n",
    "\t\tage_encoded = age_encoder.fit_transform(age_groups)\n",
    "\t\tage_onehot = np.eye(len(age_encoder.classes_), dtype=np.float32)[age_encoded]\n",
    "\t\t\n",
    "\t\tself.encoders[level]['users']['age_encoder'] = age_encoder\n",
    "\t\tfeatures_list.append(age_onehot)\n",
    "\t\tfeature_names.extend([f'age_{cls}' for cls in age_encoder.classes_])\n",
    "\t\t\n",
    "\t\t# 3. Price sensitivity (one-hot encoding)\n",
    "\t\tprice_sens = self.users_df['price_sensitivity'].fillna('medium').astype(str).str.lower().tolist()\n",
    "\t\tprice_encoder = LabelEncoder()\n",
    "\t\tprice_encoded = price_encoder.fit_transform(price_sens)\n",
    "\t\tprice_onehot = np.eye(len(price_encoder.classes_), dtype=np.float32)[price_encoded]\n",
    "\t\t\n",
    "\t\tself.encoders[level]['users']['price_encoder'] = price_encoder\n",
    "\t\tfeatures_list.append(price_onehot)\n",
    "\t\tfeature_names.extend([f'price_sens_{cls}' for cls in price_encoder.classes_])\n",
    "\t\t\n",
    "\t\tuser_features = np.hstack(features_list)\n",
    "\t\t\n",
    "\t\treturn user_features, feature_names\n",
    "\n",
    "\tdef _build_poi_user_interaction_matrix(\n",
    "\t\tself, \n",
    "\t\tpoi_ids: List[str], \n",
    "\t\tpoi_to_idx: Dict[str, int],\n",
    "\t\tuser_to_idx: Dict[str, int],\n",
    "\t\tlevel: int\n",
    "\t) -> Tuple[csr_matrix, Dict]:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild POI-User interaction matrix with weighted interaction scores\n",
    "\t\t\n",
    "\t\tFor level > 0, maps fine-grained POI IDs to parent nodes at target level\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tpoi_ids: List of POI IDs at current level\n",
    "\t\t\tpoi_to_idx: POI ID to index mapping\n",
    "\t\t\tuser_to_idx: User ID to index mapping\n",
    "\t\t\tlevel: Current tree level\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tinteraction_matrix: Sparse (n_pois, n_users) matrix\n",
    "\t\t\tstats: Dictionary with statistics\n",
    "\t\t\"\"\"\n",
    "\t\tn_pois = len(poi_ids)\n",
    "\t\tn_users = len(user_to_idx)\n",
    "\t\t\n",
    "\t\t# Aggregate interaction scores\n",
    "\t\tpoi_user_scores = {}\n",
    "\t\t\n",
    "\t\t# Interaction type weights\n",
    "\t\tinteraction_weights = {\n",
    "\t\t\t'visit': 1.0,\n",
    "\t\t\t'rating': 0.8,  # Will be scaled by rating value\n",
    "\t\t\t'search': 0.3,\n",
    "\t\t\t'click': 0.2,\n",
    "\t\t\t'bookmark': 0.5\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\ttotal_interactions = 0\n",
    "\t\t\n",
    "\t\tfor _, row in self.interactions_df.iterrows():\n",
    "\t\t\tuser_id = row['user_id']\n",
    "\t\t\tpoi_id = row['poi_id']\n",
    "\t\t\t\n",
    "\t\t\t# For higher levels, map fine-grained POI to parent at target level\n",
    "\t\t\tif level > 0:\n",
    "\t\t\t\tmapped_poi_id = self._get_parent_at_level(poi_id, target_level=level)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmapped_poi_id = poi_id\n",
    "\t\t\t\n",
    "\t\t\t# Skip if POI or user not in our index\n",
    "\t\t\tif mapped_poi_id not in poi_to_idx or user_id not in user_to_idx:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tkey = (mapped_poi_id, user_id)\n",
    "\t\t\tinteraction_type = row.get('interaction_type', 'visit')\n",
    "\t\t\t\n",
    "\t\t\t# Calculate weighted score\n",
    "\t\t\tbase_weight = interaction_weights.get(interaction_type, 0.5)\n",
    "\t\t\t\n",
    "\t\t\tif interaction_type == 'rating':\n",
    "\t\t\t\t# Scale by rating value (1-5 -> 0.2-1.0)\n",
    "\t\t\t\trating_value = row.get('value', 3)\n",
    "\t\t\t\tscore = base_weight * (rating_value / 5.0)\n",
    "\t\t\telse:\n",
    "\t\t\t\tscore = base_weight * row.get('value', 1)\n",
    "\t\t\t\n",
    "\t\t\tpoi_user_scores[key] = poi_user_scores.get(key, 0) + score\n",
    "\t\t\ttotal_interactions += 1\n",
    "\t\t\n",
    "\t\t# Build sparse matrix\n",
    "\t\trow_indices = []\n",
    "\t\tcol_indices = []\n",
    "\t\tvalues = []\n",
    "\t\t\n",
    "\t\tfor (poi_id, user_id), score in poi_user_scores.items():\n",
    "\t\t\trow_indices.append(poi_to_idx[poi_id])\n",
    "\t\t\tcol_indices.append(user_to_idx[user_id])\n",
    "\t\t\tvalues.append(score)\n",
    "\t\t\n",
    "\t\tinteraction_matrix = csr_matrix(\n",
    "\t\t\t(values, (row_indices, col_indices)),\n",
    "\t\t\tshape=(n_pois, n_users),\n",
    "\t\t\tdtype=np.float32\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tdensity = interaction_matrix.nnz / (n_pois * n_users) * 100 if n_pois * n_users > 0 else 0\n",
    "\t\t\n",
    "\t\tstats = {\n",
    "\t\t\t'density': density,\n",
    "\t\t\t'total_interactions': total_interactions,\n",
    "\t\t\t'nnz': interaction_matrix.nnz,\n",
    "\t\t\t'unique_poi_user_pairs': len(poi_user_scores)\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\treturn interaction_matrix, stats\n",
    "\n",
    "\n",
    "\tdef _aggregate_user_preferences_to_pois(\n",
    "\t\tself,\n",
    "\t\tinteraction_matrix: csr_matrix,\n",
    "\t\tuser_pref_features: np.ndarray,\n",
    "\t\tuser_pref_names: List[str]\n",
    "\t) -> Dict:\n",
    "\t\t\"\"\"\n",
    "\t\tAggregate user preferences to POIs weighted by interaction strength\n",
    "\t\t\n",
    "\t\tFor each POI, compute weighted average of user preferences based on\n",
    "\t\tinteraction scores.\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tinteraction_matrix: (n_pois, n_users) sparse matrix\n",
    "\t\t\tuser_pref_features: (n_users, n_user_features) matrix\n",
    "\t\t\tuser_pref_names: List of user feature names\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary with 'features' and 'names'\n",
    "\t\t\"\"\"\n",
    "\t\tn_pois = interaction_matrix.shape[0]\n",
    "\t\tn_user_features = user_pref_features.shape[1]\n",
    "\t\t\n",
    "\t\t# Weighted aggregation: POI_features = (interaction_matrix @ user_features) / sum(weights)\n",
    "\t\tweighted_sum = interaction_matrix.dot(user_pref_features)\n",
    "\t\t\n",
    "\t\t# Compute sum of weights per POI for normalization\n",
    "\t\tweight_sums = np.array(interaction_matrix.sum(axis=1)).flatten()\n",
    "\t\tweight_sums[weight_sums == 0] = 1.0  # Avoid division by zero\n",
    "\t\t\n",
    "\t\t# Normalize\n",
    "\t\taggregated_features = weighted_sum / weight_sums.reshape(-1, 1)\n",
    "\t\t\n",
    "\t\t# Handle POIs with no interactions (fill with global average)\n",
    "\t\tno_interaction_mask = np.array(interaction_matrix.sum(axis=1)).flatten() == 0\n",
    "\t\tif no_interaction_mask.any():\n",
    "\t\t\tglobal_avg = user_pref_features.mean(axis=0)\n",
    "\t\t\taggregated_features[no_interaction_mask] = global_avg\n",
    "\t\t\n",
    "\t\t# Rename features\n",
    "\t\taggregated_names = [f'agg_user_{name}' for name in user_pref_names]\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t'features': aggregated_features.astype(np.float32),\n",
    "\t\t\t'names': aggregated_names\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\tdef _compute_user_diversity_features(\n",
    "\t\tself,\n",
    "\t\tinteraction_matrix: csr_matrix,\n",
    "\t\tuser_pref_features: np.ndarray\n",
    "\t) -> Dict:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute user diversity features for each POI\n",
    "\t\t\n",
    "\t\tMeasures how diverse the users visiting each POI are in terms of their preferences.\n",
    "\t\tHigher diversity = POI appeals to broader audience.\n",
    "\t\t\n",
    "\t\tFeatures:\n",
    "\t\t- user_count: Number of unique users\n",
    "\t\t- user_entropy: Entropy of user distribution\n",
    "\t\t- pref_variance: Variance in user preferences\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary with 'features' and 'names'\n",
    "\t\t\"\"\"\n",
    "\t\tn_pois = interaction_matrix.shape[0]\n",
    "\t\t\n",
    "\t\tdiversity_features = []\n",
    "\t\t\n",
    "\t\t# 1. User count (normalized)\n",
    "\t\tuser_counts = np.array(interaction_matrix.getnnz(axis=1)).reshape(-1, 1).astype(np.float32)\n",
    "\t\tdiversity_features.append(user_counts)\n",
    "\t\t\n",
    "\t\t# 2. Interaction strength variance\n",
    "\t\tinteraction_variance = []\n",
    "\t\tfor i in range(n_pois):\n",
    "\t\t\trow = interaction_matrix.getrow(i).toarray().flatten()\n",
    "\t\t\tnonzero_values = row[row > 0]\n",
    "\t\t\tif len(nonzero_values) > 1:\n",
    "\t\t\t\tvariance = np.var(nonzero_values)\n",
    "\t\t\telse:\n",
    "\t\t\t\tvariance = 0.0\n",
    "\t\t\tinteraction_variance.append(variance)\n",
    "\t\tinteraction_variance = np.array(interaction_variance, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tdiversity_features.append(interaction_variance)\n",
    "\t\t\n",
    "\t\t# 3. User preference diversity (mean pairwise distance of users)\n",
    "\t\tpref_diversity = []\n",
    "\t\tfor i in range(n_pois):\n",
    "\t\t\trow = interaction_matrix.getrow(i)\n",
    "\t\t\tuser_indices = row.indices\n",
    "\t\t\t\n",
    "\t\t\tif len(user_indices) > 1:\n",
    "\t\t\t\t# Get preferences of users who interacted with this POI\n",
    "\t\t\t\tpoi_user_prefs = user_pref_features[user_indices]\n",
    "\t\t\t\t# Compute mean pairwise cosine distance\n",
    "\t\t\t\tif poi_user_prefs.shape[0] > 1:\n",
    "\t\t\t\t\tnorms = np.linalg.norm(poi_user_prefs, axis=1, keepdims=True)\n",
    "\t\t\t\t\tnorms[norms == 0] = 1.0\n",
    "\t\t\t\t\tnormalized_prefs = poi_user_prefs / norms\n",
    "\t\t\t\t\tsimilarity_matrix = normalized_prefs @ normalized_prefs.T\n",
    "\t\t\t\t\t# Mean off-diagonal similarity\n",
    "\t\t\t\t\tn = similarity_matrix.shape[0]\n",
    "\t\t\t\t\tmean_similarity = (similarity_matrix.sum() - n) / (n * (n - 1)) if n > 1 else 1.0\n",
    "\t\t\t\t\tdiversity = 1.0 - mean_similarity  # Convert to diversity\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdiversity = 0.0\n",
    "\t\t\telse:\n",
    "\t\t\t\tdiversity = 0.0\n",
    "\t\t\t\n",
    "\t\t\tpref_diversity.append(diversity)\n",
    "\t\t\n",
    "\t\tpref_diversity = np.array(pref_diversity, dtype=np.float32).reshape(-1, 1)\n",
    "\t\tdiversity_features.append(pref_diversity)\n",
    "\t\t\n",
    "\t\t# Concatenate\n",
    "\t\tall_diversity = np.hstack(diversity_features)\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t'features': all_diversity,\n",
    "\t\t\t'names': ['user_count', 'interaction_variance', 'user_pref_diversity']\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\tdef _compute_interaction_pattern_features(\n",
    "\t\tself,\n",
    "\t\tpoi_ids: List[str],\n",
    "\t\tpoi_to_idx: Dict[str, int],\n",
    "\t\tlevel: int\n",
    "\t) -> Dict:\n",
    "\t\t\"\"\"\n",
    "\t\tCompute interaction pattern features for each POI\n",
    "\t\t\n",
    "\t\tFeatures:\n",
    "\t\t- visit_ratio: Ratio of visits vs other interaction types\n",
    "\t\t- avg_rating: Average rating received\n",
    "\t\t- search_to_visit_ratio: Conversion rate from search to visit\n",
    "\t\t- repeat_visitor_ratio: Ratio of users with multiple visits\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary with 'features' and 'names'\n",
    "\t\t\"\"\"\n",
    "\t\tn_pois = len(poi_ids)\n",
    "\t\t\n",
    "\t\t# Initialize accumulators\n",
    "\t\tpoi_stats = {pid: {\n",
    "\t\t\t'visits': 0,\n",
    "\t\t\t'ratings': [],\n",
    "\t\t\t'searches': 0,\n",
    "\t\t\t'total': 0,\n",
    "\t\t\t'user_visits': {}  # user_id -> visit count\n",
    "\t\t} for pid in poi_ids}\n",
    "\t\t\n",
    "\t\tfor _, row in self.interactions_df.iterrows():\n",
    "\t\t\tpoi_id = row['poi_id']\n",
    "\t\t\tuser_id = row['user_id']\n",
    "\t\t\t\n",
    "\t\t\t# Map to parent level if needed\n",
    "\t\t\tif level > 0:\n",
    "\t\t\t\tpoi_id = self._get_parent_at_level(poi_id, target_level=level)\n",
    "\t\t\t\n",
    "\t\t\tif poi_id not in poi_stats:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tstats = poi_stats[poi_id]\n",
    "\t\t\tstats['total'] += 1\n",
    "\t\t\t\n",
    "\t\t\tinteraction_type = row.get('interaction_type', 'visit')\n",
    "\t\t\t\n",
    "\t\t\tif interaction_type == 'visit':\n",
    "\t\t\t\tstats['visits'] += 1\n",
    "\t\t\t\tstats['user_visits'][user_id] = stats['user_visits'].get(user_id, 0) + 1\n",
    "\t\t\telif interaction_type == 'rating':\n",
    "\t\t\t\tstats['ratings'].append(row.get('value', 3))\n",
    "\t\t\telif interaction_type == 'search':\n",
    "\t\t\t\tstats['searches'] += 1\n",
    "\t\t\n",
    "\t\t# Compute features\n",
    "\t\tvisit_ratios = []\n",
    "\t\tavg_ratings = []\n",
    "\t\tsearch_to_visit_ratios = []\n",
    "\t\trepeat_visitor_ratios = []\n",
    "\t\t\n",
    "\t\tfor poi_id in poi_ids:\n",
    "\t\t\tstats = poi_stats[poi_id]\n",
    "\t\t\t\n",
    "\t\t\t# Visit ratio\n",
    "\t\t\tvisit_ratio = stats['visits'] / stats['total'] if stats['total'] > 0 else 0.5\n",
    "\t\t\tvisit_ratios.append(visit_ratio)\n",
    "\t\t\t\n",
    "\t\t\t# Average rating\n",
    "\t\t\tavg_rating = np.mean(stats['ratings']) if stats['ratings'] else 3.0\n",
    "\t\t\tavg_ratings.append(avg_rating)\n",
    "\t\t\t\n",
    "\t\t\t# Search to visit ratio (conversion)\n",
    "\t\t\tif stats['searches'] > 0:\n",
    "\t\t\t\ts2v_ratio = min(stats['visits'] / stats['searches'], 2.0)  # Cap at 2\n",
    "\t\t\telse:\n",
    "\t\t\t\ts2v_ratio = 1.0\n",
    "\t\t\tsearch_to_visit_ratios.append(s2v_ratio)\n",
    "\t\t\t\n",
    "\t\t\t# Repeat visitor ratio\n",
    "\t\t\tif stats['user_visits']:\n",
    "\t\t\t\trepeat_count = sum(1 for v in stats['user_visits'].values() if v > 1)\n",
    "\t\t\t\trepeat_ratio = repeat_count / len(stats['user_visits'])\n",
    "\t\t\telse:\n",
    "\t\t\t\trepeat_ratio = 0.0\n",
    "\t\t\trepeat_visitor_ratios.append(repeat_ratio)\n",
    "\t\t\n",
    "\t\t# Stack features\n",
    "\t\tpattern_features = np.column_stack([\n",
    "\t\t\tvisit_ratios,\n",
    "\t\t\tavg_ratings,\n",
    "\t\t\tsearch_to_visit_ratios,\n",
    "\t\t\trepeat_visitor_ratios\n",
    "\t\t]).astype(np.float32)\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t'features': pattern_features,\n",
    "\t\t\t'names': ['visit_ratio', 'avg_rating', 'search_to_visit_ratio', 'repeat_visitor_ratio']\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\tdef _compute_latent_embeddings(self, interaction_matrix: csr_matrix, embedding_dim: int) -> Dict:\n",
    "\t\tif interaction_matrix.nnz == 0:\n",
    "\t\t\tn_pois = interaction_matrix.shape[0]\n",
    "\t\t\treturn {\n",
    "\t\t\t\t'features': np.zeros((n_pois, embedding_dim), dtype=np.float32),\n",
    "\t\t\t\t'names': [f'latent_{i}' for i in range(embedding_dim)],\n",
    "\t\t\t\t'reconstruction_error': 0.0,\n",
    "\t\t\t\t'nmf_model': None\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\tinteraction_dense = interaction_matrix.toarray()\n",
    "\t\tinteraction_dense = np.maximum(interaction_dense, 0)\n",
    "\t\t\n",
    "\t\tactual_dim = min(embedding_dim, min(interaction_dense.shape) - 1)\n",
    "\t\tactual_dim = max(actual_dim, 1)\n",
    "\t\t\n",
    "\t\tnmf = NMF(\n",
    "\t\t\tn_components=actual_dim,\n",
    "\t\t\tinit='nndsvda',\n",
    "\t\t\trandom_state=42,\n",
    "\t\t\tmax_iter=300,\n",
    "\t\t\tl1_ratio=0.5,\n",
    "\t\t\talpha_W=0.1,\n",
    "\t\t\talpha_H=0.1\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\ttry:\n",
    "\t\t\tlatent_features = nmf.fit_transform(interaction_dense)\n",
    "\t\t\treconstruction_error = nmf.reconstruction_err_\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tprint(f\"    Warning: NMF failed ({e}), using SVD fallback\")\n",
    "\t\t\tfrom sklearn.decomposition import TruncatedSVD\n",
    "\t\t\tsvd = TruncatedSVD(n_components=actual_dim, random_state=42)\n",
    "\t\t\tlatent_features = svd.fit_transform(interaction_matrix)\n",
    "\t\t\tlatent_features = np.maximum(latent_features, 0)\n",
    "\t\t\treconstruction_error = 0.0\n",
    "\t\t\tnmf = None  # No NMF model to store\n",
    "\t\t\n",
    "\t\tif actual_dim < embedding_dim:\n",
    "\t\t\tpadding = np.zeros((latent_features.shape[0], embedding_dim - actual_dim), dtype=np.float32)\n",
    "\t\t\tlatent_features = np.hstack([latent_features, padding])\n",
    "\t\t\n",
    "\t\treturn {\n",
    "\t\t\t'features': latent_features.astype(np.float32),\n",
    "\t\t\t'names': [f'latent_{i}' for i in range(embedding_dim)],\n",
    "\t\t\t'reconstruction_error': reconstruction_error,\n",
    "\t\t\t'nmf_model': nmf  # Return the model for storage\n",
    "\t\t}\n",
    "\n",
    "\n",
    "\tdef _get_parent_at_level(self, poi_id: str, target_level: int) -> str:\n",
    "\t\t\"\"\"\n",
    "\t\tGet parent node of poi_id at target_level\n",
    "\t\t\n",
    "\t\tTraverses the POI tree from level 0 upward until reaching target_level.\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tpoi_id: POI ID at level 0\n",
    "\t\t\ttarget_level: Target level to find parent at\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tParent POI ID at target_level, or original poi_id if not found\n",
    "\t\t\"\"\"\n",
    "\t\tif target_level == 0:\n",
    "\t\t\treturn poi_id\n",
    "\t\t\n",
    "\t\tcurrent_level = 0\n",
    "\t\tcurrent_id = poi_id\n",
    "\t\t\n",
    "\t\twhile current_level < target_level:\n",
    "\t\t\tlevel_key = f'level_{current_level}'\n",
    "\t\t\t\n",
    "\t\t\tif level_key not in self.poi_tree:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\tif current_id not in self.poi_tree[level_key]:\n",
    "\t\t\t\tbreak\n",
    "\t\t\t\n",
    "\t\t\tparent = self.poi_tree[level_key][current_id].get('parent')\n",
    "\t\t\t\n",
    "\t\t\tif parent:\n",
    "\t\t\t\tcurrent_id = parent\n",
    "\t\t\t\tcurrent_level += 1\n",
    "\t\t\telse:\n",
    "\t\t\t\t# No parent found, return current\n",
    "\t\t\t\tbreak\n",
    "\t\t\n",
    "\t\treturn current_id\n",
    "\n",
    "\tdef build_poi_embeddings(self, levels: List[int] = [0, 1, 2, 3]):\n",
    "\t\tprint(\"\\n\" + \"=\" * 60)\n",
    "\t\tprint(\"Building Complete POI Embeddings (All Levels)\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\tlevel_names = {0: 'Building', 1: 'Street', 2: 'District', 3: 'Region'}\n",
    "\t\t\n",
    "\t\tfor level in levels:\n",
    "\t\t\tprint(f\"\\n{'#' * 60}\")\n",
    "\t\t\tprint(f\"### Processing Level {level}: {level_names.get(level, 'Unknown')} ###\")\n",
    "\t\t\tprint(f\"{'#' * 60}\")\n",
    "\t\t\t\n",
    "\t\t\t# Build explicit POI attributes (Y_A)\n",
    "\t\t\tY_A_l, poi_ids_A, Y_A_feature_names = self.build_Y_A_level(level)\n",
    "\t\t\t\n",
    "\t\t\t# Build derived POI attributes (Y_T)\n",
    "\t\t\tY_T_l, poi_ids_T = self.build_Y_T_level(level, embedding_dim=32)\n",
    "\t\t\t\n",
    "\t\t\t# Verify POI ID consistency\n",
    "\t\t\tif poi_ids_A != poi_ids_T:\n",
    "\t\t\t\tprint(f\"  Warning: POI ID mismatch between Y_A and Y_T at level {level}\")\n",
    "\t\t\t\tprint(f\"    Y_A POIs: {len(poi_ids_A)}, Y_T POIs: {len(poi_ids_T)}\")\n",
    "\t\t\t\t# Use Y_A poi_ids as reference (from poi_tree)\n",
    "\t\t\t\tpoi_ids = poi_ids_A\n",
    "\t\t\telse:\n",
    "\t\t\t\tpoi_ids = poi_ids_A\n",
    "\t\t\t\n",
    "\t\t\t# Generate Y_T feature names\n",
    "\t\t\tY_T_feature_names = self._get_Y_T_feature_names(Y_T_l.shape[1])\n",
    "\t\t\t\n",
    "\t\t\t# Concatenate Y_A and Y_T to form complete embedding\n",
    "\t\t\tY_l = np.hstack([Y_A_l, Y_T_l])\n",
    "\t\t\t\n",
    "\t\t\t# Combined feature names\n",
    "\t\t\tall_feature_names = Y_A_feature_names + Y_T_feature_names\n",
    "\t\t\t\n",
    "\t\t\t# Print summary\n",
    "\t\t\tprint(f\"\\n{'=' * 60}\")\n",
    "\t\t\tprint(f\"Final POI Embedding Summary - Level {level} ({level_names.get(level, 'Unknown')})\")\n",
    "\t\t\tprint(f\"{'=' * 60}\")\n",
    "\t\t\tprint(f\"  Number of POIs: {len(poi_ids)}\")\n",
    "\t\t\tprint(f\"  Y_A^{level} (Explicit) dimensions: {Y_A_l.shape[1]}\")\n",
    "\t\t\tprint(f\"  Y_T^{level} (Derived) dimensions: {Y_T_l.shape[1]}\")\n",
    "\t\t\tprint(f\"  Total embedding dimensions: {Y_l.shape[1]}\")\n",
    "\t\t\tprint(f\"  Final shape: {Y_l.shape}\")\n",
    "\t\t\t\n",
    "\t\t\t# Store embeddings with all metadata\n",
    "\t\t\tself.poi_embeddings[f'level_{level}'] = {\n",
    "\t\t\t\t'embeddings': Y_l,\n",
    "\t\t\t\t'poi_ids': poi_ids,\n",
    "\t\t\t\t'Y_A': Y_A_l,\n",
    "\t\t\t\t'Y_T': Y_T_l,\n",
    "\t\t\t\t'Y_A_feature_names': Y_A_feature_names,\n",
    "\t\t\t\t'Y_T_feature_names': Y_T_feature_names,\n",
    "\t\t\t\t'all_feature_names': all_feature_names,\n",
    "\t\t\t\t'n_explicit_features': Y_A_l.shape[1],\n",
    "\t\t\t\t'n_derived_features': Y_T_l.shape[1],\n",
    "\t\t\t\t'level_name': level_names.get(level, 'Unknown')\n",
    "\t\t\t}\n",
    "\n",
    "\tdef _get_Y_T_feature_names(self, n_features: int) -> List[str]:\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tGenerate feature names for Y_T matrix based on the build_Y_T_level structure\n",
    "\t\t\t\n",
    "\t\t\tArgs:\n",
    "\t\t\t\t\tn_features: Total number of Y_T features\n",
    "\t\t\t\n",
    "\t\t\tReturns:\n",
    "\t\t\t\t\tList of feature names\n",
    "\t\t\t\"\"\"\n",
    "\t\t\tfeature_names = []\n",
    "\t\t\t\n",
    "\t\t\t# Get user preference feature names if available\n",
    "\t\t\tif 'user_interests_encoder' in self.encoders:\n",
    "\t\t\t\t\tinterest_classes = self.encoders['user_interests_encoder'].classes_\n",
    "\t\t\t\t\tfeature_names.extend([f'agg_user_interest_{cls}' for cls in interest_classes])\n",
    "\t\t\t\n",
    "\t\t\tif 'user_age_encoder' in self.encoders:\n",
    "\t\t\t\t\tage_classes = self.encoders['user_age_encoder'].classes_\n",
    "\t\t\t\t\tfeature_names.extend([f'agg_user_age_{cls}' for cls in age_classes])\n",
    "\t\t\t\n",
    "\t\t\tif 'user_price_encoder' in self.encoders:\n",
    "\t\t\t\t\tprice_classes = self.encoders['user_price_encoder'].classes_\n",
    "\t\t\t\t\tfeature_names.extend([f'agg_user_price_sens_{cls}' for cls in price_classes])\n",
    "\t\t\t\n",
    "\t\t\t# Diversity features\n",
    "\t\t\tfeature_names.extend(['user_count', 'interaction_variance', 'user_pref_diversity'])\n",
    "\t\t\t\n",
    "\t\t\t# Interaction pattern features\n",
    "\t\t\tfeature_names.extend(['visit_ratio', 'avg_rating', 'search_to_visit_ratio', 'repeat_visitor_ratio'])\n",
    "\t\t\t\n",
    "\t\t\t# Latent features (fill remaining)\n",
    "\t\t\tcurrent_count = len(feature_names)\n",
    "\t\t\tlatent_count = n_features - current_count\n",
    "\t\t\tif latent_count > 0:\n",
    "\t\t\t\t\tfeature_names.extend([f'latent_{i}' for i in range(latent_count)])\n",
    "\t\t\t\n",
    "\t\t\t# Truncate if we have too many names\n",
    "\t\t\treturn feature_names[:n_features]\n",
    "\t\n",
    "\tdef save_embeddings_csv(self, output_dir: str = '../Sources/Embeddings v3 csv/poi_embeddings_csv'):\n",
    "\t\t\n",
    "\t\tos.makedirs(output_dir, exist_ok=True)\n",
    "\t\t\n",
    "\t\tprint(f\"\\n{'='*60}\")\n",
    "\t\tprint(f\"Saving POI Embeddings to CSV (Human-Readable)\")\n",
    "\t\tprint(f\"{'='*60}\")\n",
    "\t\tprint(f\"Output directory: {output_dir}\\n\")\n",
    "\t\t\n",
    "\t\tfor level_key, level_data in self.poi_embeddings.items():\n",
    "\t\t\tembeddings = level_data['embeddings']      # 2D numpy: (n_pois, n_features)\n",
    "\t\t\tpoi_ids = level_data['poi_ids']            # List of UUIDs\n",
    "\t\t\tfeature_names = level_data.get('all_feature_names', [])\n",
    "\t\t\tY_A_count = level_data['n_explicit_features']\n",
    "\t\t\tY_T_count = level_data['n_derived_features']\n",
    "\t\t\t\n",
    "\t\t\tif feature_names and len(feature_names) == embeddings.shape[1]:\n",
    "\t\t\t\tcolumns = feature_names\n",
    "\t\t\telse:\n",
    "\t\t\t\tcolumns = [f'dim_{i}' for i in range(embeddings.shape[1])]\n",
    "\t\t\t\n",
    "\t\t\tdf = pd.DataFrame(embeddings, index=poi_ids, columns=columns)\n",
    "\t\t\t\n",
    "\t\t\t# Insert metadata columns at front\n",
    "\t\t\tdf.insert(0, 'level', level_key)\n",
    "\t\t\tdf.insert(1, 'Y_A_split_idx', Y_A_count) \n",
    "\t\t\tdf.insert(2, 'total_dims', embeddings.shape[1])\n",
    "\t\t\t\n",
    "\t\t\tfilename = os.path.join(output_dir, f'poi_embeddings_{level_key}.csv')\n",
    "\t\t\tdf.to_csv(filename, index=True, index_label='poi_id')\n",
    "\t\t\t\n",
    "\t\t\tsplit_manifest = {\n",
    "\t\t\t\t'level': level_key,\n",
    "\t\t\t\t'level_name': level_data['level_name'],\n",
    "\t\t\t\t'n_pois': len(poi_ids),\n",
    "\t\t\t\t'dimensions': {\n",
    "\t\t\t\t\t'total': embeddings.shape[1],\n",
    "\t\t\t\t\t'Y_A_explicit': Y_A_count,\n",
    "\t\t\t\t\t'Y_T_derived': Y_T_count\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'column_indices': {\n",
    "\t\t\t\t\t'Y_A_range': [0, Y_A_count - 1],\n",
    "\t\t\t\t\t'Y_T_range': [Y_A_count, embeddings.shape[1] - 1]\n",
    "\t\t\t\t},\n",
    "\t\t\t\t'example_pois': poi_ids[:3]  # First 3 POIs for verification\n",
    "\t\t\t}\n",
    "\t\t\t\n",
    "\t\t\tmanifest_file = os.path.join(output_dir, f'{level_key}_manifest.json')\n",
    "\t\t\twith open(manifest_file, 'w') as f:\n",
    "\t\t\t\tjson.dump(split_manifest, f, indent=2)\n",
    "\t\t\t\n",
    "\t\t\tfile_size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "\t\t\tprint(f\"  {level_key}: {embeddings.shape} â†’ {filename} ({file_size_mb:.2f} MB)\")\n",
    "\t\t\n",
    "\t\tprint(f\"\\nCSV export complete!\")\n",
    "\t\t\n",
    "\tdef save_embeddings(self, output_file: str = '../Sources/Embeddings v3/poi_embeddings.pkl'):\n",
    "\t\tprint(f\"\\nSaving embeddings to: {output_file}\")\n",
    "\t\t\n",
    "\t\t# Build embedding dimensions dict separately to avoid variable shadowing\n",
    "\t\tembedding_dims = {}\n",
    "\t\tfor level_key, level_data in self.poi_embeddings.items():\n",
    "\t\t\t\tembedding_dims[level_key] = {\n",
    "\t\t\t\t\t\t'total': level_data['embeddings'].shape[1],\n",
    "\t\t\t\t\t\t'explicit': level_data['n_explicit_features'],\n",
    "\t\t\t\t\t\t'derived': level_data['n_derived_features']\n",
    "\t\t\t\t}\n",
    "\t\t\n",
    "\t\t# Build POI ID to index mappings\n",
    "\t\tpoi_id_to_idx = {}\n",
    "\t\tfor level_key, level_data in self.poi_embeddings.items():\n",
    "\t\t\t\tpoi_id_to_idx[level_key] = {\n",
    "\t\t\t\t\t\tpid: idx for idx, pid in enumerate(level_data['poi_ids'])\n",
    "\t\t\t\t}\n",
    "\t\t\n",
    "\t\t# Build feature name mappings\n",
    "\t\tfeature_names_map = {}\n",
    "\t\tfor level_key, level_data in self.poi_embeddings.items():\n",
    "\t\t\t\tfeature_names_map[level_key] = {\n",
    "\t\t\t\t\t\t'all': level_data['all_feature_names'],\n",
    "\t\t\t\t\t\t'explicit': level_data['Y_A_feature_names'],\n",
    "\t\t\t\t\t\t'derived': level_data['Y_T_feature_names']\n",
    "\t\t\t\t}\n",
    "\t\t\n",
    "\t\tsave_data = {\n",
    "\t\t\t\t# POI embeddings for all levels\n",
    "\t\t\t\t'poi_embeddings': self.poi_embeddings,\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Encoders and scalers for inference\n",
    "\t\t\t\t'encoders': self.encoders,\n",
    "\t\t\t\t\n",
    "\t\t\t\t# POI tree structure (for parent lookups during inference)\n",
    "\t\t\t\t'poi_tree': self.poi_tree,\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Metadata\n",
    "\t\t\t\t'metadata': {\n",
    "\t\t\t\t\t\t'levels': list(self.poi_embeddings.keys()),\n",
    "\t\t\t\t\t\t'n_users': len(self.users_df),\n",
    "\t\t\t\t\t\t'n_interactions': len(self.interactions_df),\n",
    "\t\t\t\t\t\t'created_at': pd.Timestamp.now().isoformat(),\n",
    "\t\t\t\t\t\t'embedding_dimensions': embedding_dims\n",
    "\t\t\t\t},\n",
    "\t\t\t\t\n",
    "\t\t\t\t# POI ID to index mappings for fast lookup\n",
    "\t\t\t\t'poi_id_to_idx': poi_id_to_idx,\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Feature name mappings\n",
    "\t\t\t\t'feature_names': feature_names_map\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\twith open(output_file, 'wb') as f:\n",
    "\t\t\t\tpickle.dump(save_data, f)\n",
    "\t\n",
    "\t\t# Print save summary\n",
    "\t\tfile_size = os.path.getsize(output_file) / (1024 * 1024)  # MB\n",
    "\t\tprint(f\"  File size: {file_size:.2f} MB\")\n",
    "\t\tprint(f\"  Levels saved: {list(self.poi_embeddings.keys())}\")\n",
    "\t\tprint(f\"  Encoders saved: {list(self.encoders.keys())}\")\n",
    "\t\tprint(\"  Save complete!\")\n",
    "\n",
    "\n",
    "\tdef load_embeddings(self, input_file: str = '../Sources/Embeddings v3/poi_embeddings.pkl'):\n",
    "\t\tprint(f\"\\nLoading embeddings from: {input_file}\")\n",
    "\t\t\n",
    "\t\twith open(input_file, 'rb') as f:\n",
    "\t\t\tdata = pickle.load(f)\n",
    "\t\t\n",
    "\t\tself.poi_embeddings = data['poi_embeddings']\n",
    "\t\tself.encoders = data['encoders']\n",
    "\t\tself.poi_tree = data['poi_tree']\n",
    "\t\t\n",
    "\t\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08a0c745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Building Complete POI Embeddings (All Levels)\n",
      "============================================================\n",
      "\n",
      "############################################################\n",
      "### Processing Level 0: Building ###\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Building Y_A^0: Direct POI Attribute Matrix (Level 0)\n",
      "============================================================\n",
      "Granularity: Building\n",
      "Number of nodes at level 0: 4696\n",
      "  [1] Spatial features: 2 dimensions (lat, lon normalized)\n",
      "  [2] Category features: 23 dimensions (one-hot)\n",
      "  [3] Price feature: 1 dimension (normalized)\n",
      "      Range: [4.20, 57.15], mean: 29.99\n",
      "  [4] Popularity feature: 1 dimension (normalized)\n",
      "  [5] Characteristics features: 22 dimensions (multi-hot)\n",
      "  [T] Textual features: 100 dimensions (TF-IDF)\n",
      "\n",
      "============================================================\n",
      "Building Y_T^0: Inverse/Derived POI Attribute Matrix (Level 0)\n",
      "============================================================\n",
      "Granularity: Building\n",
      "Number of POIs at level 0: 4696\n",
      "Number of users: 21\n",
      "\n",
      "  [Step 1] Building user preference features...\n",
      "    User preference matrix shape: (21, 33)\n",
      "\n",
      "  [Step 2] Building POI-User interaction matrix...\n",
      "    Interaction matrix shape: (4696, 21)\n",
      "    Density: 0.26%\n",
      "\n",
      "  [Step 3] Deriving POI features from user preferences...\n",
      "    Aggregated user preferences: 33 dims\n",
      "    User diversity features: 3 dims\n",
      "    Interaction pattern features: 4 dims\n",
      "\n",
      "  [Step 4] Computing latent embeddings via NMF...\n",
      "    Latent embeddings: 32 dims\n",
      "    Reconstruction error: 25.3527\n",
      "\n",
      "============================================================\n",
      "Final POI Embedding Summary - Level 0 (Building)\n",
      "============================================================\n",
      "  Number of POIs: 4696\n",
      "  Y_A^0 (Explicit) dimensions: 149\n",
      "  Y_T^0 (Derived) dimensions: 72\n",
      "  Total embedding dimensions: 221\n",
      "  Final shape: (4696, 221)\n",
      "\n",
      "############################################################\n",
      "### Processing Level 1: Street ###\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Building Y_A^1: Direct POI Attribute Matrix (Level 1)\n",
      "============================================================\n",
      "Granularity: Street\n",
      "Number of nodes at level 1: 1355\n",
      "  [1] Spatial features: 2 dimensions (lat, lon normalized)\n",
      "  [2] Category features: 21 dimensions (one-hot)\n",
      "  [3] Num entities feature: 1 dimension (normalized)\n",
      "  [T] Textual features: 75 dimensions (TF-IDF)\n",
      "\n",
      "============================================================\n",
      "Building Y_T^1: Inverse/Derived POI Attribute Matrix (Level 1)\n",
      "============================================================\n",
      "Granularity: Street\n",
      "Number of POIs at level 1: 1355\n",
      "Number of users: 21\n",
      "\n",
      "  [Step 1] Building user preference features...\n",
      "    User preference matrix shape: (21, 33)\n",
      "\n",
      "  [Step 2] Building POI-User interaction matrix...\n",
      "    Interaction matrix shape: (1355, 21)\n",
      "    Density: 0.81%\n",
      "\n",
      "  [Step 3] Deriving POI features from user preferences...\n",
      "    Aggregated user preferences: 33 dims\n",
      "    User diversity features: 3 dims\n",
      "    Interaction pattern features: 4 dims\n",
      "\n",
      "  [Step 4] Computing latent embeddings via NMF...\n",
      "    Latent embeddings: 32 dims\n",
      "    Reconstruction error: 30.9852\n",
      "\n",
      "============================================================\n",
      "Final POI Embedding Summary - Level 1 (Street)\n",
      "============================================================\n",
      "  Number of POIs: 1355\n",
      "  Y_A^1 (Explicit) dimensions: 99\n",
      "  Y_T^1 (Derived) dimensions: 72\n",
      "  Total embedding dimensions: 171\n",
      "  Final shape: (1355, 171)\n",
      "\n",
      "############################################################\n",
      "### Processing Level 2: District ###\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Building Y_A^2: Direct POI Attribute Matrix (Level 2)\n",
      "============================================================\n",
      "Granularity: District\n",
      "Number of nodes at level 2: 44\n",
      "  [1] Spatial features: 2 dimensions (lat, lon normalized)\n",
      "  [2] Num streets (level1 nodes) feature: 1 dimension (normalized)\n",
      "  [T] Textual features: 50 dimensions (TF-IDF)\n",
      "\n",
      "============================================================\n",
      "Building Y_T^2: Inverse/Derived POI Attribute Matrix (Level 2)\n",
      "============================================================\n",
      "Granularity: District\n",
      "Number of POIs at level 2: 44\n",
      "Number of users: 21\n",
      "\n",
      "  [Step 1] Building user preference features...\n",
      "    User preference matrix shape: (21, 33)\n",
      "\n",
      "  [Step 2] Building POI-User interaction matrix...\n",
      "    Interaction matrix shape: (44, 21)\n",
      "    Density: 19.48%\n",
      "\n",
      "  [Step 3] Deriving POI features from user preferences...\n",
      "    Aggregated user preferences: 33 dims\n",
      "    User diversity features: 3 dims\n",
      "    Interaction pattern features: 4 dims\n",
      "\n",
      "  [Step 4] Computing latent embeddings via NMF...\n",
      "    Latent embeddings: 32 dims\n",
      "    Reconstruction error: 16.0701\n",
      "\n",
      "============================================================\n",
      "Final POI Embedding Summary - Level 2 (District)\n",
      "============================================================\n",
      "  Number of POIs: 44\n",
      "  Y_A^2 (Explicit) dimensions: 53\n",
      "  Y_T^2 (Derived) dimensions: 72\n",
      "  Total embedding dimensions: 125\n",
      "  Final shape: (44, 125)\n",
      "\n",
      "############################################################\n",
      "### Processing Level 3: Region ###\n",
      "############################################################\n",
      "\n",
      "============================================================\n",
      "Building Y_A^3: Direct POI Attribute Matrix (Level 3)\n",
      "============================================================\n",
      "Granularity: Region\n",
      "Number of nodes at level 3: 5\n",
      "  [1] Spatial features: 2 dimensions (lat, lon normalized)\n",
      "  [2] Num districts feature: 1 dimension (normalized)\n",
      "  [T] Textual features: 30 dimensions (TF-IDF)\n",
      "\n",
      "============================================================\n",
      "Building Y_T^3: Inverse/Derived POI Attribute Matrix (Level 3)\n",
      "============================================================\n",
      "Granularity: Region\n",
      "Number of POIs at level 3: 5\n",
      "Number of users: 21\n",
      "\n",
      "  [Step 1] Building user preference features...\n",
      "    User preference matrix shape: (21, 33)\n",
      "\n",
      "  [Step 2] Building POI-User interaction matrix...\n",
      "    Interaction matrix shape: (5, 21)\n",
      "    Density: 67.62%\n",
      "\n",
      "  [Step 3] Deriving POI features from user preferences...\n",
      "    Aggregated user preferences: 33 dims\n",
      "    User diversity features: 3 dims\n",
      "    Interaction pattern features: 4 dims\n",
      "\n",
      "  [Step 4] Computing latent embeddings via NMF...\n",
      "    Latent embeddings: 32 dims\n",
      "    Reconstruction error: 6.4334\n",
      "\n",
      "============================================================\n",
      "Final POI Embedding Summary - Level 3 (Region)\n",
      "============================================================\n",
      "  Number of POIs: 5\n",
      "  Y_A^3 (Explicit) dimensions: 33\n",
      "  Y_T^3 (Derived) dimensions: 72\n",
      "  Total embedding dimensions: 105\n",
      "  Final shape: (5, 105)\n",
      "\n",
      "Saving embeddings to: ../Sources/Embeddings v3/poi_embeddings.pkl\n",
      "  File size: 13.07 MB\n",
      "  Levels saved: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Encoders saved: [0, 1, 2, 3]\n",
      "  Save complete!\n",
      "\n",
      "============================================================\n",
      "Saving POI Embeddings to CSV (Human-Readable)\n",
      "============================================================\n",
      "Output directory: ../Sources/Embeddings v3 csv/poi_embeddings.csv\n",
      "\n",
      "  level_0: (4696, 221) â†’ ../Sources/Embeddings v3 csv/poi_embeddings.csv\\poi_embeddings_level_0.csv (6.01 MB)\n",
      "  level_1: (1355, 171) â†’ ../Sources/Embeddings v3 csv/poi_embeddings.csv\\poi_embeddings_level_1.csv (1.52 MB)\n",
      "  level_2: (44, 125) â†’ ../Sources/Embeddings v3 csv/poi_embeddings.csv\\poi_embeddings_level_2.csv (0.05 MB)\n",
      "  level_3: (5, 105) â†’ ../Sources/Embeddings v3 csv/poi_embeddings.csv\\poi_embeddings_level_3.csv (0.01 MB)\n",
      "\n",
      "CSV export complete!\n",
      "\n",
      "Loading embeddings from: ../Sources/Embeddings v3/poi_embeddings.pkl\n",
      "\n",
      "Embedding dimensions per level:\n",
      "  level_0: 221 total (149 explicit + 72 derived)\n",
      "  level_1: 171 total (99 explicit + 72 derived)\n",
      "  level_2: 125 total (53 explicit + 72 derived)\n",
      "  level_3: 105 total (33 explicit + 72 derived)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tuser_preferences_file = \"../Sources/Files/user_preferences.csv\"\n",
    "\tuser_poi_interactions_file = \"../Sources/Files/user_poi_interactions.csv\"\n",
    "\tpoi_tree_file = \"../Sources/Files/poi_tree_with_uuids.json\"\n",
    "\t\n",
    "\toutput_file = \"../Sources/Embeddings v3/poi_embeddings.pkl\"\n",
    "\toutput_file_csv = \"../Sources/Embeddings v3 csv/poi_embeddings.csv\"\n",
    "\n",
    "\t# Initialize embedding generator\n",
    "\tlearner = POIEmbeddings(\n",
    "\t\tusers_file=user_preferences_file,\n",
    "\t\tuser_poi_interactions_file=user_poi_interactions_file,\n",
    "\t\tpoi_tree_file=poi_tree_file\n",
    "\t)\n",
    "\t\n",
    "\t# Build embeddings for all levels\n",
    "\tlearner.build_poi_embeddings(levels=[0, 1, 2, 3])\n",
    "\t\n",
    "\t# Save embeddings\n",
    "\tlearner.save_embeddings(output_file)\n",
    "\tlearner.save_embeddings_csv(output_file_csv)\n",
    "\t\n",
    "\tloaded_data = learner.load_embeddings(output_file)\n",
    "\t\n",
    "\tprint(\"\\nEmbedding dimensions per level:\")\n",
    "\tfor level_key, dims in loaded_data['metadata']['embedding_dimensions'].items():\n",
    "\t\tprint(f\"  {level_key}: {dims['total']} total ({dims['explicit']} explicit + {dims['derived']} derived)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c48cbe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
