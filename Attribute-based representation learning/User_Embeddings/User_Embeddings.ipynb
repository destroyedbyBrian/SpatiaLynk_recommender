{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b9dcfff3",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
        "from sklearn.decomposition import NMF, TruncatedSVD\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "import json\n",
        "from scipy.sparse import csr_matrix\n",
        "import pickle\n",
        "from typing import Optional, List\n",
        "from pathlib import Path\n",
        "\n",
        "# Dim for temporal / interaction-based embedding block (X_T)\n",
        "FINAL_EMBEDDING_DIM = 32\n",
        "\n",
        "# Final embedding dim for user/poi alignment\n",
        "TARGET_EMBEDDING_DIM = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0e0dea5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "class UserEmbeddings: \n",
        "\tdef __init__(self,\n",
        "\t\t\tusers_file: str,\n",
        "\t\t\tuser_poi_interactions_file: str,\n",
        "\t\t\tpoi_tree_file: str,\n",
        "\t\t\tmetadata_pkl: Optional[str] = None):\n",
        "\t\tself.users_df = pd.read_csv(users_file)\n",
        "\t\tself.interactions_df = pd.read_csv(user_poi_interactions_file)\n",
        "\n",
        "\t\twith open(poi_tree_file, 'r', encoding='utf-8') as f:\n",
        "\t\t\tself.poi_tree = json.load(f)\n",
        "\n",
        "\t\t# Auto-detect user_id column (uuid / uudi / user_id)\n",
        "\t\tself.user_id_col = self._resolve_user_id_col()\n",
        "\n",
        "\t\t# Load metadata.pkl (use for ordering if present)\n",
        "\t\tself.meta_user_to_idx = {}\n",
        "\t\tself.meta_idx_to_user = {}\n",
        "\t\tself.meta_idx_to_poi = {}\n",
        "\t\tif metadata_pkl is None:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tmetadata_pkl = str(Path(users_file).resolve().parent / \"metadata.pkl\")\n",
        "\t\t\texcept Exception:\n",
        "\t\t\t\tmetadata_pkl = None\n",
        "\n",
        "\t\tif metadata_pkl and Path(metadata_pkl).exists():\n",
        "\t\t\twith open(metadata_pkl, \"rb\") as f:\n",
        "\t\t\t\t_meta = pickle.load(f)\n",
        "\t\t\tself.meta_user_to_idx = _meta.get(\"user_to_idx\", {})\n",
        "\t\t\tself.meta_idx_to_user = _meta.get(\"idx_to_user\", {})\n",
        "\t\t\tself.meta_idx_to_poi = _meta.get(\"idx_to_poi\", {})\n",
        "\n",
        "\t\tself.user_embeddings = {}\n",
        "\t\tself.poi_embeddings = {}\n",
        "\n",
        "\tdef _resolve_user_id_col(self) -> str:\n",
        "\t\tfor col in (\"uuid\", \"uudi\", \"user_id\"):\n",
        "\t\t\tif col in self.users_df.columns:\n",
        "\t\t\t\treturn col\n",
        "\t\traise KeyError(\"Missing user id column: expected one of ['uuid','uudi','user_id']\")\n",
        "\n",
        "\tdef _get_ordered_user_ids(self) -> List[str]:\n",
        "\t\tif self.meta_idx_to_user:\n",
        "\t\t\tidx2user = self.meta_idx_to_user\n",
        "\t\t\tordered = [idx2user[i] for i in sorted(idx2user.keys()) if idx2user[i] in set(self.users_df[self.user_id_col].astype(str))]\n",
        "\t\t\tif ordered:\n",
        "\t\t\t\treturn ordered\n",
        "\t\treturn self.users_df[self.user_id_col].astype(str).tolist()\n",
        "\n",
        "\tdef _get_ordered_level0_poi_ids(self) -> List[str]:\n",
        "\t\tlvl0 = self.poi_tree.get(\"level_0\", {})\n",
        "\t\tif self.meta_idx_to_poi and 0 in self.meta_idx_to_poi:\n",
        "\t\t\tidx2poi = self.meta_idx_to_poi[0]\n",
        "\t\t\tordered = [idx2poi[i] for i in sorted(idx2poi.keys()) if idx2poi[i] in lvl0]\n",
        "\t\t\tif ordered:\n",
        "\t\t\t\treturn ordered\n",
        "\t\treturn list(lvl0.keys())\n",
        "\n",
        "\tdef _align_embedding_dim(self, X: np.ndarray, target_dim: int, label: str) -> np.ndarray:\n",
        "\t\t\"\"\"Project/pad embeddings to target_dim for user/poi alignment.\"\"\"\n",
        "\t\tif target_dim is None:\n",
        "\t\t\treturn X\n",
        "\t\tn_samples, n_features = X.shape\n",
        "\t\tif n_features == target_dim:\n",
        "\t\t\treturn X\n",
        "\t\tif n_features < target_dim:\n",
        "\t\t\tpad = np.zeros((n_samples, target_dim - n_features), dtype=X.dtype)\n",
        "\t\t\tprint(f\"[align] {label}: padding {n_features} -> {target_dim}\")\n",
        "\t\t\treturn np.hstack([X, pad])\n",
        "\t\t# n_features > target_dim: reduce\n",
        "\t\tif n_samples <= 1:\n",
        "\t\t\tprint(f\"[align] {label}: skip projection (n_samples <= 1)\")\n",
        "\t\t\treturn X\n",
        "\t\tif n_samples <= target_dim:\n",
        "\t\t\tprint(f\"[align] {label}: random projection {n_features} -> {target_dim}\")\n",
        "\t\t\trp = GaussianRandomProjection(n_components=target_dim, random_state=42)\n",
        "\t\t\treturn rp.fit_transform(X)\n",
        "\t\tprint(f\"[align] {label}: SVD projection {n_features} -> {target_dim}\")\n",
        "\t\tsvd = TruncatedSVD(n_components=target_dim, random_state=42)\n",
        "\t\treturn svd.fit_transform(X)\n",
        "\n",
        "\tdef build_X_A(self) -> np.ndarray:\n",
        "\t\t\"\"\"\n",
        "\t\tFeatures from user profile:\n",
        "\t\t- age_group\n",
        "\t\t- interests\n",
        "\t\t- transportation_mode\n",
        "\t\t- price_sensitivity\n",
        "\t\t\"\"\"\n",
        "\n",
        "\t\tprint(\"\\n\" + \"=\"*60)\n",
        "\t\tprint(\"Building X_A: Direct User Attribute Matrix\")\n",
        "\t\tprint(\"=\"*60)\n",
        "\t\n",
        "\t\tfeatures_list = []\n",
        "\t\tfeature_names = []\n",
        "\n",
        "\t\tage_encoder = LabelEncoder()\n",
        "\t\tage_encoded = age_encoder.fit_transform(self.users_df['age_group'])\n",
        "\t\tage_onehot = np.eye(len(age_encoder.classes_))[age_encoded]\n",
        "\t\tfeatures_list.append(age_onehot)\n",
        "\t\tfeature_names.extend([f'age_group_{cls}' for cls in age_encoder.classes_])\n",
        "\n",
        "\t\tinterests_list = [\n",
        "\t\t\t\t[interest.strip() for interest in row.split(';')] \n",
        "\t\t\t\tfor row in self.users_df['interests']\n",
        "\t\t]\n",
        "\t\tmlb_interests = MultiLabelBinarizer()\n",
        "\t\tinterests_onehot = mlb_interests.fit_transform(interests_list)\n",
        "\t\tfeatures_list.append(interests_onehot)\n",
        "\t\tfeature_names.extend([f'interest_{cls}' for cls in mlb_interests.classes_])\n",
        "\t\tprint(f\"Added interests features: {len(mlb_interests.classes_)} dimensions\")\n",
        "\n",
        "\t\ttransport_list = [\n",
        "\t\t\t\t[mode.strip() for mode in row.split(';')] \n",
        "\t\t\t\tfor row in self.users_df['transportation_modes']\n",
        "\t\t]\n",
        "\t\tmlb_transport = MultiLabelBinarizer()\n",
        "\t\ttransport_onehot = mlb_transport.fit_transform(transport_list)\n",
        "\t\tfeatures_list.append(transport_onehot)\n",
        "\t\tfeature_names.extend([f'transport_{cls}' for cls in mlb_transport.classes_])\n",
        "\t\tprint(f\"Added transportation_modes features: {len(mlb_transport.classes_)} dimensions\")\n",
        "\t\t\n",
        "\t\tprice_encoder = LabelEncoder()\n",
        "\t\tprice_encoded = price_encoder.fit_transform(self.users_df['price_sensitivity'])\n",
        "\t\tprice_onehot = np.eye(len(price_encoder.classes_))[price_encoded]\n",
        "\t\tfeatures_list.append(price_onehot)\n",
        "\t\tfeature_names.extend([f'price_{cls}' for cls in price_encoder.classes_])\n",
        "\t\tprint(f\"Added price_sensitivity features: {len(price_encoder.classes_)} dimensions\")\n",
        "\n",
        "\t\tX_A = np.hstack(features_list)\n",
        "\t\t\n",
        "\t\tprint(f\"\\nX_A shape: {X_A.shape}\")\n",
        "\t\tprint(f\"Total features: {len(feature_names)}\")\n",
        "\n",
        "\t\treturn X_A\n",
        "\t\n",
        "\tdef build_X_T(self, embedding_dim: int = 64) -> np.ndarray:\n",
        "\t\t\"\"\"\n",
        "\t\tSource 1: Sources/Files/user_poi_interactions.csv\n",
        "\t\t- user_id, poi_id\n",
        "\t\tSource 2: Sources/Files/poi_tree_with_uuids.json (level 0)\n",
        "\t\t- data.category, data.price, data.characteristics\n",
        "\t\t\"\"\"\n",
        "\t\n",
        "\t\tprint(\"\\n\" + \"=\"*60)\n",
        "\t\tprint(\"Building X_T: Inverse User Attribute Matrix\")\n",
        "\t\tprint(\"=\"*60)\n",
        "\t\t\n",
        "\t\t# Get unique users and POIs (prefer metadata ordering)\n",
        "\t\tunique_users = self._get_ordered_user_ids()\n",
        "\t\t\n",
        "\t\t# Get all level 0 POI IDs from tree (prefer metadata ordering)\n",
        "\t\tall_poi_ids = self._get_ordered_level0_poi_ids()\n",
        "\t\t\n",
        "\t\tuser_to_idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
        "\t\tpoi_to_idx = {pid: idx for idx, pid in enumerate(all_poi_ids)}\n",
        "\n",
        "\t\t# Create sparse interaction matrix\n",
        "\t\tn_users = len(unique_users)\n",
        "\t\tn_pois = len(all_poi_ids)\n",
        "\t\t\n",
        "\t\tprint(f\"Building interaction matrix: {n_users} users × {n_pois} POIs\")\n",
        "\n",
        "\t\t# Aggregate interactions (visits + weighted ratings)\n",
        "\t\tuser_poi_scores = {}\n",
        "\t\t\n",
        "\t\tfor _, row in self.interactions_df.iterrows():\n",
        "\t\t\t\tuser_id = row['user_id']\n",
        "\t\t\t\tpoi_id = row['poi_id']\n",
        "\t\t\t\t\n",
        "\t\t\t\tif user_id not in user_to_idx or poi_id not in poi_to_idx:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\t\t\t\t\n",
        "\t\t\t\tkey = (user_id, poi_id)\n",
        "\t\t\t\t\n",
        "\t\t\t\tif row['interaction_type'] == 'visit':\n",
        "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 1.0\n",
        "\t\t\t\telif row['interaction_type'] == 'rating':\n",
        "\t\t\t\t\t\t# Normalize rating to 0-1 scale\n",
        "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + (row['value'] / 5.0)\n",
        "\t\t\t\telif row['interaction_type'] == 'search':\n",
        "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 0.3\n",
        "\t\t\n",
        "\t\t# Build sparse matrix\n",
        "\t\trow_indices = []\n",
        "\t\tcol_indices = []\n",
        "\t\tvalues = []\n",
        "\t\t\n",
        "\t\tfor (user_id, poi_id), score in user_poi_scores.items():\n",
        "\t\t\t\trow_indices.append(user_to_idx[user_id])\n",
        "\t\t\t\tcol_indices.append(poi_to_idx[poi_id])\n",
        "\t\t\t\tvalues.append(score)\n",
        "\t\t\n",
        "\t\tinteraction_matrix = csr_matrix(\n",
        "\t\t\t\t(values, (row_indices, col_indices)),\n",
        "\t\t\t\tshape=(n_users, n_pois)\n",
        "\t\t)\n",
        "\t\t\n",
        "\t\tprint(f\"Interaction matrix density: {interaction_matrix.nnz / (n_users * n_pois) * 100:.2f}%\")\n",
        "\t\t\n",
        "\t\t# Matrix factorization to learn latent user features\n",
        "\t\t# Using NMF (Non-negative Matrix Factorization)\n",
        "\t\tprint(f\"Performing matrix factorization (embedding_dim={embedding_dim})...\")\n",
        "\t\t\n",
        "\t\tnmf = NMF(n_components=embedding_dim, init='random', random_state=42, max_iter=200)\n",
        "\t\tX_T = nmf.fit_transform(interaction_matrix)\n",
        "\t\t\n",
        "\t\t# Normalize\n",
        "\t\tscaler = StandardScaler()\n",
        "\t\tX_T = scaler.fit_transform(X_T)\n",
        "\t\t\n",
        "\t\tprint(f\"X_T shape: {X_T.shape}\")\n",
        "\t\tprint(f\"Reconstruction error: {nmf.reconstruction_err_:.4f}\")\n",
        "\t\t\n",
        "\t\tself.X_T = X_T\n",
        "\t\tself.X_T_model = nmf\n",
        "\t\tself.poi_to_idx = poi_to_idx\n",
        "\n",
        "\t\treturn X_T\n",
        "\t\n",
        "\tdef build_user_embeddings(self) -> np.ndarray:\n",
        "\t\tprint(\"\\n\" + \"=\"*60)\n",
        "\t\tprint(\"Building Complete User Embeddings\")\n",
        "\t\tprint(\"=\"*60)\n",
        "\t\t\n",
        "\t\tX_A = self.build_X_A()\n",
        "\t\tX_T = self.build_X_T(embedding_dim=FINAL_EMBEDDING_DIM)\n",
        "\t\t\n",
        "\t\t# Concatenate\n",
        "\t\tX = np.hstack([X_A, X_T])\n",
        "\t\tX = self._align_embedding_dim(X, TARGET_EMBEDDING_DIM, \"user\")\n",
        "\n",
        "\t\t# store for saving\n",
        "\t\tself.X_A = X_A\n",
        "\t\tself.X_T = X_T\n",
        "\t\t\n",
        "\t\tprint(f\"\\nFinal user embedding shape: {X.shape}\")\n",
        "\t\tprint(f\"  X_A dimensions: {X_A.shape[1]}\")\n",
        "\t\tprint(f\"  X_T dimensions: {X_T.shape[1]}\")\n",
        "\t\tprint(f\"  Total dimensions: {X.shape[1]}\")\n",
        "\t\t\n",
        "\t\tself.X = X\n",
        "\t\t\n",
        "\t\t# Store user embeddings in dictionary (metadata ordering)\n",
        "\t\tself.user_ids = self._get_ordered_user_ids()\n",
        "\t\tself.user_id_to_idx = {uid: i for i, uid in enumerate(self.user_ids)}\n",
        "\t\tself.idx_to_user = {i: uid for i, uid in enumerate(self.user_ids)}\n",
        "\t\t\n",
        "\t\tfor idx, user_id in enumerate(self.user_ids):\n",
        "\t\t\t\tself.user_embeddings[user_id] = X[idx]\n",
        "\t\t\n",
        "\t\treturn X\n",
        "\n",
        "\tdef save_embeddings(self, output_file: str = 'user_embeddings.pkl'):\n",
        "\t\t# If poi_embeddings is empty, try loading from Sources/poi_embeddings.pkl\n",
        "\t\tif not self.poi_embeddings:\n",
        "\t\t\troot = Path(output_file).resolve().parent.parent if Path(output_file).is_absolute() else None\n",
        "\t\t\tif root is not None:\n",
        "\t\t\t\tcand = root / \"Sources\" / \"poi_embeddings.pkl\"\n",
        "\t\t\t\tif cand.exists():\n",
        "\t\t\t\t\twith cand.open(\"rb\") as f:\n",
        "\t\t\t\t\t\tpoi_data = pickle.load(f)\n",
        "\t\t\t\t\tself.poi_embeddings = poi_data.get(\"poi_embeddings\", {})\n",
        "\n",
        "\t\tdata = {\n",
        "\t\t\t'user_embeddings': self.user_embeddings,\n",
        "\t\t\t'user_id_to_idx': getattr(self, 'user_id_to_idx', {}),\n",
        "\t\t\t'idx_to_user': getattr(self, 'idx_to_user', {}),\n",
        "\t\t\t'X': getattr(self, 'X', None),\n",
        "\t\t\t'X_A': getattr(self, 'X_A', None),\n",
        "\t\t\t'X_T': getattr(self, 'X_T', None),\n",
        "\t\t\t'user_id_col': self.user_id_col,\n",
        "\t\t\t'poi_embeddings': self.poi_embeddings,\n",
        "\t\t}\n",
        "\n",
        "\t\twith open(output_file, 'wb') as f:\n",
        "\t\t\tpickle.dump(data, f, protocol=4)\n",
        "\t\t\t\n",
        "\tdef load_embeddings(self, input_file: str = 'user_embeddings.pkl'):\n",
        "\t\twith open(input_file, 'rb') as f:\n",
        "\t\t\tdata = pickle.load(f)\n",
        "\t\t\t\t\t\t\n",
        "\t\tself.user_embeddings = data.get('user_embeddings', {})\n",
        "\t\tself.poi_embeddings = data.get('poi_embeddings', {})\n",
        "\t\tself.user_id_to_idx = data.get('user_id_to_idx', {})\n",
        "\t\tself.idx_to_user = data.get('idx_to_user', {})\n",
        "\t\tself.X = data.get('X', None)\n",
        "\t\tself.user_id_col = data.get('user_id_col', self.user_id_col)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bcb469c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user_preferences_file: C:\\Users\\syoon\\SpatiaLynk_recommender\\Sources\\Files\\user_preferences.csv True\n",
            "user_poi_interactions_file: C:\\Users\\syoon\\SpatiaLynk_recommender\\Sources\\Files\\user_poi_interactions.csv True\n",
            "poi_tree_file: C:\\Users\\syoon\\SpatiaLynk_recommender\\Sources\\Files\\poi_tree_with_uuids.json True\n",
            "\n",
            "============================================================\n",
            "Building Complete User Embeddings\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Building X_A: Direct User Attribute Matrix\n",
            "============================================================\n",
            "Added interests features: 25 dimensions\n",
            "Added transportation_modes features: 6 dimensions\n",
            "Added price_sensitivity features: 3 dimensions\n",
            "\n",
            "X_A shape: (21, 39)\n",
            "Total features: 39\n",
            "\n",
            "============================================================\n",
            "Building X_T: Inverse User Attribute Matrix\n",
            "============================================================\n",
            "Building interaction matrix: 21 users × 4696 POIs\n",
            "Interaction matrix density: 0.26%\n",
            "Performing matrix factorization (embedding_dim=32)...\n",
            "X_T shape: (21, 32)\n",
            "Reconstruction error: 0.0033\n",
            "[align] user: random projection 71 -> 64\n",
            "\n",
            "Final user embedding shape: (21, 64)\n",
            "  X_A dimensions: 39\n",
            "  X_T dimensions: 32\n",
            "  Total dimensions: 64\n",
            "Saved user embeddings to: C:\\Users\\syoon\\SpatiaLynk_recommender\\Sources\\user_embeddings.pkl\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def find_repo_root(start=None) -> Path:\n",
        "\tstart = Path(start or Path.cwd()).resolve()\n",
        "\tfor p in [start] + list(start.parents):\n",
        "\t\tif (p / \".git\").exists():\n",
        "\t\t\treturn p\n",
        "\traise RuntimeError(f\"Cannot find repo root from {start}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tROOT = find_repo_root()\n",
        "\tSOURCES = ROOT / \"Sources\"\n",
        "\tDATA_DIR = SOURCES / \"Files\"\n",
        "\n",
        "\tuser_preferences_file = DATA_DIR / \"user_preferences.csv\"\n",
        "\tuser_poi_interactions_file = DATA_DIR / \"user_poi_interactions.csv\"\n",
        "\tpoi_tree_file = DATA_DIR / \"poi_tree_with_uuids.json\"\n",
        "\n",
        "\tprint(\"user_preferences_file:\", user_preferences_file, user_preferences_file.exists())\n",
        "\tprint(\"user_poi_interactions_file:\", user_poi_interactions_file, user_poi_interactions_file.exists())\n",
        "\tprint(\"poi_tree_file:\", poi_tree_file, poi_tree_file.exists())\n",
        "\n",
        "\tlearner = UserEmbeddings(\n",
        "\t\tusers_file=str(user_preferences_file),\n",
        "\t\tuser_poi_interactions_file=str(user_poi_interactions_file),\n",
        "\t\tpoi_tree_file=str(poi_tree_file),\n",
        "\t)\n",
        "\n",
        "\t# Build user embeddings\n",
        "\tlearner.build_user_embeddings()\n",
        "\t\n",
        "\t# Save embeddings (under Sources folder)\n",
        "\tout_pkl = SOURCES / \"user_embeddings.pkl\"\n",
        "\tlearner.save_embeddings(str(out_pkl))\n",
        "\tprint(\"Saved user embeddings to:\", out_pkl)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
