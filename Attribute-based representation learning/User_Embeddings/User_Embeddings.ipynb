{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dcfff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer, StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "import json\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0dea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserEmbeddigns: \n",
    "\tdef __init__(self,\n",
    "\t\t\tusers_file: str,\n",
    "\t\t\tuser_poi_interactions_file: str,\n",
    "\t\t\tpoi_tree_file: str):\n",
    "\t\tself.users_df = pd.read_csv(users_file)\n",
    "\t\tself.interactions_df = pd.read_csv(user_poi_interactions_file)\n",
    "\n",
    "\t\twith open(poi_tree_file, 'r') as f:\n",
    "\t\t\tself.poi_tree = json.load(f)\n",
    "\t\n",
    "\t\tself.user_embeddings = {}\n",
    "\t\tself.poi_embeddings = {}\n",
    "\n",
    "\tdef build_X_A(self) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tFeatures from user profile:\n",
    "\t\t- age_group\n",
    "\t\t- interests\n",
    "\t\t- transportation_mode\n",
    "\t\t- price_sensitivity\n",
    "\t\t\"\"\"\n",
    "\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building X_A: Direct User Attribute Matrix\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\n",
    "\t\tfeatures_list = []\n",
    "\t\tfeature_names = []\n",
    "\n",
    "\t\tage_encoder = LabelEncoder()\n",
    "\t\tage_encoded = age_encoder.fit_transform(self.users_df['age_group'])\n",
    "\t\tage_onehot = np.eye(len(age_encoder.classes_))[age_encoded]\n",
    "\t\tfeatures_list.append(age_onehot)\n",
    "\t\tfeature_names.extend([f'age_group_{cls}' for cls in age_encoder.classes_])\n",
    "\n",
    "\t\tinterests_list = [\n",
    "\t\t\t\t[interest.strip() for interest in row.split(';')] \n",
    "\t\t\t\tfor row in self.users_df['interests']\n",
    "\t\t]\n",
    "\t\tmlb_interests = MultiLabelBinarizer()\n",
    "\t\tinterests_onehot = mlb_interests.fit_transform(interests_list)\n",
    "\t\tfeatures_list.append(interests_onehot)\n",
    "\t\tfeature_names.extend([f'interest_{cls}' for cls in mlb_interests.classes_])\n",
    "\t\tprint(f\"Added interests features: {len(mlb_interests.classes_)} dimensions\")\n",
    "\n",
    "\t\ttransport_list = [\n",
    "\t\t\t\t[mode.strip() for mode in row.split(';')] \n",
    "\t\t\t\tfor row in self.users_df['transportation_modes']\n",
    "\t\t]\n",
    "\t\tmlb_transport = MultiLabelBinarizer()\n",
    "\t\ttransport_onehot = mlb_transport.fit_transform(transport_list)\n",
    "\t\tfeatures_list.append(transport_onehot)\n",
    "\t\tfeature_names.extend([f'transport_{cls}' for cls in mlb_transport.classes_])\n",
    "\t\tprint(f\"Added transportation_modes features: {len(mlb_transport.classes_)} dimensions\")\n",
    "\t\t\n",
    "\t\tprice_encoder = LabelEncoder()\n",
    "\t\tprice_encoded = price_encoder.fit_transform(self.users_df['price_sensitivity'])\n",
    "\t\tprice_onehot = np.eye(len(price_encoder.classes_))[price_encoded]\n",
    "\t\tfeatures_list.append(price_onehot)\n",
    "\t\tfeature_names.extend([f'price_{cls}' for cls in price_encoder.classes_])\n",
    "\t\tprint(f\"Added price_sensitivity features: {len(price_encoder.classes_)} dimensions\")\n",
    "\n",
    "\t\tX_A = np.hstack(features_list)\n",
    "\t\t\n",
    "\t\tprint(f\"\\nX_A shape: {X_A.shape}\")\n",
    "\t\tprint(f\"Total features: {len(feature_names)}\")\n",
    "\n",
    "\t\treturn X_A\n",
    "\t\n",
    "\tdef build_X_T(self, embedding_dim: int = 32) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tSource 1: user_poi_interactions.csv\n",
    "\t\t- user_id, poi_id\n",
    "\t\tSource 2: poi_tree_with_uuids.json (level 0)\n",
    "\t\t- data.category, data.price, data.characteristics\n",
    "\t\t\"\"\"\n",
    "\t\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building X_T: Inverse User Attribute Matrix\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\t\n",
    "\t\t# Get unique users and POIs\n",
    "\t\tunique_users = self.users_df['uudi'].tolist()\n",
    "\t\t\n",
    "\t\t# Get all level 0 POI IDs from tree\n",
    "\t\tall_poi_ids = list(self.poi_tree['level_0'].keys())\n",
    "\t\t\n",
    "\t\tuser_to_idx = {uid: idx for idx, uid in enumerate(unique_users)}\n",
    "\t\tpoi_to_idx = {pid: idx for idx, pid in enumerate(all_poi_ids)}\n",
    "\n",
    "\t\t# Create sparse interaction matrix\n",
    "\t\tn_users = len(unique_users)\n",
    "\t\tn_pois = len(all_poi_ids)\n",
    "\t\t\n",
    "\t\tprint(f\"Building interaction matrix: {n_users} users × {n_pois} POIs\")\n",
    "\n",
    "\t\t# Aggregate interactions (visits + weighted ratings)\n",
    "\t\tuser_poi_scores = {}\n",
    "\t\t\n",
    "\t\tfor _, row in self.interactions_df.iterrows():\n",
    "\t\t\t\tuser_id = row['user_id']\n",
    "\t\t\t\tpoi_id = row['poi_id']\n",
    "\t\t\t\t\n",
    "\t\t\t\tif user_id not in user_to_idx or poi_id not in poi_to_idx:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\n",
    "\t\t\t\tkey = (user_id, poi_id)\n",
    "\t\t\t\t\n",
    "\t\t\t\tif row['interaction_type'] == 'visit':\n",
    "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 1.0\n",
    "\t\t\t\telif row['interaction_type'] == 'rating':\n",
    "\t\t\t\t\t\t# Normalize rating to 0-1 scale\n",
    "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + (row['value'] / 5.0)\n",
    "\t\t\t\telif row['interaction_type'] == 'search':\n",
    "\t\t\t\t\t\tuser_poi_scores[key] = user_poi_scores.get(key, 0) + 0.3\n",
    "\t\t\n",
    "\t\t# Build sparse matrix\n",
    "\t\trow_indices = []\n",
    "\t\tcol_indices = []\n",
    "\t\tvalues = []\n",
    "\t\t\n",
    "\t\tfor (user_id, poi_id), score in user_poi_scores.items():\n",
    "\t\t\t\trow_indices.append(user_to_idx[user_id])\n",
    "\t\t\t\tcol_indices.append(poi_to_idx[poi_id])\n",
    "\t\t\t\tvalues.append(score)\n",
    "\t\t\n",
    "\t\tinteraction_matrix = csr_matrix(\n",
    "\t\t\t\t(values, (row_indices, col_indices)),\n",
    "\t\t\t\tshape=(n_users, n_pois)\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\tprint(f\"Interaction matrix density: {interaction_matrix.nnz / (n_users * n_pois) * 100:.2f}%\")\n",
    "\t\t\n",
    "\t\t# Matrix factorization to learn latent user features\n",
    "\t\t# Using NMF (Non-negative Matrix Factorization)\n",
    "\t\tprint(f\"Performing matrix factorization (embedding_dim={embedding_dim})...\")\n",
    "\t\t\n",
    "\t\tnmf = NMF(n_components=embedding_dim, init='random', random_state=42, max_iter=200)\n",
    "\t\tX_T = nmf.fit_transform(interaction_matrix)\n",
    "\t\t\n",
    "\t\t# Normalize\n",
    "\t\tscaler = StandardScaler()\n",
    "\t\tX_T = scaler.fit_transform(X_T)\n",
    "\t\t\n",
    "\t\tprint(f\"X_T shape: {X_T.shape}\")\n",
    "\t\tprint(f\"Reconstruction error: {nmf.reconstruction_err_:.4f}\")\n",
    "\t\t\n",
    "\t\tself.X_T = X_T\n",
    "\t\tself.X_T_model = nmf\n",
    "\t\tself.poi_to_idx = poi_to_idx\n",
    "\n",
    "\t\treturn X_T\n",
    "\t\n",
    "\tdef build_user_embeddings(self) -> np.ndarray:\n",
    "\t\tprint(\"\\n\" + \"=\"*60)\n",
    "\t\tprint(\"Building Complete User Embeddings\")\n",
    "\t\tprint(\"=\"*60)\n",
    "\t\t\n",
    "\t\tX_A = self.build_X_A()\n",
    "\t\tX_T = self.build_X_T(embedding_dim=32)\n",
    "\t\t\n",
    "\t\t# Concatenate\n",
    "\t\tX = np.hstack([X_A, X_T])\n",
    "\t\t\n",
    "\t\tprint(f\"\\nFinal user embedding shape: {X.shape}\")\n",
    "\t\tprint(f\"  X_A dimensions: {X_A.shape[1]}\")\n",
    "\t\tprint(f\"  X_T dimensions: {X_T.shape[1]}\")\n",
    "\t\tprint(f\"  Total dimensions: {X.shape[1]}\")\n",
    "\t\t\n",
    "\t\tself.X = X\n",
    "\t\t\n",
    "\t\t# Store user embeddings in dictionary\n",
    "\t\tfor idx, user_id in enumerate(self.users_df['uudi']):\n",
    "\t\t\t\tself.user_embeddings[user_id] = X[idx]\n",
    "\t\t\n",
    "\t\treturn X\n",
    "\n",
    "\tdef save_embeddings(self, output_file: str = 'user_embeddings.pkl'):\n",
    "\t\tdata = {\n",
    "\t\t\t'user_embeddings': self.user_embeddings,\n",
    "\t\t\t'poi_embeddings': self.poi_embeddings,\n",
    "\t\t}\n",
    "\n",
    "\t\twith open(output_file, 'wb') as f:\n",
    "\t\t\tpickle.dump(data, f)\n",
    "\t\t\t\n",
    "\tdef load_embeddings(self, input_file: str = 'user_embeddings.pkl'):\n",
    "\t\twith open(input_file, 'rb') as f:\n",
    "\t\t\tdata = pickle.load(f)\n",
    "\t\t\t\t\t\t\n",
    "\t\tself.user_embeddings = data['user_embeddings']\n",
    "\t\tself.poi_embeddings = data['poi_embeddings']\n",
    "\t\tself.user_id_to_idx = data['user_id_to_idx']\n",
    "\t\tself.X = data['X']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcb469c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Building Complete User Embeddings\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Building X_A: Direct User Attribute Matrix\n",
      "============================================================\n",
      "Added interests features: 25 dimensions\n",
      "Added transportation_modes features: 6 dimensions\n",
      "Added price_sensitivity features: 3 dimensions\n",
      "\n",
      "X_A shape: (21, 39)\n",
      "Total features: 39\n",
      "\n",
      "============================================================\n",
      "Building X_T: Inverse User Attribute Matrix\n",
      "============================================================\n",
      "Building interaction matrix: 21 users × 4696 POIs\n",
      "Interaction matrix density: 0.26%\n",
      "Performing matrix factorization (embedding_dim=32)...\n",
      "X_T shape: (21, 32)\n",
      "Reconstruction error: 0.0033\n",
      "\n",
      "Final user embedding shape: (21, 71)\n",
      "  X_A dimensions: 39\n",
      "  X_T dimensions: 32\n",
      "  Total dimensions: 71\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tuser_preferences_file = \"../../Sources/user_preferences.csv\"\n",
    "\tuser_poi_interactions_file = \"../../Sources/user_poi_interactions.csv\"\n",
    "\tpoi_tree_file = \"../../Sources/poi_tree_with_uuids.json\"\n",
    "\n",
    "\tlearner = UserEmbeddigns(\n",
    "\t\tusers_file=user_preferences_file,\n",
    "\t\tuser_poi_interactions_file=user_poi_interactions_file,\n",
    "\t\tpoi_tree_file=poi_tree_file\n",
    "\t)\n",
    "\n",
    "\t# Build user embeddings\n",
    "\tlearner.build_user_embeddings()\n",
    "\t\n",
    "\t# Save embeddings\n",
    "\tlearner.save_embeddings(\"user_embeddings.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
