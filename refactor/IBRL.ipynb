{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a9eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dc6115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionBasedRepresentationLearning:\n",
    "    def __init__(self, \n",
    "                 embeddings_file: str,\n",
    "                 interactions_file: str,\n",
    "                 poi_tree_file: str,\n",
    "                 users_file: str):\n",
    "        \"\"\"\n",
    "        Initialize interaction-based representation learning\n",
    "        \n",
    "        Args:\n",
    "            embeddings_file: Path to embeddings.pkl (from attribute-based learning)\n",
    "            interactions_file: Path to user-POI interactions CSV\n",
    "            poi_tree_file: Path to POI tree JSON\n",
    "            users_file: Path to user preferences CSV\n",
    "        \"\"\"\n",
    "        # Load pre-computed embeddings\n",
    "        with open(embeddings_file, 'rb') as f:\n",
    "            embeddings = pickle.load(f)\n",
    "        \n",
    "        self.X_A = embeddings['X_A']  # Explicit user features\n",
    "        self.X_T = embeddings['X_T']  # Implicit user features\n",
    "        self.user_embeddings = embeddings['user_embeddings']\n",
    "        self.poi_embeddings = embeddings['poi_embeddings']\n",
    "        self.user_id_to_idx = embeddings['user_id_to_idx']\n",
    "        \n",
    "        # Load raw data\n",
    "        self.interactions_df = pd.read_csv(interactions_file)\n",
    "        self.users_df = pd.read_csv(users_file)\n",
    "        \n",
    "        with open(poi_tree_file, 'r') as f:\n",
    "            self.poi_tree = json.load(f)\n",
    "        \n",
    "        # Will store computed components\n",
    "        self.Theta_u = None  # Trainable user parameters\n",
    "        self.A_l_p = {}      # Inter-level POI features for each level\n",
    "        self.G_l = {}        # POI context graphs for each level\n",
    "        self.attention_params = {}  # Attention network parameters\n",
    "        self.P_l = {}        # Complete user representation per level\n",
    "        self.Q_l = {}        # Complete POI representation per level\n",
    "        self.S_l = {}        # Feature-based check-in matrix per level\n",
    "        self.U_l_g = {}      # Graph-based check-in representation per level\n",
    "        \n",
    "        print(\"Initialized Interaction-based Representation Learning\")\n",
    "        print(f\"Users: {len(self.users_df)}\")\n",
    "        print(f\"Interactions: {len(self.interactions_df)}\")\n",
    "        print(f\"User embedding dim: {self.X_A.shape[1] + self.X_T.shape[1]}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2A: Initialize Trainable Parameters\n",
    "    # ========================================================================\n",
    "    \n",
    "    def initialize_trainable_parameters(self, \n",
    "                                       user_embedding_dim: int = 16,\n",
    "                                       attention_hidden_dim: int = 32,\n",
    "                                       seed: int = 42):\n",
    "        \"\"\"\n",
    "        Initialize trainable parameters:\n",
    "        - Θ_u: Additional user embedding parameters\n",
    "        - Attention network parameters (W_1, b_1, W_2, b_2)\n",
    "        \n",
    "        Args:\n",
    "            user_embedding_dim: Dimension of trainable user embeddings\n",
    "            attention_hidden_dim: Hidden layer size for attention network\n",
    "            seed: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2A: Initializing Trainable Parameters\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        num_users = len(self.users_df)\n",
    "        implicit_poi_dim = self.X_T.shape[1]  # Should be 32\n",
    "        \n",
    "        # 1. Trainable user parameters Θ_u\n",
    "        self.Theta_u = np.random.randn(num_users, user_embedding_dim) * 0.01\n",
    "        print(f\"Initialized Θ_u: shape {self.Theta_u.shape}\")\n",
    "        \n",
    "        # 2. Attention network parameters (shared across all levels)\n",
    "        self.attention_params = {\n",
    "            'W_1': np.random.randn(attention_hidden_dim, implicit_poi_dim) * 0.01,\n",
    "            'b_1': np.zeros(attention_hidden_dim),\n",
    "            'W_2': np.random.randn(1, attention_hidden_dim) * 0.01,\n",
    "            'b_2': np.zeros(1)\n",
    "        }\n",
    "        \n",
    "        print(f\"Initialized attention network:\")\n",
    "        print(f\"  W_1: {self.attention_params['W_1'].shape}\")\n",
    "        print(f\"  b_1: {self.attention_params['b_1'].shape}\")\n",
    "        print(f\"  W_2: {self.attention_params['W_2'].shape}\")\n",
    "        print(f\"  b_2: {self.attention_params['b_2'].shape}\")\n",
    "        \n",
    "        return self.Theta_u, self.attention_params\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2B: Compute Inter-level POI Features with Attention\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _relu(self, x):\n",
    "        \"\"\"ReLU activation\"\"\"\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def _sigmoid(self, x):\n",
    "        \"\"\"Sigmoid activation\"\"\"\n",
    "        return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "    \n",
    "    def _softmax(self, x):\n",
    "        \"\"\"Softmax normalization\"\"\"\n",
    "        exp_x = np.exp(x - np.max(x))\n",
    "        return exp_x / exp_x.sum()\n",
    "    \n",
    "    def compute_attention_weight(self, child_embedding: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Compute attention weight for a child POI\n",
    "        \n",
    "        α = Sigmoid(W_2 * ReLU(W_1 * h_child + b_1) + b_2)\n",
    "        \n",
    "        Args:\n",
    "            child_embedding: Implicit feature embedding of child POI\n",
    "        \n",
    "        Returns:\n",
    "            Attention weight (scalar)\n",
    "        \"\"\"\n",
    "        W_1 = self.attention_params['W_1']\n",
    "        b_1 = self.attention_params['b_1']\n",
    "        W_2 = self.attention_params['W_2']\n",
    "        b_2 = self.attention_params['b_2']\n",
    "        \n",
    "        # Hidden layer with ReLU\n",
    "        z = self._relu(W_1 @ child_embedding + b_1)  # Shape: (attention_hidden_dim,)\n",
    "        \n",
    "        # Output layer with Sigmoid\n",
    "        alpha = self._sigmoid(W_2 @ z + b_2)  # Shape: (1,)\n",
    "        \n",
    "        return float(alpha[0])\n",
    "    \n",
    "    def compute_inter_level_features(self, level: int) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Compute inter-level POI features A^l_p for level l\n",
    "        \n",
    "        For each parent POI at level l:\n",
    "        1. Get children POIs at level l-1\n",
    "        2. Compute attention weights for each child\n",
    "        3. Aggregate child embeddings using attention weights\n",
    "        \n",
    "        Args:\n",
    "            level: Target level (must be >= 1, as level 0 has no children)\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping parent_poi_id -> aggregated_embedding\n",
    "        \"\"\"\n",
    "        if level == 0:\n",
    "            print(f\"Level 0 has no children, skipping inter-level features\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"\\nComputing A^{level}_p (Inter-level features for level {level})\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        parent_level_key = f'level_{level}'\n",
    "        child_level_key = f'level_{level-1}'\n",
    "        \n",
    "        parent_pois = self.poi_tree[parent_level_key]\n",
    "        child_pois_data = self.poi_tree[child_level_key]\n",
    "        \n",
    "        # Get child POI embeddings (implicit features Y_T)\n",
    "        child_Y_T = self.poi_embeddings[child_level_key]['Y_T']\n",
    "        child_poi_ids = self.poi_embeddings[child_level_key]['poi_ids']\n",
    "        child_id_to_idx = {pid: idx for idx, pid in enumerate(child_poi_ids)}\n",
    "        \n",
    "        # Get child POI full embeddings (Y = [Y_A | Y_T])\n",
    "        child_Y_full = self.poi_embeddings[child_level_key]['embeddings']\n",
    "        \n",
    "        A_l_p = {}\n",
    "        aggregation_dim = child_Y_full.shape[1]  # Full embedding dimension\n",
    "        \n",
    "        processed = 0\n",
    "        for parent_id, parent_data in parent_pois.items():\n",
    "            children_ids = parent_data.get('children', [])\n",
    "            \n",
    "            if len(children_ids) == 0:\n",
    "                # No children, use zero vector\n",
    "                A_l_p[parent_id] = np.zeros(aggregation_dim)\n",
    "                continue\n",
    "            \n",
    "            attention_weights = []\n",
    "            child_embeddings_implicit = []\n",
    "            child_embeddings_full = []\n",
    "            \n",
    "            for child_id in children_ids:\n",
    "                if child_id not in child_id_to_idx:\n",
    "                    continue\n",
    "                \n",
    "                child_idx = child_id_to_idx[child_id]\n",
    "                \n",
    "                # Get child implicit embedding (for attention computation)\n",
    "                h_child_implicit = child_Y_T[child_idx]  # Shape: (32,)\n",
    "                \n",
    "                # Get child full embedding (for aggregation)\n",
    "                h_child_full = child_Y_full[child_idx]\n",
    "                \n",
    "                # Compute attention weight using implicit features\n",
    "                alpha = self.compute_attention_weight(h_child_implicit)\n",
    "                \n",
    "                attention_weights.append(alpha)\n",
    "                child_embeddings_implicit.append(h_child_implicit)\n",
    "                child_embeddings_full.append(h_child_full)\n",
    "            \n",
    "            if len(attention_weights) == 0:\n",
    "                A_l_p[parent_id] = np.zeros(aggregation_dim)\n",
    "                continue\n",
    "            \n",
    "            # Normalize attention weights using softmax\n",
    "            attention_weights = self._softmax(np.array(attention_weights))\n",
    "            \n",
    "            # Aggregate child full embeddings using attention weights\n",
    "            aggregated = sum(w * emb for w, emb in zip(attention_weights, child_embeddings_full))\n",
    "            A_l_p[parent_id] = aggregated\n",
    "            \n",
    "            processed += 1\n",
    "            if processed % 100 == 0:\n",
    "                print(f\"  Processed {processed}/{len(parent_pois)} parent POIs\")\n",
    "        \n",
    "        print(f\"Completed A^{level}_p: {len(A_l_p)} parent POIs\")\n",
    "        print(f\"  Aggregated embedding dimension: {aggregation_dim}\")\n",
    "        \n",
    "        return A_l_p\n",
    "    \n",
    "    def compute_all_inter_level_features(self, levels: List[int] = [1, 2, 3]):\n",
    "        \"\"\"\n",
    "        Compute inter-level features for all specified levels\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2B: Computing Inter-level POI Features with Attention\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for level in levels:\n",
    "            self.A_l_p[f'level_{level}'] = self.compute_inter_level_features(level)\n",
    "        \n",
    "        print(f\"\\nCompleted inter-level features for levels: {levels}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2C: Build POI Context Graphs\n",
    "    # ========================================================================\n",
    "    \n",
    "    def _haversine_distance(self, lat1: float, lon1: float, \n",
    "                           lat2: float, lon2: float) -> float:\n",
    "        \"\"\"Calculate distance between two coordinates in km\"\"\"\n",
    "        R = 6371\n",
    "        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "        return R * c\n",
    "    \n",
    "    def compute_co_occurrence_matrix(self, \n",
    "                                    level: int, \n",
    "                                    interaction_type: str = 'visit',\n",
    "                                    window_size: int = 1) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute co-occurrence matrix for POIs at a given level\n",
    "        \n",
    "        Two POIs co-occur if a user interacts with both within a time window\n",
    "        \n",
    "        Args:\n",
    "            level: POI tree level\n",
    "            interaction_type: 'visit' or 'search'\n",
    "            window_size: Time window in days\n",
    "        \n",
    "        Returns:\n",
    "            Co-occurrence matrix (symmetric)\n",
    "        \"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        poi_ids = self.poi_embeddings[level_key]['poi_ids']\n",
    "        poi_to_idx = {pid: idx for idx, pid in enumerate(poi_ids)}\n",
    "        n_pois = len(poi_ids)\n",
    "        \n",
    "        co_matrix = np.zeros((n_pois, n_pois))\n",
    "        \n",
    "        # Filter interactions by type\n",
    "        interactions = self.interactions_df[\n",
    "            self.interactions_df['interaction_type'] == interaction_type\n",
    "        ].copy()\n",
    "        \n",
    "        # Convert timestamp to datetime\n",
    "        interactions['timestamp'] = pd.to_datetime(interactions['timestamp'])\n",
    "        \n",
    "        # Group by user\n",
    "        for user_id, user_interactions in interactions.groupby('user_id'):\n",
    "            user_interactions = user_interactions.sort_values('timestamp')\n",
    "            \n",
    "            poi_list = []\n",
    "            for _, row in user_interactions.iterrows():\n",
    "                poi_id = row['poi_id']\n",
    "                \n",
    "                # Map to current level if needed\n",
    "                if level > 0:\n",
    "                    poi_id = self._get_parent_at_level(poi_id, level)\n",
    "                \n",
    "                if poi_id in poi_to_idx:\n",
    "                    poi_list.append(poi_id)\n",
    "            \n",
    "            # Count co-occurrences\n",
    "            for i in range(len(poi_list)):\n",
    "                for j in range(i+1, min(i+window_size+1, len(poi_list))):\n",
    "                    poi_i, poi_j = poi_list[i], poi_list[j]\n",
    "                    idx_i, idx_j = poi_to_idx[poi_i], poi_to_idx[poi_j]\n",
    "                    \n",
    "                    co_matrix[idx_i, idx_j] += 1\n",
    "                    co_matrix[idx_j, idx_i] += 1  # Symmetric\n",
    "        \n",
    "        # Normalize\n",
    "        max_val = co_matrix.max()\n",
    "        if max_val > 0:\n",
    "            co_matrix /= max_val\n",
    "        \n",
    "        return co_matrix\n",
    "    \n",
    "    def _get_parent_at_level(self, poi_id: str, target_level: int) -> str:\n",
    "        \"\"\"Get parent node of poi_id at target_level\"\"\"\n",
    "        current_level = 0\n",
    "        current_id = poi_id\n",
    "        \n",
    "        while current_level < target_level:\n",
    "            level_key = f'level_{current_level}'\n",
    "            if current_id in self.poi_tree[level_key]:\n",
    "                parent = self.poi_tree[level_key][current_id].get('parent')\n",
    "                if parent:\n",
    "                    current_id = parent\n",
    "                    current_level += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return current_id\n",
    "    \n",
    "    def build_poi_context_graph(self, \n",
    "                                level: int,\n",
    "                                distance_threshold: float = 2.0,\n",
    "                                co_search_weight: float = 0.3,\n",
    "                                co_visit_weight: float = 0.5,\n",
    "                                geo_weight: float = 0.2,\n",
    "                                edge_threshold: float = 0.1) -> nx.Graph:\n",
    "        \"\"\"\n",
    "        Build POI context graph G^l for level l\n",
    "        \n",
    "        G^l = <V^l, E^l>\n",
    "        - V^l: POIs at level l\n",
    "        - E^l: Edges with relationships (co-search, co-visit, geo-proximity)\n",
    "        \n",
    "        Args:\n",
    "            level: POI tree level\n",
    "            distance_threshold: Max distance (km) for geo-proximity edges\n",
    "            co_search_weight: Weight for co-search edges\n",
    "            co_visit_weight: Weight for co-visit edges\n",
    "            geo_weight: Weight for geo-proximity edges\n",
    "            edge_threshold: Minimum weight to create edge\n",
    "        \n",
    "        Returns:\n",
    "            NetworkX graph\n",
    "        \"\"\"\n",
    "        print(f\"\\nBuilding POI context graph G^{level}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        pois = list(self.poi_tree[level_key].keys())\n",
    "        n_pois = len(pois)\n",
    "        \n",
    "        print(f\"Number of POIs: {n_pois}\")\n",
    "        \n",
    "        # Initialize graph\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(pois)\n",
    "        \n",
    "        # 1. Compute co-search matrix\n",
    "        print(\"Computing co-search relationships...\")\n",
    "        co_search = self.compute_co_occurrence_matrix(level, 'search', window_size=1)\n",
    "        \n",
    "        # 2. Compute co-visit matrix\n",
    "        print(\"Computing co-visit relationships...\")\n",
    "        co_visit = self.compute_co_occurrence_matrix(level, 'visit', window_size=3)\n",
    "        \n",
    "        # 3. Add edges\n",
    "        print(\"Building edges...\")\n",
    "        poi_to_idx = {pid: idx for idx, pid in enumerate(pois)}\n",
    "        edges_added = 0\n",
    "        \n",
    "        for i, poi_i in enumerate(pois):\n",
    "            poi_i_data = self.poi_tree[level_key][poi_i]\n",
    "            spatial_i = poi_i_data['spatial']\n",
    "            if isinstance(spatial_i, str):\n",
    "                spatial_i = eval(spatial_i)\n",
    "            lat_i, lon_i = spatial_i\n",
    "            \n",
    "            for j in range(i+1, n_pois):\n",
    "                poi_j = pois[j]\n",
    "                poi_j_data = self.poi_tree[level_key][poi_j]\n",
    "                spatial_j = poi_j_data['spatial']\n",
    "                if isinstance(spatial_j, str):\n",
    "                    spatial_j = eval(spatial_j)\n",
    "                lat_j, lon_j = spatial_j\n",
    "                \n",
    "                # Compute geo-proximity score\n",
    "                dist = self._haversine_distance(lat_i, lon_i, lat_j, lon_j)\n",
    "                \n",
    "                if dist < distance_threshold:\n",
    "                    geo_score = 1 / (1 + dist)  # Closer = higher score\n",
    "                else:\n",
    "                    geo_score = 0\n",
    "                \n",
    "                # Compute combined edge weight\n",
    "                idx_i, idx_j = poi_to_idx[poi_i], poi_to_idx[poi_j]\n",
    "                \n",
    "                edge_weight = (co_search_weight * co_search[idx_i, idx_j] +\n",
    "                              co_visit_weight * co_visit[idx_i, idx_j] +\n",
    "                              geo_weight * geo_score)\n",
    "                \n",
    "                # Add edge if weight exceeds threshold\n",
    "                if edge_weight > edge_threshold:\n",
    "                    G.add_edge(poi_i, poi_j, weight=edge_weight)\n",
    "                    edges_added += 1\n",
    "            \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"  Processed {i+1}/{n_pois} POIs\")\n",
    "        \n",
    "        print(f\"Graph G^{level} constructed:\")\n",
    "        print(f\"  Nodes: {G.number_of_nodes()}\")\n",
    "        print(f\"  Edges: {G.number_of_edges()}\")\n",
    "        print(f\"  Density: {nx.density(G):.4f}\")\n",
    "        print(f\"  Avg degree: {sum(dict(G.degree()).values()) / G.number_of_nodes():.2f}\")\n",
    "        \n",
    "        return G\n",
    "    \n",
    "    def build_all_poi_context_graphs(self, \n",
    "                                     levels: List[int] = [0, 1, 2, 3],\n",
    "                                     distance_thresholds: Dict[int, float] = None):\n",
    "        \"\"\"\n",
    "        Build POI context graphs for all specified levels\n",
    "        \n",
    "        Args:\n",
    "            levels: List of levels to build graphs for\n",
    "            distance_thresholds: Dict mapping level -> distance threshold\n",
    "                                Default: level 0=2km, level 1=5km, level 2=10km, level 3=20km\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2C: Building POI Context Graphs\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        if distance_thresholds is None:\n",
    "            distance_thresholds = {\n",
    "                0: 2.0,   # 2km for individual POIs\n",
    "                1: 5.0,   # 5km for containers/streets\n",
    "                2: 10.0,  # 10km for districts\n",
    "                3: 20.0   # 20km for regions\n",
    "            }\n",
    "        \n",
    "        for level in levels:\n",
    "            threshold = distance_thresholds.get(level, 5.0)\n",
    "            self.G_l[f'level_{level}'] = self.build_poi_context_graph(\n",
    "                level=level,\n",
    "                distance_threshold=threshold\n",
    "            )\n",
    "        \n",
    "        print(f\"\\nCompleted POI context graphs for levels: {levels}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # STEP 2D: Compute Graph-based Check-in Representation\n",
    "    # ========================================================================\n",
    "    \n",
    "    def get_user_history(self, user_id: str, level: int = 0) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get list of POIs user has visited at given level\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            level: POI tree level\n",
    "        \n",
    "        Returns:\n",
    "            List of POI IDs\n",
    "        \"\"\"\n",
    "        user_interactions = self.interactions_df[\n",
    "            (self.interactions_df['user_id'] == user_id) &\n",
    "            (self.interactions_df['interaction_type'] == 'visit')\n",
    "        ]\n",
    "        \n",
    "        history = []\n",
    "        for _, row in user_interactions.iterrows():\n",
    "            poi_id = row['poi_id']\n",
    "            \n",
    "            # Map to current level if needed\n",
    "            if level > 0:\n",
    "                poi_id = self._get_parent_at_level(poi_id, level)\n",
    "            \n",
    "            if poi_id not in history:\n",
    "                history.append(poi_id)\n",
    "        \n",
    "        return history\n",
    "    \n",
    "    def compute_graph_based_checkin_single(self,\n",
    "                                          user_id: str,\n",
    "                                          candidate_poi: str,\n",
    "                                          level: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute graph-based check-in representation U^l_g for a single user-POI pair\n",
    "        \n",
    "        U^l_g[u, p_i] = (1/|H_u|) * Σ w(p_i, p_j) * Y^l[p_j]\n",
    "                         for all p_j in H_u (user's history)\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            candidate_poi: Candidate POI ID to recommend\n",
    "            level: POI tree level\n",
    "        \n",
    "        Returns:\n",
    "            Graph-based representation vector\n",
    "        \"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        G = self.G_l.get(level_key)\n",
    "        \n",
    "        if G is None:\n",
    "            raise ValueError(f\"Graph for level {level} not built yet\")\n",
    "        \n",
    "        # Get user's historical visited POIs\n",
    "        history = self.get_user_history(user_id, level)\n",
    "        \n",
    "        if len(history) == 0:\n",
    "            # No history, return zero vector\n",
    "            poi_embedding_dim = self.poi_embeddings[level_key]['embeddings'].shape[1]\n",
    "            return np.zeros(poi_embedding_dim)\n",
    "        \n",
    "        # Get POI embeddings\n",
    "        poi_ids = self.poi_embeddings[level_key]['poi_ids']\n",
    "        poi_embeddings = self.poi_embeddings[level_key]['embeddings']\n",
    "        poi_to_idx = {pid: idx for idx, pid in enumerate(poi_ids)}\n",
    "        \n",
    "        # Aggregate geo-spatial influence from history\n",
    "        geo_influence = np.zeros(poi_embeddings.shape[1])\n",
    "        \n",
    "        for visited_poi in history:\n",
    "            if visited_poi not in poi_to_idx:\n",
    "                continue\n",
    "            \n",
    "            # Check if edge exists in graph\n",
    "            if G.has_edge(candidate_poi, visited_poi):\n",
    "                edge_weight = G[candidate_poi][visited_poi]['weight']\n",
    "                visited_poi_idx = poi_to_idx[visited_poi]\n",
    "                visited_poi_embedding = poi_embeddings[visited_poi_idx]\n",
    "                \n",
    "                geo_influence += edge_weight * visited_poi_embedding\n",
    "        \n",
    "        # Average over history\n",
    "        geo_influence /= len(history)\n",
    "        \n",
    "        return geo_influence\n",
    "    \n",
    "    def compute_graph_based_checkin_matrix(self, level: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute graph-based check-in matrix U^l_g for all user-POI pairs at level l\n",
    "        \n",
    "        Args:\n",
    "            level: POI tree level\n",
    "        \n",
    "        Returns:\n",
    "            U^l_g matrix: (num_users, num_pois, embedding_dim)\n",
    "        \"\"\"\n",
    "        print(f\"\\nComputing U^{level}_g (Graph-based check-in matrix for level {level})\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        poi_ids = self.poi_embeddings[level_key]['poi_ids']\n",
    "        user_ids = self.users_df['uudi'].tolist()\n",
    "        \n",
    "        n_users = len(user_ids)\n",
    "        n_pois = len(poi_ids)\n",
    "        embedding_dim = self.poi_embeddings[level_key]['embeddings'].shape[1]\n",
    "        \n",
    "        print(f\"Computing for {n_users} users × {n_pois} POIs\")\n",
    "        \n",
    "        U_l_g = np.zeros((n_users, n_pois, embedding_dim))\n",
    "        \n",
    "        for u_idx, user_id in enumerate(user_ids):\n",
    "            for p_idx, poi_id in enumerate(poi_ids):\n",
    "                U_l_g[u_idx, p_idx, :] = self.compute_graph_based_checkin_single(\n",
    "                    user_id, poi_id, level\n",
    "                )\n",
    "            \n",
    "            if (u_idx + 1) % 5 == 0:\n",
    "                print(f\"  Processed {u_idx+1}/{n_users} users\")\n",
    "        \n",
    "        print(f\"U^{level}_g computed: shape {U_l_g.shape}\")\n",
    "        \n",
    "        return U_l_g\n",
    "    \n",
    "    def compute_all_graph_based_checkin_matrices(self, levels: List[int] = [0, 1, 2, 3]):\n",
    "        \"\"\"\n",
    "        Compute graph-based check-in matrices for all levels\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"STEP 2D: Computing Graph-based Check-in Representations\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for level in levels:\n",
    "            self.U_l_g[f'level_{level}'] = self.compute_graph_based_checkin_matrix(level)\n",
    "        \n",
    "        print(f\"\\nCompleted graph-based check-in matrices for levels: {levels}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build Complete User & POI Representations P^l and Q^l\n",
    "    # ========================================================================\n",
    "    \n",
    "    def build_complete_representations(self, level: int):\n",
    "        \"\"\"\n",
    "        Build complete user and POI representations for level l:\n",
    "        \n",
    "        P^l = [X_A | X_T | Θ_u]\n",
    "        Q^l = [Y_A^l | Y_T^l | A^l_p]\n",
    "        \n",
    "        Args:\n",
    "            level: POI tree level\n",
    "        \"\"\"\n",
    "        print(f\"\\nBuilding complete representations for level {level}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Build P^l (user representation)\n",
    "        P_l = np.hstack([self.X_A, self.X_T, self.Theta_u])\n",
    "        self.P_l[level_key] = P_l\n",
    "        \n",
    "        print(f\"P^{level} shape: {P_l.shape}\")\n",
    "        print(f\"  X_A: {self.X_A.shape[1]} dims\")\n",
    "        print(f\"  X_T: {self.X_T.shape[1]} dims\")\n",
    "        print(f\"  Θ_u: {self.Theta_u.shape[1]} dims\")\n",
    "        \n",
    "        # Build Q^l (POI representation)\n",
    "        Y_A_l = self.poi_embeddings[level_key]['Y_A']\n",
    "        Y_T_l = self.poi_embeddings[level_key]['Y_T']\n",
    "        \n",
    "        if level == 0:\n",
    "            # Level 0 has no inter-level features\n",
    "            Q_l = np.hstack([Y_A_l, Y_T_l])\n",
    "        else:\n",
    "            # Levels 1+ have inter-level features\n",
    "            A_l_p_dict = self.A_l_p[level_key]\n",
    "            poi_ids = self.poi_embeddings[level_key]['poi_ids']\n",
    "            \n",
    "            # Convert dict to matrix\n",
    "            A_l_p_matrix = np.array([A_l_p_dict[pid] for pid in poi_ids])\n",
    "            Q_l = np.hstack([Y_A_l, Y_T_l, A_l_p_matrix])\n",
    "        \n",
    "        self.Q_l[level_key] = Q_l\n",
    "        \n",
    "        print(f\"Q^{level} shape: {Q_l.shape}\")\n",
    "        print(f\"  Y_A^{level}: {Y_A_l.shape[1]} dims\")\n",
    "        print(f\"  Y_T^{level}: {Y_T_l.shape[1]} dims\")\n",
    "        if level > 0:\n",
    "            print(f\"  A^{level}_p: {A_l_p_matrix.shape[1]} dims\")\n",
    "    \n",
    "    def build_all_complete_representations(self, levels: List[int] = [0, 1, 2, 3]):\n",
    "        \"\"\"Build P^l and Q^l for all levels\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Building Complete User & POI Representations\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for level in levels:\n",
    "            self.build_complete_representations(level)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Compute Feature-based Check-in Matrix S^l\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_feature_based_checkin_matrix(self, level: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Compute feature-based check-in matrix S^l\n",
    "        \n",
    "        S^l = P^l @ (Q^l)^T\n",
    "        \n",
    "        Args:\n",
    "            level: POI tree level\n",
    "        \n",
    "        Returns:\n",
    "            S^l: (num_users, num_pois) affinity matrix\n",
    "        \"\"\"\n",
    "        print(f\"\\nComputing S^{level} (Feature-based check-in matrix)\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        P_l = self.P_l[level_key]\n",
    "        Q_l = self.Q_l[level_key]\n",
    "        \n",
    "        # Pad to match dimensions if needed\n",
    "        if P_l.shape[1] != Q_l.shape[1]:\n",
    "            max_dim = max(P_l.shape[1], Q_l.shape[1])\n",
    "            \n",
    "            if P_l.shape[1] < max_dim:\n",
    "                padding = np.zeros((P_l.shape[0], max_dim - P_l.shape[1]))\n",
    "                P_l = np.hstack([P_l, padding])\n",
    "            \n",
    "            if Q_l.shape[1] < max_dim:\n",
    "                padding = np.zeros((Q_l.shape[0], max_dim - Q_l.shape[1]))\n",
    "                Q_l = np.hstack([Q_l, padding])\n",
    "        \n",
    "        # Compute affinity matrix\n",
    "        S_l = P_l @ Q_l.T\n",
    "        \n",
    "        print(f\"S^{level} shape: {S_l.shape}\")\n",
    "        print(f\"  Min score: {S_l.min():.4f}\")\n",
    "        print(f\"  Max score: {S_l.max():.4f}\")\n",
    "        print(f\"  Mean score: {S_l.mean():.4f}\")\n",
    "        \n",
    "        self.S_l[level_key] = S_l\n",
    "        \n",
    "        return S_l\n",
    "    \n",
    "    def compute_all_feature_based_checkin_matrices(self, levels: List[int] = [0, 1, 2, 3]):\n",
    "        \"\"\"Compute S^l for all levels\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Computing Feature-based Check-in Matrices\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for level in levels:\n",
    "            self.compute_feature_based_checkin_matrix(level)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Save & Load\n",
    "    # ========================================================================\n",
    "    \n",
    "    def save_all(self, output_file: str = 'interaction_learning.pkl'):\n",
    "        \"\"\"Save all computed components\"\"\"\n",
    "        data = {\n",
    "            'Theta_u': self.Theta_u,\n",
    "            'attention_params': self.attention_params,\n",
    "            'A_l_p': self.A_l_p,\n",
    "            'G_l': self.G_l,\n",
    "            'P_l': self.P_l,\n",
    "            'Q_l': self.Q_l,\n",
    "            'S_l': self.S_l,\n",
    "            'U_l_g': self.U_l_g\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"All components saved to: {output_file}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    def load_all(self, input_file: str = 'interaction_learning.pkl'):\n",
    "        \"\"\"Load all components\"\"\"\n",
    "        with open(input_file, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.Theta_u = data['Theta_u']\n",
    "        self.attention_params = data['attention_params']\n",
    "        self.A_l_p = data['A_l_p']\n",
    "        self.G_l = data['G_l']\n",
    "        self.P_l = data['P_l']\n",
    "        self.Q_l = data['Q_l']\n",
    "        self.S_l = data['S_l']\n",
    "        self.U_l_g = data['U_l_g']\n",
    "        \n",
    "        print(f\"All components loaded from: {input_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36c7c70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTERACTION-BASED REPRESENTATION LEARNING\n",
      "============================================================\n",
      "Initialized Interaction-based Representation Learning\n",
      "Users: 21\n",
      "Interactions: 529\n",
      "User embedding dim: 82\n",
      "\n",
      "============================================================\n",
      "STEP 2A: Initializing Trainable Parameters\n",
      "============================================================\n",
      "Initialized Θ_u: shape (21, 16)\n",
      "Initialized attention network:\n",
      "  W_1: (32, 32)\n",
      "  b_1: (32,)\n",
      "  W_2: (1, 32)\n",
      "  b_2: (1,)\n",
      "\n",
      "============================================================\n",
      "STEP 2B: Computing Inter-level POI Features with Attention\n",
      "============================================================\n",
      "\n",
      "Computing A^1_p (Inter-level features for level 1)\n",
      "------------------------------------------------------------\n",
      "  Processed 100/1355 parent POIs\n",
      "  Processed 200/1355 parent POIs\n",
      "  Processed 300/1355 parent POIs\n",
      "  Processed 400/1355 parent POIs\n",
      "  Processed 500/1355 parent POIs\n",
      "  Processed 600/1355 parent POIs\n",
      "  Processed 700/1355 parent POIs\n",
      "  Processed 800/1355 parent POIs\n",
      "  Processed 900/1355 parent POIs\n",
      "Completed A^1_p: 1355 parent POIs\n",
      "  Aggregated embedding dimension: 86\n",
      "\n",
      "Computing A^2_p (Inter-level features for level 2)\n",
      "------------------------------------------------------------\n",
      "Completed A^2_p: 44 parent POIs\n",
      "  Aggregated embedding dimension: 84\n",
      "\n",
      "Computing A^3_p (Inter-level features for level 3)\n",
      "------------------------------------------------------------\n",
      "Completed A^3_p: 5 parent POIs\n",
      "  Aggregated embedding dimension: 84\n",
      "\n",
      "Completed inter-level features for levels: [1, 2, 3]\n",
      "\n",
      "============================================================\n",
      "STEP 2C: Building POI Context Graphs\n",
      "============================================================\n",
      "\n",
      "Building POI context graph G^0\n",
      "------------------------------------------------------------\n",
      "Number of POIs: 4696\n",
      "Computing co-search relationships...\n",
      "Computing co-visit relationships...\n",
      "Building edges...\n",
      "  Processed 100/4696 POIs\n",
      "  Processed 200/4696 POIs\n",
      "  Processed 300/4696 POIs\n",
      "  Processed 400/4696 POIs\n",
      "  Processed 500/4696 POIs\n",
      "  Processed 600/4696 POIs\n",
      "  Processed 700/4696 POIs\n",
      "  Processed 800/4696 POIs\n",
      "  Processed 900/4696 POIs\n",
      "  Processed 1000/4696 POIs\n",
      "  Processed 1100/4696 POIs\n",
      "  Processed 1200/4696 POIs\n",
      "  Processed 1300/4696 POIs\n",
      "  Processed 1400/4696 POIs\n",
      "  Processed 1500/4696 POIs\n",
      "  Processed 1600/4696 POIs\n",
      "  Processed 1700/4696 POIs\n",
      "  Processed 1800/4696 POIs\n",
      "  Processed 1900/4696 POIs\n",
      "  Processed 2000/4696 POIs\n",
      "  Processed 2100/4696 POIs\n",
      "  Processed 2200/4696 POIs\n",
      "  Processed 2300/4696 POIs\n",
      "  Processed 2400/4696 POIs\n",
      "  Processed 2500/4696 POIs\n",
      "  Processed 2600/4696 POIs\n",
      "  Processed 2700/4696 POIs\n",
      "  Processed 2800/4696 POIs\n",
      "  Processed 2900/4696 POIs\n",
      "  Processed 3000/4696 POIs\n",
      "  Processed 3100/4696 POIs\n",
      "  Processed 3200/4696 POIs\n",
      "  Processed 3300/4696 POIs\n",
      "  Processed 3400/4696 POIs\n",
      "  Processed 3500/4696 POIs\n",
      "  Processed 3600/4696 POIs\n",
      "  Processed 3700/4696 POIs\n",
      "  Processed 3800/4696 POIs\n",
      "  Processed 3900/4696 POIs\n",
      "  Processed 4000/4696 POIs\n",
      "  Processed 4100/4696 POIs\n",
      "  Processed 4200/4696 POIs\n",
      "  Processed 4300/4696 POIs\n",
      "  Processed 4400/4696 POIs\n",
      "  Processed 4500/4696 POIs\n",
      "  Processed 4600/4696 POIs\n",
      "Graph G^0 constructed:\n",
      "  Nodes: 4696\n",
      "  Edges: 469182\n",
      "  Density: 0.0426\n",
      "  Avg degree: 199.82\n",
      "\n",
      "Building POI context graph G^1\n",
      "------------------------------------------------------------\n",
      "Number of POIs: 1355\n",
      "Computing co-search relationships...\n",
      "Computing co-visit relationships...\n",
      "Building edges...\n",
      "  Processed 100/1355 POIs\n",
      "  Processed 200/1355 POIs\n",
      "  Processed 300/1355 POIs\n",
      "  Processed 400/1355 POIs\n",
      "  Processed 500/1355 POIs\n",
      "  Processed 600/1355 POIs\n",
      "  Processed 700/1355 POIs\n",
      "  Processed 800/1355 POIs\n",
      "  Processed 900/1355 POIs\n",
      "  Processed 1000/1355 POIs\n",
      "  Processed 1100/1355 POIs\n",
      "  Processed 1200/1355 POIs\n",
      "  Processed 1300/1355 POIs\n",
      "Graph G^1 constructed:\n",
      "  Nodes: 1355\n",
      "  Edges: 40979\n",
      "  Density: 0.0447\n",
      "  Avg degree: 60.49\n",
      "\n",
      "Building POI context graph G^2\n",
      "------------------------------------------------------------\n",
      "Number of POIs: 44\n",
      "Computing co-search relationships...\n",
      "Computing co-visit relationships...\n",
      "Building edges...\n",
      "Graph G^2 constructed:\n",
      "  Nodes: 44\n",
      "  Edges: 65\n",
      "  Density: 0.0687\n",
      "  Avg degree: 2.95\n",
      "\n",
      "Building POI context graph G^3\n",
      "------------------------------------------------------------\n",
      "Number of POIs: 5\n",
      "Computing co-search relationships...\n",
      "Computing co-visit relationships...\n",
      "Building edges...\n",
      "Graph G^3 constructed:\n",
      "  Nodes: 5\n",
      "  Edges: 2\n",
      "  Density: 0.2000\n",
      "  Avg degree: 0.80\n",
      "\n",
      "Completed POI context graphs for levels: [0, 1, 2, 3]\n",
      "\n",
      "============================================================\n",
      "STEP 2D: Computing Graph-based Check-in Representations\n",
      "============================================================\n",
      "\n",
      "Computing U^0_g (Graph-based check-in matrix for level 0)\n",
      "------------------------------------------------------------\n",
      "Computing for 21 users × 4696 POIs\n",
      "  Processed 5/21 users\n",
      "  Processed 10/21 users\n",
      "  Processed 15/21 users\n",
      "  Processed 20/21 users\n",
      "U^0_g computed: shape (21, 4696, 86)\n",
      "\n",
      "Computing U^1_g (Graph-based check-in matrix for level 1)\n",
      "------------------------------------------------------------\n",
      "Computing for 21 users × 1355 POIs\n",
      "  Processed 5/21 users\n",
      "  Processed 10/21 users\n",
      "  Processed 15/21 users\n",
      "  Processed 20/21 users\n",
      "U^1_g computed: shape (21, 1355, 84)\n",
      "\n",
      "Computing U^2_g (Graph-based check-in matrix for level 2)\n",
      "------------------------------------------------------------\n",
      "Computing for 21 users × 44 POIs\n",
      "  Processed 5/21 users\n",
      "  Processed 10/21 users\n",
      "  Processed 15/21 users\n",
      "  Processed 20/21 users\n",
      "U^2_g computed: shape (21, 44, 84)\n",
      "\n",
      "Computing U^3_g (Graph-based check-in matrix for level 3)\n",
      "------------------------------------------------------------\n",
      "Computing for 21 users × 5 POIs\n",
      "  Processed 5/21 users\n",
      "  Processed 10/21 users\n",
      "  Processed 15/21 users\n",
      "  Processed 20/21 users\n",
      "U^3_g computed: shape (21, 5, 84)\n",
      "\n",
      "Completed graph-based check-in matrices for levels: [0, 1, 2, 3]\n",
      "\n",
      "============================================================\n",
      "Building Complete User & POI Representations\n",
      "============================================================\n",
      "\n",
      "Building complete representations for level 0\n",
      "------------------------------------------------------------\n",
      "P^0 shape: (21, 98)\n",
      "  X_A: 50 dims\n",
      "  X_T: 32 dims\n",
      "  Θ_u: 16 dims\n",
      "Q^0 shape: (4696, 86)\n",
      "  Y_A^0: 54 dims\n",
      "  Y_T^0: 32 dims\n",
      "\n",
      "Building complete representations for level 1\n",
      "------------------------------------------------------------\n",
      "P^1 shape: (21, 98)\n",
      "  X_A: 50 dims\n",
      "  X_T: 32 dims\n",
      "  Θ_u: 16 dims\n",
      "Q^1 shape: (1355, 170)\n",
      "  Y_A^1: 52 dims\n",
      "  Y_T^1: 32 dims\n",
      "  A^1_p: 86 dims\n",
      "\n",
      "Building complete representations for level 2\n",
      "------------------------------------------------------------\n",
      "P^2 shape: (21, 98)\n",
      "  X_A: 50 dims\n",
      "  X_T: 32 dims\n",
      "  Θ_u: 16 dims\n",
      "Q^2 shape: (44, 168)\n",
      "  Y_A^2: 52 dims\n",
      "  Y_T^2: 32 dims\n",
      "  A^2_p: 84 dims\n",
      "\n",
      "Building complete representations for level 3\n",
      "------------------------------------------------------------\n",
      "P^3 shape: (21, 98)\n",
      "  X_A: 50 dims\n",
      "  X_T: 32 dims\n",
      "  Θ_u: 16 dims\n",
      "Q^3 shape: (5, 168)\n",
      "  Y_A^3: 52 dims\n",
      "  Y_T^3: 32 dims\n",
      "  A^3_p: 84 dims\n",
      "\n",
      "============================================================\n",
      "Computing Feature-based Check-in Matrices\n",
      "============================================================\n",
      "\n",
      "Computing S^0 (Feature-based check-in matrix)\n",
      "------------------------------------------------------------\n",
      "S^0 shape: (21, 4696)\n",
      "  Min score: -38.9516\n",
      "  Max score: 375.2596\n",
      "  Mean score: 0.7387\n",
      "\n",
      "Computing S^1 (Feature-based check-in matrix)\n",
      "------------------------------------------------------------\n",
      "S^1 shape: (21, 1355)\n",
      "  Min score: -24.1651\n",
      "  Max score: 308.1379\n",
      "  Mean score: 0.3485\n",
      "\n",
      "Computing S^2 (Feature-based check-in matrix)\n",
      "------------------------------------------------------------\n",
      "S^2 shape: (21, 44)\n",
      "  Min score: -7.4975\n",
      "  Max score: 32.6224\n",
      "  Mean score: 0.6290\n",
      "\n",
      "Computing S^3 (Feature-based check-in matrix)\n",
      "------------------------------------------------------------\n",
      "S^3 shape: (21, 5)\n",
      "  Min score: -8.5953\n",
      "  Max score: 16.2637\n",
      "  Mean score: 0.7678\n",
      "\n",
      "============================================================\n",
      "All components saved to: interaction_learning.pkl\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "INTERACTION-BASED LEARNING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Generated components:\n",
      "  ✓ Θ_u: Trainable user parameters\n",
      "  ✓ A^l_p: Inter-level POI features (levels 1-3)\n",
      "  ✓ G^l: POI context graphs (levels 0-3)\n",
      "  ✓ U^l_g: Graph-based check-in matrices (levels 0-3)\n",
      "  ✓ P^l: Complete user representations (levels 0-3)\n",
      "  ✓ Q^l: Complete POI representations (levels 0-3)\n",
      "  ✓ S^l: Feature-based check-in matrices (levels 0-3)\n",
      "\n",
      "============================================================\n",
      "EXAMPLE: Recommendation Scores\n",
      "============================================================\n",
      "\n",
      "Top 10 POI recommendations for user Aiden:\n",
      "  1. CHICHA San Chen (score: 183.8928)\n",
      "  2. State Of Mind (score: 164.5533)\n",
      "  3. Unicorn Kampung 1200 (score: 156.7437)\n",
      "  4. iTea (score: 42.0443)\n",
      "  5. TA Community (score: 23.2200)\n",
      "  6. UOB (score: 6.1239)\n",
      "  7. UOB (score: 5.7824)\n",
      "  8. UOB (score: 5.7528)\n",
      "  9. UOB (score: 5.7516)\n",
      "  10. UOB (score: 5.6233)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"INTERACTION-BASED REPRESENTATION LEARNING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Initialize\n",
    "    learner = InteractionBasedRepresentationLearning(\n",
    "        embeddings_file='embeddings.pkl',\n",
    "        interactions_file='user_poi_interactions.csv',\n",
    "        poi_tree_file='poi_tree_with_uuids.json',\n",
    "        users_file='user_preferences.csv'\n",
    "    )\n",
    "    \n",
    "    # STEP 2A: Initialize trainable parameters\n",
    "    learner.initialize_trainable_parameters(\n",
    "        user_embedding_dim=16,\n",
    "        attention_hidden_dim=32\n",
    "    )\n",
    "    \n",
    "    # STEP 2B: Compute inter-level POI features with attention\n",
    "    learner.compute_all_inter_level_features(levels=[1, 2, 3])\n",
    "    \n",
    "    # STEP 2C: Build POI context graphs\n",
    "    learner.build_all_poi_context_graphs(levels=[0, 1, 2, 3])\n",
    "    \n",
    "    # STEP 2D: Compute graph-based check-in representations\n",
    "    learner.compute_all_graph_based_checkin_matrices(levels=[0, 1, 2, 3])\n",
    "    \n",
    "    # Build complete representations P^l and Q^l\n",
    "    learner.build_all_complete_representations(levels=[0, 1, 2, 3])\n",
    "    \n",
    "    # Compute feature-based check-in matrices S^l\n",
    "    learner.compute_all_feature_based_checkin_matrices(levels=[0, 1, 2, 3])\n",
    "    \n",
    "    # Save everything\n",
    "    learner.save_all('interaction_learning.pkl')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"INTERACTION-BASED LEARNING COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nGenerated components:\")\n",
    "    print(\"  ✓ Θ_u: Trainable user parameters\")\n",
    "    print(\"  ✓ A^l_p: Inter-level POI features (levels 1-3)\")\n",
    "    print(\"  ✓ G^l: POI context graphs (levels 0-3)\")\n",
    "    print(\"  ✓ U^l_g: Graph-based check-in matrices (levels 0-3)\")\n",
    "    print(\"  ✓ P^l: Complete user representations (levels 0-3)\")\n",
    "    print(\"  ✓ Q^l: Complete POI representations (levels 0-3)\")\n",
    "    print(\"  ✓ S^l: Feature-based check-in matrices (levels 0-3)\")\n",
    "    \n",
    "    # Example: Get recommendation scores for a user\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"EXAMPLE: Recommendation Scores\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    user_idx = 0\n",
    "    level = 0\n",
    "    \n",
    "    S_0 = learner.S_l['level_0']\n",
    "    user_scores = S_0[user_idx]  # Scores for all POIs\n",
    "    \n",
    "    # Top 10 recommendations\n",
    "    top_10_indices = np.argsort(user_scores)[-10:][::-1]\n",
    "    top_10_poi_ids = [learner.poi_embeddings['level_0']['poi_ids'][i] for i in top_10_indices]\n",
    "    \n",
    "    print(f\"\\nTop 10 POI recommendations for user {learner.users_df.iloc[user_idx]['name']}:\")\n",
    "    for rank, (poi_id, score) in enumerate(zip(top_10_poi_ids, user_scores[top_10_indices]), 1):\n",
    "        poi_name = learner.poi_tree['level_0'][poi_id]['name']\n",
    "        print(f\"  {rank}. {poi_name} (score: {score:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c93657f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
