{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a52b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.sparse import lil_matrix, csr_matrix, save_npz, diags\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b02bbd",
   "metadata": {},
   "source": [
    "### Step 1 : Extract User-POI interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c282c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_base_interaction_matrix(interactions_data, meta_data, level):\n",
    "    \"\"\"\n",
    "    Build base user-POI interaction matrix for a specific level\n",
    "    \"\"\"\n",
    "    # Get interaction data for this level\n",
    "    level_data = interactions_data['interactions'][level]\n",
    "    \n",
    "    # Get dimensions from the data itself\n",
    "    n_users = level_data['n_users']\n",
    "    n_pois = level_data['n_pois']\n",
    "    \n",
    "    print(f\"  {level}: {n_users} users × {n_pois} POIs\")\n",
    "    \n",
    "    # OPTION 1: Use pre-built matrix if available\n",
    "    if 'matrices' in level_data and 'interaction' in level_data['matrices']:\n",
    "        print(\"  Using pre-built interaction matrix\")\n",
    "        interaction_matrix = level_data['matrices']['interaction']\n",
    "        \n",
    "        # Ensure it's in CSR format\n",
    "        if not isinstance(interaction_matrix, csr_matrix):\n",
    "            interaction_matrix = csr_matrix(interaction_matrix)\n",
    "        \n",
    "        print(f\"  ✓ Matrix shape: {interaction_matrix.shape}\")\n",
    "        print(f\"  ✓ Non-zero interactions: {interaction_matrix.nnz}\")\n",
    "    \n",
    "    # OPTION 2: Build from edges\n",
    "    else:\n",
    "        print(\"  Building matrix from edges...\")\n",
    "        \n",
    "        # Create sparse matrix\n",
    "        interaction_matrix = lil_matrix((n_users, n_pois), dtype=np.float32)\n",
    "        \n",
    "        # Get edge data\n",
    "        edges = level_data['edges']\n",
    "        user_indices = edges['user_indices']  # Already integer indices!\n",
    "        poi_indices = edges['poi_indices']    # Already integer indices!\n",
    "        weights = edges.get('weights', None)\n",
    "        \n",
    "        print(f\"  Processing {len(user_indices)} edges\")\n",
    "        \n",
    "        # Fill the matrix\n",
    "        if weights is not None:\n",
    "            for user_idx, poi_idx, weight in zip(user_indices, poi_indices, weights):\n",
    "                interaction_matrix[user_idx, poi_idx] += weight\n",
    "        else:\n",
    "            for user_idx, poi_idx in zip(user_indices, poi_indices):\n",
    "                interaction_matrix[user_idx, poi_idx] += 1.0\n",
    "        \n",
    "        # Convert to CSR\n",
    "        interaction_matrix = interaction_matrix.tocsr()\n",
    "        print(f\"  ✓ Matrix shape: {interaction_matrix.shape}\")\n",
    "        print(f\"  ✓ Non-zero interactions: {interaction_matrix.nnz}\")\n",
    "    \n",
    "    # Get ordered IDs\n",
    "    user_ids = meta_data['user_ids']\n",
    "    level_num = int(level.split('_')[1])\n",
    "    poi_ids = meta_data['poi_ids'][level_num]\n",
    "    \n",
    "    return interaction_matrix, user_ids, poi_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f605c0b8",
   "metadata": {},
   "source": [
    "### Step 2 : Graph-based POI Representation Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7c2516b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate_poi_representations_via_graph(poi_context_graph, poi_embeddings, poi_ids, \n",
    "                                            alpha=0.15, max_iter=10, tol=1e-4):\n",
    "    \"\"\"\n",
    "    Propagate POI representations through context graph\n",
    "    \n",
    "    Args:\n",
    "        poi_context_graph: NetworkX graph with edges between ALL POIs\n",
    "        poi_embeddings: (n_pois, d) embeddings for POIs at this level\n",
    "        poi_ids: List of POI IDs at this level\n",
    "        alpha: Restart probability (how much to weight original embeddings)\n",
    "        max_iter: Maximum iterations for propagation\n",
    "        tol: Convergence tolerance\n",
    "    \n",
    "    Returns:\n",
    "        G_l: Enhanced POI representations (n_pois, d)\n",
    "    \"\"\"\n",
    "    n_pois, d = poi_embeddings.shape\n",
    "    print(f\"Propagating {n_pois} POIs with dimension {d}\")\n",
    "    \n",
    "    # Create mapping from POI ID to index in this level\n",
    "    poi_id_to_idx = {poi_id: idx for idx, poi_id in enumerate(poi_ids)}\n",
    "    poi_ids_set = set(poi_ids)\n",
    "    \n",
    "    # Extract subgraph containing only POIs at this level\n",
    "    if hasattr(poi_context_graph, 'subgraph'):\n",
    "        # NetworkX graph\n",
    "        level_subgraph = poi_context_graph.subgraph(poi_ids_set)\n",
    "        n_edges = level_subgraph.number_of_edges()\n",
    "        \n",
    "        print(f\"    Found {n_edges} edges between POIs at this level\")\n",
    "        \n",
    "        if n_edges == 0:\n",
    "            print(\"    No edges found - returning original embeddings\")\n",
    "            return poi_embeddings\n",
    "        \n",
    "        # Build adjacency matrix for this level\n",
    "        A = lil_matrix((n_pois, n_pois), dtype=np.float32)\n",
    "        \n",
    "        for u, v, data in level_subgraph.edges(data=True):\n",
    "            if u in poi_id_to_idx and v in poi_id_to_idx:\n",
    "                u_idx = poi_id_to_idx[u]\n",
    "                v_idx = poi_id_to_idx[v]\n",
    "                weight = data.get('weight', 1.0)\n",
    "                A[u_idx, v_idx] = weight\n",
    "                A[v_idx, u_idx] = weight  # Symmetric\n",
    "        \n",
    "        A = A.tocsr()\n",
    "        \n",
    "    else:\n",
    "        print(\"Warning: Graph format not recognized, returning original embeddings\")\n",
    "        return poi_embeddings\n",
    "    \n",
    "    # Normalize adjacency matrix (row-wise)\n",
    "    row_sums = np.array(A.sum(axis=1)).flatten()\n",
    "    row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "    D_inv = diags(1.0 / row_sums)\n",
    "    A_norm = D_inv @ A\n",
    "    \n",
    "    # Iterative propagation\n",
    "    G_l = poi_embeddings.copy()\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        G_l_new = (1 - alpha) * (A_norm @ G_l) + alpha * poi_embeddings\n",
    "        \n",
    "        # Check convergence\n",
    "        delta = np.abs(G_l_new - G_l).max()\n",
    "        G_l = G_l_new\n",
    "        \n",
    "        if delta < tol:\n",
    "            print(f\"    Converged at iteration {iteration + 1}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"    Reached max iterations ({max_iter})\")\n",
    "    \n",
    "    return G_l\n",
    "\n",
    "\n",
    "def build_graph_enhanced_poi_matrix(poi_context_graph, poi_embeddings_data, \n",
    "                                    meta_data, level):\n",
    "    \"\"\"\n",
    "    Build graph-enhanced POI representation matrix G^l\n",
    "    FIXED: Use correct structure - embeddings matrix + poi_ids list\n",
    "    \"\"\"\n",
    "    level_num = int(level.split('_')[1])\n",
    "    \n",
    "    # Get POI embeddings for this level\n",
    "    level_embeddings = poi_embeddings_data['poi_embeddings'][level]\n",
    "    \n",
    "    # Extract the embeddings matrix and POI IDs\n",
    "    poi_embeddings = level_embeddings['embeddings']  # Shape: (n_pois, embedding_dim)\n",
    "    poi_ids_in_embeddings = level_embeddings['poi_ids']  # List of POI IDs in same order\n",
    "    \n",
    "    # Get POI IDs for this level from metadata (canonical order)\n",
    "    poi_ids = meta_data['poi_ids'][level_num]\n",
    "    \n",
    "    print(f\"  Building G^{level_num} with {len(poi_ids)} POIs\")\n",
    "    print(f\"  POI embeddings shape: {poi_embeddings.shape}\")\n",
    "    \n",
    "    # Create mapping from POI ID to embedding row index\n",
    "    poi_id_to_embedding_idx = {poi_id: idx for idx, poi_id in enumerate(poi_ids_in_embeddings)}\n",
    "    \n",
    "    # Reorder embeddings to match canonical POI order\n",
    "    ordered_embeddings = []\n",
    "    missing_count = 0\n",
    "    \n",
    "    for poi_id in poi_ids:\n",
    "        if poi_id in poi_id_to_embedding_idx:\n",
    "            idx = poi_id_to_embedding_idx[poi_id]\n",
    "            ordered_embeddings.append(poi_embeddings[idx])\n",
    "        else:\n",
    "            # POI not in embeddings, use zero vector\n",
    "            ordered_embeddings.append(np.zeros(poi_embeddings.shape[1]))\n",
    "            missing_count += 1\n",
    "    \n",
    "    ordered_embeddings = np.array(ordered_embeddings)\n",
    "    \n",
    "    if missing_count > 0:\n",
    "        print(f\"  Warning: {missing_count} POIs missing from embeddings (using zero vectors)\")\n",
    "    \n",
    "    print(f\"  Ordered embeddings shape: {ordered_embeddings.shape}\")\n",
    "    \n",
    "    # Propagate through graph\n",
    "    G_l = propagate_poi_representations_via_graph(\n",
    "        poi_context_graph, ordered_embeddings, poi_ids\n",
    "    )\n",
    "    \n",
    "    return G_l\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d892490",
   "metadata": {},
   "source": [
    "### Step 3 : Build User Representation w/ Explicit Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2d3e3d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_representation_matrix(base_interaction_matrix, user_embeddings_data,\n",
    "                                    meta_data, G_l, beta=0.5):\n",
    "    \"\"\"\n",
    "    Build user representation matrix U^l\n",
    "    \"\"\"\n",
    "    n_users = base_interaction_matrix.shape[0]\n",
    "    d = G_l.shape[1]\n",
    "    \n",
    "    print(f\"  Building U matrix: {n_users} users, dimension {d}\")\n",
    "    \n",
    "    # Component 1: Interaction-based user representation\n",
    "    interaction_based = base_interaction_matrix @ G_l\n",
    "    \n",
    "    # Normalize by number of interactions per user\n",
    "    user_interaction_counts = np.array(\n",
    "        base_interaction_matrix.sum(axis=1)\n",
    "    ).flatten()\n",
    "    user_interaction_counts[user_interaction_counts == 0] = 1\n",
    "    \n",
    "    interaction_based = interaction_based / user_interaction_counts[:, np.newaxis]\n",
    "    \n",
    "    print(f\"  Interaction-based representation shape: {interaction_based.shape}\")\n",
    "    \n",
    "    # Component 2: Explicit user attributes\n",
    "    # Check structure of user_embeddings_data\n",
    "    if 'user_embeddings' in user_embeddings_data:\n",
    "        user_emb_data = user_embeddings_data['user_embeddings']\n",
    "        \n",
    "        # Check if it has the same structure as POI embeddings\n",
    "        if isinstance(user_emb_data, dict) and 'embeddings' in user_emb_data:\n",
    "            # Same structure as POI embeddings\n",
    "            user_embeddings = user_emb_data['embeddings']\n",
    "            user_ids_in_embeddings = user_emb_data['user_ids']\n",
    "            \n",
    "            # Create mapping\n",
    "            user_id_to_embedding_idx = {user_id: idx for idx, user_id in enumerate(user_ids_in_embeddings)}\n",
    "            \n",
    "            # Reorder to match canonical user order\n",
    "            ordered_user_embeddings = []\n",
    "            missing_count = 0\n",
    "            \n",
    "            for user_id in meta_data['user_ids']:\n",
    "                if user_id in user_id_to_embedding_idx:\n",
    "                    idx = user_id_to_embedding_idx[user_id]\n",
    "                    ordered_user_embeddings.append(user_embeddings[idx])\n",
    "                else:\n",
    "                    ordered_user_embeddings.append(np.zeros(user_embeddings.shape[1]))\n",
    "                    missing_count += 1\n",
    "            \n",
    "            user_explicit_embeddings = np.array(ordered_user_embeddings)\n",
    "            \n",
    "            if missing_count > 0:\n",
    "                print(f\"  Warning: {missing_count} users missing from embeddings\")\n",
    "        \n",
    "        elif isinstance(user_emb_data, np.ndarray):\n",
    "            # Direct array\n",
    "            user_explicit_embeddings = user_emb_data\n",
    "        \n",
    "        else:\n",
    "            # Dictionary mapping user_id -> embedding\n",
    "            user_explicit_embeddings = []\n",
    "            missing_count = 0\n",
    "            \n",
    "            for user_id in meta_data['user_ids']:\n",
    "                if user_id in user_emb_data:\n",
    "                    user_explicit_embeddings.append(user_emb_data[user_id])\n",
    "                else:\n",
    "                    # Get dimension from first user\n",
    "                    sample_user = list(user_emb_data.keys())[0]\n",
    "                    user_dim = len(user_emb_data[sample_user])\n",
    "                    user_explicit_embeddings.append(np.zeros(user_dim))\n",
    "                    missing_count += 1\n",
    "            \n",
    "            user_explicit_embeddings = np.array(user_explicit_embeddings)\n",
    "            \n",
    "            if missing_count > 0:\n",
    "                print(f\"  Warning: {missing_count} users missing from embeddings\")\n",
    "    \n",
    "    else:\n",
    "        # No user embeddings, use zero vectors\n",
    "        print(\"  No user embeddings found, using zero vectors\")\n",
    "        user_explicit_embeddings = np.zeros((n_users, d))\n",
    "    \n",
    "    print(f\"  User explicit embeddings shape: {user_explicit_embeddings.shape}\")\n",
    "    \n",
    "    # Ensure dimensions match\n",
    "    if user_explicit_embeddings.shape[1] != d:\n",
    "        print(f\"  Projecting user embeddings from {user_explicit_embeddings.shape[1]} to {d}\")\n",
    "        # Simple linear projection\n",
    "        projection = np.random.randn(user_explicit_embeddings.shape[1], d) * 0.01\n",
    "        user_explicit_embeddings = user_explicit_embeddings @ projection\n",
    "    \n",
    "    # Combine both components\n",
    "    U_l = beta * interaction_based + (1 - beta) * user_explicit_embeddings\n",
    "    \n",
    "    print(f\"  Final U^l shape: {U_l.shape}\")\n",
    "    \n",
    "    return U_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593fa798",
   "metadata": {},
   "source": [
    "### Step 4 : Compute Historical Check-in Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c21333ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_historical_checkin_matrix(U_l, G_l):\n",
    "    \"\"\"\n",
    "    Compute H^l = U^l · (G^l)^T\n",
    "    \"\"\"\n",
    "    H_l = U_l @ G_l.T\n",
    "    return H_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb7cd9",
   "metadata": {},
   "source": [
    "### Step 5 : Build Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a01325f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_complete_historical_checkin_pipeline(interactions_data, meta_data, \n",
    "                                                poi_embeddings_data, user_embeddings_data,\n",
    "                                                poi_context_graph):\n",
    "    \"\"\"\n",
    "    Complete pipeline - FULLY CORRECTED for edge-based interaction data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"BUILDING HISTORICAL CHECK-IN MATRICES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {\n",
    "        'base_matrices': {},\n",
    "        'G_matrices': {},\n",
    "        'U_matrices': {},\n",
    "        'H_matrices': {},\n",
    "        'poi_ids': {},\n",
    "        'user_ids': meta_data['user_ids']\n",
    "    }\n",
    "    \n",
    "    for level in ['level_0', 'level_1', 'level_2', 'level_3']:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Processing {level}...\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Step 1: Base interaction matrix\n",
    "        print(\"Step 1: Building base interaction matrix...\")\n",
    "        base_matrix, user_ids, poi_ids = build_base_interaction_matrix(\n",
    "            interactions_data, meta_data, level\n",
    "        )\n",
    "        results['base_matrices'][level] = base_matrix\n",
    "        results['poi_ids'][level] = poi_ids\n",
    "        print(f\"  ✓ Base matrix shape: {base_matrix.shape}\")\n",
    "        print(f\"  ✓ Non-zero interactions: {base_matrix.nnz}\")\n",
    "        print(f\"  ✓ Density: {base_matrix.nnz / (base_matrix.shape[0] * base_matrix.shape[1]):.6f}\")\n",
    "        \n",
    "        # Step 2: Graph-enhanced POI representations\n",
    "        print(\"\\nStep 2: Building graph-enhanced POI matrix G^l...\")\n",
    "        G_l = build_graph_enhanced_poi_matrix(\n",
    "            poi_context_graph, poi_embeddings_data, meta_data, level\n",
    "        )\n",
    "        results['G_matrices'][level] = G_l\n",
    "        print(f\"  ✓ G^l shape: {G_l.shape}\")\n",
    "        \n",
    "        # Step 3: User representation matrix\n",
    "        print(\"\\nStep 3: Building user representation matrix U^l...\")\n",
    "        U_l = build_user_representation_matrix(\n",
    "            base_matrix, user_embeddings_data, meta_data, G_l\n",
    "        )\n",
    "        results['U_matrices'][level] = U_l\n",
    "        print(f\"  ✓ U^l shape: {U_l.shape}\")\n",
    "        \n",
    "        # Step 4: Historical check-in matrix\n",
    "        print(\"\\nStep 4: Computing historical check-in matrix H^l...\")\n",
    "        H_l = compute_historical_checkin_matrix(U_l, G_l)\n",
    "        results['H_matrices'][level] = H_l\n",
    "        print(f\"  ✓ H^l shape: {H_l.shape}\")\n",
    "        print(f\"  ✓ H^l stats: min={H_l.min():.4f}, max={H_l.max():.4f}, mean={H_l.mean():.4f}\")\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"Saving results...\")\n",
    "    with open('historical_checkin_matrices.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'H_matrices': results['H_matrices'],\n",
    "            'U_matrices': results['U_matrices'],\n",
    "            'G_matrices': results['G_matrices'],\n",
    "            'base_matrices': results['base_matrices'],\n",
    "            'poi_ids': results['poi_ids'],\n",
    "            'user_ids': results['user_ids'],\n",
    "            'metadata': {\n",
    "                'formula': 'H^l = U^l · (G^l)^T',\n",
    "                'U_l_components': ['interaction_based', 'explicit_user_attributes'],\n",
    "                'G_l_components': ['explicit_poi_embeddings', 'graph_propagation'],\n",
    "                'created_at': str(np.datetime64('now'))\n",
    "            }\n",
    "        }, f)\n",
    "    \n",
    "    print(\"✓ Saved to 'historical_checkin_matrices.pkl'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(\"PIPELINE COMPLETE!\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "437a2488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Testing POI embeddings structure...\n",
      "======================================================================\n",
      "\n",
      "Testing level_0:\n",
      "  Building G^0 with 4696 POIs\n",
      "  POI embeddings shape: (4696, 221)\n",
      "  Ordered embeddings shape: (4696, 221)\n",
      "Propagating 4696 POIs with dimension 221\n",
      "    Found 0 edges between POIs at this level\n",
      "    No edges found - returning original embeddings\n",
      "✓ G^l shape: (4696, 221)\n",
      "✓ G^l stats: min=-7.7627, max=64.9592, mean=0.0289\n",
      "\n",
      "======================================================================\n",
      "Testing user representation matrix...\n",
      "======================================================================\n",
      "  level_0: 21 users × 4696 POIs\n",
      "  Using pre-built interaction matrix\n",
      "  ✓ Matrix shape: (21, 4696)\n",
      "  ✓ Non-zero interactions: 257\n",
      "\n",
      "Base matrix: (21, 4696)\n",
      "  Building U matrix: 21 users, dimension 221\n",
      "  Interaction-based representation shape: (21, 221)\n",
      "  User explicit embeddings shape: (21, 71)\n",
      "  Projecting user embeddings from 71 to 221\n",
      "  Final U^l shape: (21, 221)\n",
      "✓ U^l shape: (21, 221)\n",
      "======================================================================\n",
      "ANALYZING POI CONTEXT GRAPH FOR EACH LEVEL\n",
      "======================================================================\n",
      "======================================================================\n",
      "BUILDING HISTORICAL CHECK-IN MATRICES\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing level_0...\n",
      "======================================================================\n",
      "Step 1: Building base interaction matrix...\n",
      "  level_0: 21 users × 4696 POIs\n",
      "  Using pre-built interaction matrix\n",
      "  ✓ Matrix shape: (21, 4696)\n",
      "  ✓ Non-zero interactions: 257\n",
      "  ✓ Base matrix shape: (21, 4696)\n",
      "  ✓ Non-zero interactions: 257\n",
      "  ✓ Density: 0.002606\n",
      "\n",
      "Step 2: Building graph-enhanced POI matrix G^l...\n",
      "  Building G^0 with 4696 POIs\n",
      "  POI embeddings shape: (4696, 221)\n",
      "  Ordered embeddings shape: (4696, 221)\n",
      "Propagating 4696 POIs with dimension 221\n",
      "    Found 0 edges between POIs at this level\n",
      "    No edges found - returning original embeddings\n",
      "  ✓ G^l shape: (4696, 221)\n",
      "\n",
      "Step 3: Building user representation matrix U^l...\n",
      "  Building U matrix: 21 users, dimension 221\n",
      "  Interaction-based representation shape: (21, 221)\n",
      "  User explicit embeddings shape: (21, 71)\n",
      "  Projecting user embeddings from 71 to 221\n",
      "  Final U^l shape: (21, 221)\n",
      "  ✓ U^l shape: (21, 221)\n",
      "\n",
      "Step 4: Computing historical check-in matrix H^l...\n",
      "  ✓ H^l shape: (21, 4696)\n",
      "  ✓ H^l stats: min=-93.1698, max=975.8209, mean=0.4965\n",
      "\n",
      "======================================================================\n",
      "Processing level_1...\n",
      "======================================================================\n",
      "Step 1: Building base interaction matrix...\n",
      "  level_1: 21 users × 1355 POIs\n",
      "  Using pre-built interaction matrix\n",
      "  ✓ Matrix shape: (21, 1355)\n",
      "  ✓ Non-zero interactions: 231\n",
      "  ✓ Base matrix shape: (21, 1355)\n",
      "  ✓ Non-zero interactions: 231\n",
      "  ✓ Density: 0.008118\n",
      "\n",
      "Step 2: Building graph-enhanced POI matrix G^l...\n",
      "  Building G^1 with 1355 POIs\n",
      "  POI embeddings shape: (1355, 171)\n",
      "  Ordered embeddings shape: (1355, 171)\n",
      "Propagating 1355 POIs with dimension 171\n",
      "    Found 0 edges between POIs at this level\n",
      "    No edges found - returning original embeddings\n",
      "  ✓ G^l shape: (1355, 171)\n",
      "\n",
      "Step 3: Building user representation matrix U^l...\n",
      "  Building U matrix: 21 users, dimension 171\n",
      "  Interaction-based representation shape: (21, 171)\n",
      "  User explicit embeddings shape: (21, 71)\n",
      "  Projecting user embeddings from 71 to 171\n",
      "  Final U^l shape: (21, 171)\n",
      "  ✓ U^l shape: (21, 171)\n",
      "\n",
      "Step 4: Computing historical check-in matrix H^l...\n",
      "  ✓ H^l shape: (21, 1355)\n",
      "  ✓ H^l stats: min=-37.1084, max=745.2852, mean=0.2621\n",
      "\n",
      "======================================================================\n",
      "Processing level_2...\n",
      "======================================================================\n",
      "Step 1: Building base interaction matrix...\n",
      "  level_2: 21 users × 44 POIs\n",
      "  Using pre-built interaction matrix\n",
      "  ✓ Matrix shape: (21, 44)\n",
      "  ✓ Non-zero interactions: 180\n",
      "  ✓ Base matrix shape: (21, 44)\n",
      "  ✓ Non-zero interactions: 180\n",
      "  ✓ Density: 0.194805\n",
      "\n",
      "Step 2: Building graph-enhanced POI matrix G^l...\n",
      "  Building G^2 with 44 POIs\n",
      "  POI embeddings shape: (44, 125)\n",
      "  Ordered embeddings shape: (44, 125)\n",
      "Propagating 44 POIs with dimension 125\n",
      "    Found 0 edges between POIs at this level\n",
      "    No edges found - returning original embeddings\n",
      "  ✓ G^l shape: (44, 125)\n",
      "\n",
      "Step 3: Building user representation matrix U^l...\n",
      "  Building U matrix: 21 users, dimension 125\n",
      "  Interaction-based representation shape: (21, 125)\n",
      "  User explicit embeddings shape: (21, 71)\n",
      "  Projecting user embeddings from 71 to 125\n",
      "  Final U^l shape: (21, 125)\n",
      "  ✓ U^l shape: (21, 125)\n",
      "\n",
      "Step 4: Computing historical check-in matrix H^l...\n",
      "  ✓ H^l shape: (21, 44)\n",
      "  ✓ H^l stats: min=-10.3261, max=55.7467, mean=0.2648\n",
      "\n",
      "======================================================================\n",
      "Processing level_3...\n",
      "======================================================================\n",
      "Step 1: Building base interaction matrix...\n",
      "  level_3: 21 users × 5 POIs\n",
      "  Using pre-built interaction matrix\n",
      "  ✓ Matrix shape: (21, 5)\n",
      "  ✓ Non-zero interactions: 71\n",
      "  ✓ Base matrix shape: (21, 5)\n",
      "  ✓ Non-zero interactions: 71\n",
      "  ✓ Density: 0.676190\n",
      "\n",
      "Step 2: Building graph-enhanced POI matrix G^l...\n",
      "  Building G^3 with 5 POIs\n",
      "  POI embeddings shape: (5, 105)\n",
      "  Ordered embeddings shape: (5, 105)\n",
      "Propagating 5 POIs with dimension 105\n",
      "    Found 0 edges between POIs at this level\n",
      "    No edges found - returning original embeddings\n",
      "  ✓ G^l shape: (5, 105)\n",
      "\n",
      "Step 3: Building user representation matrix U^l...\n",
      "  Building U matrix: 21 users, dimension 105\n",
      "  Interaction-based representation shape: (21, 105)\n",
      "  User explicit embeddings shape: (21, 71)\n",
      "  Projecting user embeddings from 71 to 105\n",
      "  Final U^l shape: (21, 105)\n",
      "  ✓ U^l shape: (21, 105)\n",
      "\n",
      "Step 4: Computing historical check-in matrix H^l...\n",
      "  ✓ H^l shape: (21, 5)\n",
      "  ✓ H^l stats: min=-16.0223, max=17.3479, mean=0.2089\n",
      "\n",
      "======================================================================\n",
      "Saving results...\n",
      "✓ Saved to 'historical_checkin_matrices.pkl'\n",
      "======================================================================\n",
      "PIPELINE COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "\n",
      "level_0:\n",
      "  Original embedding stats:\n",
      "    Mean: 0.0289, Std: 0.4689\n",
      "  Enhanced embedding stats:\n",
      "    Mean: 0.0289, Std: 0.4689\n",
      "  Absolute difference:\n",
      "    Mean: 0.1098, Max: 64.9862\n",
      "  % of embeddings changed (>0.01): 100.0%\n",
      "\n",
      "======================================================================\n",
      "SUMMARY OF RESULTS\n",
      "======================================================================\n",
      "\n",
      "level_0:\n",
      "  H^l shape: (21, 4696)\n",
      "  Min score: -93.1698\n",
      "  Max score: 975.8209\n",
      "  Mean score: 0.4965\n",
      "  Std score: 24.1193\n",
      "\n",
      "level_1:\n",
      "  H^l shape: (21, 1355)\n",
      "  Min score: -37.1084\n",
      "  Max score: 745.2852\n",
      "  Mean score: 0.2621\n",
      "  Std score: 14.7483\n",
      "\n",
      "level_2:\n",
      "  H^l shape: (21, 44)\n",
      "  Min score: -10.3261\n",
      "  Max score: 55.7467\n",
      "  Mean score: 0.2648\n",
      "  Std score: 5.3351\n",
      "\n",
      "level_3:\n",
      "  H^l shape: (21, 5)\n",
      "  Min score: -16.0223\n",
      "  Max score: 17.3479\n",
      "  Mean score: 0.2089\n",
      "  Std score: 7.7630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_9352\\2655878462.py:3: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  interactions_data = pickle.load(f)\n",
      "C:\\Windows\\Temp\\ipykernel_9352\\2655878462.py:9: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  poi_embeddings_data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with open('../../Sources/Embeddings/interactions.pkl', 'rb') as f:\n",
    "        interactions_data = pickle.load(f)\n",
    "    \n",
    "    with open('../../Sources/Embeddings/metadata.pkl', 'rb') as f:\n",
    "        meta_data = pickle.load(f)\n",
    "        \n",
    "    with open('../../Sources/Embeddings/poi_embeddings.pkl', 'rb') as f:\n",
    "        poi_embeddings_data = pickle.load(f)\n",
    "        \n",
    "    with open('../../Sources/Embeddings/user_embeddings.pkl', 'rb') as f:\n",
    "        user_embeddings_data = pickle.load(f)\n",
    "        \n",
    "    with open('../../Sources/Embeddings/poi_context_graph.pkl', 'rb') as f:\n",
    "        poi_context_graph = pickle.load(f)\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"Testing POI embeddings structure...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Test build_graph_enhanced_poi_matrix\n",
    "    level = 'level_0'\n",
    "    print(f\"\\nTesting {level}:\")\n",
    "    G_l = build_graph_enhanced_poi_matrix(\n",
    "        poi_context_graph, poi_embeddings_data, meta_data, level\n",
    "    )\n",
    "    print(f\"✓ G^l shape: {G_l.shape}\")\n",
    "    print(f\"✓ G^l stats: min={G_l.min():.4f}, max={G_l.max():.4f}, mean={G_l.mean():.4f}\")\n",
    "\n",
    "    # Test with base interaction matrix\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"Testing user representation matrix...\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    base_matrix, user_ids, poi_ids = build_base_interaction_matrix(\n",
    "        interactions_data, meta_data, level\n",
    "    )\n",
    "    print(f\"\\nBase matrix: {base_matrix.shape}\")\n",
    "\n",
    "    U_l = build_user_representation_matrix(\n",
    "        base_matrix, user_embeddings_data, meta_data, G_l\n",
    "    )\n",
    "    print(f\"✓ U^l shape: {U_l.shape}\")\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"ANALYZING POI CONTEXT GRAPH FOR EACH LEVEL\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    results = build_complete_historical_checkin_pipeline(\n",
    "        interactions_data=interactions_data,\n",
    "        meta_data=meta_data,\n",
    "        poi_embeddings_data=poi_embeddings_data,\n",
    "        user_embeddings_data=user_embeddings_data,\n",
    "        poi_context_graph=poi_context_graph\n",
    "    )\n",
    "\n",
    "    # Get original embeddings\n",
    "    original_emb = poi_embeddings_data['poi_embeddings'][level]['embeddings']\n",
    "    \n",
    "    # Get graph-enhanced embeddings\n",
    "    enhanced_emb = results['G_matrices'][level]\n",
    "    \n",
    "    # Compute difference\n",
    "    diff = np.abs(enhanced_emb - original_emb)\n",
    "    \n",
    "    print(f\"\\n{level}:\")\n",
    "    print(f\"  Original embedding stats:\")\n",
    "    print(f\"    Mean: {original_emb.mean():.4f}, Std: {original_emb.std():.4f}\")\n",
    "    print(f\"  Enhanced embedding stats:\")\n",
    "    print(f\"    Mean: {enhanced_emb.mean():.4f}, Std: {enhanced_emb.std():.4f}\")\n",
    "    print(f\"  Absolute difference:\")\n",
    "    print(f\"    Mean: {diff.mean():.4f}, Max: {diff.max():.4f}\")\n",
    "    print(f\"  % of embeddings changed (>0.01): {(diff.max(axis=1) > 0.01).mean()*100:.1f}%\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SUMMARY OF RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    for level in ['level_0', 'level_1', 'level_2', 'level_3']:\n",
    "        H_l = results['H_matrices'][level]\n",
    "        print(f\"\\n{level}:\")\n",
    "        print(f\"  H^l shape: {H_l.shape}\")\n",
    "        print(f\"  Min score: {H_l.min():.4f}\")\n",
    "        print(f\"  Max score: {H_l.max():.4f}\")\n",
    "        print(f\"  Mean score: {H_l.mean():.4f}\")\n",
    "        print(f\"  Std score: {H_l.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8d61c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
