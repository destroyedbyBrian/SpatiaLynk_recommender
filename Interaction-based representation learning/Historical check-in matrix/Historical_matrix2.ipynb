{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a52a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "from scipy.sparse import csr_matrix, lil_matrix, diags\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28744536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_historical_matrices(\n",
    "    csv_path, \n",
    "    poi_tree_path, \n",
    "    poi_emb_path, \n",
    "    user_emb_path, \n",
    "    graph_path, \n",
    "    output_path\n",
    "):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LOADING DATA\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    print(f\"✓ Loaded {len(df)} interactions from CSV\")\n",
    "    \n",
    "    # Load POI Tree (for ID mapping poi_X_Name -> UUID)\n",
    "    with open(poi_tree_path, 'r') as f:\n",
    "        poi_tree = json.load(f)\n",
    "    \n",
    "    # Build mapping: poi_key -> uuid\n",
    "    poi_key_to_uuid = {}\n",
    "    uuid_to_level = {}\n",
    "    for level_key in poi_tree.keys():\n",
    "        if level_key.startswith('level_'):\n",
    "            level_num = int(level_key.split('_')[1])\n",
    "            for poi_key, poi_info in poi_tree[level_key].items():\n",
    "                if 'uuid' in poi_info:\n",
    "                    poi_key_to_uuid[poi_key] = poi_info['uuid']\n",
    "                    uuid_to_level[poi_info['uuid']] = level_num\n",
    "    \n",
    "    print(f\"✓ POI Tree: {len(poi_key_to_uuid)} POIs mapped\")\n",
    "    \n",
    "    # Load embeddings and graph\n",
    "    with open(poi_emb_path, 'rb') as f:\n",
    "        poi_emb_data = pickle.load(f)\n",
    "    \n",
    "    with open(user_emb_path, 'rb') as f:\n",
    "        user_emb_data = pickle.load(f)\n",
    "        X_A = user_emb_data['X_A']  # (n_users, 39)\n",
    "        X_T = user_emb_data['X_T']  # (n_users, 32)\n",
    "        U_explicit = np.concatenate([X_A, X_T], axis=1)\n",
    "        n_users = U_explicit.shape[0]\n",
    "        # Get user UUIDs\n",
    "        user_ids = user_emb_data.get('user_ids', [f\"user_{i}\" for i in range(n_users)])\n",
    "        user_to_idx = {uid: i for i, uid in enumerate(user_ids)}\n",
    "    \n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph_container = pickle.load(f)\n",
    "        G = graph_container.get('graph', graph_container) if isinstance(graph_container, dict) else graph_container\n",
    "    \n",
    "    print(f\"✓ Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "    print(f\"✓ Users: {n_users}\")\n",
    "    \n",
    "    # Filter CSV to valid users and POIs\n",
    "    print(\"\\nProcessing CSV...\")\n",
    "    \n",
    "    # Map user IDs\n",
    "    df['user_idx'] = df['user_id'].map(user_to_idx)\n",
    "    \n",
    "    # Map POI IDs (poi_X_Name -> UUID)\n",
    "    df['poi_uuid'] = df['poi_id'].map(poi_key_to_uuid)\n",
    "    \n",
    "    # Get level for each UUID\n",
    "    df['level'] = df['poi_uuid'].map(uuid_to_level)\n",
    "    \n",
    "    # Filter valid rows\n",
    "    valid_df = df[(df['user_idx'].notna()) & (df['poi_uuid'].notna())].copy()\n",
    "    valid_df['user_idx'] = valid_df['user_idx'].astype(int)\n",
    "    \n",
    "    print(f\"✓ Valid interactions: {len(valid_df)}/{len(df)}\")\n",
    "    print(f\"  Users: {valid_df['user_idx'].nunique()}\")\n",
    "    print(f\"  POIs: {valid_df['poi_uuid'].nunique()}\")\n",
    "    \n",
    "    # Group by level to create R^l matrices\n",
    "    results = {}\n",
    "    \n",
    "    for level in range(4):\n",
    "        level_key = f'level_{level}'\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Building Level {level} (G^{level})\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Get level-specific data\n",
    "        level_df = valid_df[valid_df['level'] == level]\n",
    "        \n",
    "        if level_df.empty:\n",
    "            print(f\"  No interactions for level {level}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Get POI info for this level\n",
    "        if level_key not in poi_emb_data['poi_embeddings']:\n",
    "            print(f\"  No embeddings for {level_key}, skipping\")\n",
    "            continue\n",
    "            \n",
    "        level_poi_data = poi_emb_data['poi_embeddings'][level_key]\n",
    "        poi_embeddings = level_poi_data['embeddings']\n",
    "        poi_ids = level_poi_data['poi_ids']\n",
    "        n_pois = len(poi_ids)\n",
    "        poi_to_idx = {pid: i for i, pid in enumerate(poi_ids)}\n",
    "        \n",
    "        print(f\"  POIs at level: {n_pois}\")\n",
    "        print(f\"  Interactions: {len(level_df)}\")\n",
    "        \n",
    "        # Step 1: Build R^l (Interaction Matrix)\n",
    "        print(\"  Building R^l (interaction matrix)...\")\n",
    "        \n",
    "        # Aggregate by user-POI pairs (sum visit values)\n",
    "        agg = level_df.groupby(['user_idx', 'poi_uuid'])['value'].sum().reset_index()\n",
    "        \n",
    "        # Map POI UUID to index\n",
    "        agg['poi_idx'] = agg['poi_uuid'].map(poi_to_idx)\n",
    "        agg = agg[agg['poi_idx'].notna()]\n",
    "        agg['poi_idx'] = agg['poi_idx'].astype(int)\n",
    "        \n",
    "        # Build sparse matrix\n",
    "        rows = agg['user_idx'].values\n",
    "        cols = agg['poi_idx'].values\n",
    "        data = agg['value'].values\n",
    "        \n",
    "        R = csr_matrix((data, (rows, cols)), shape=(n_users, n_pois))\n",
    "        print(f\"    R^{level} shape: {R.shape}, nnz: {R.nnz}, density: {R.nnz/(R.shape[0]*R.shape[1]):.4f}\")\n",
    "        \n",
    "        # Step 2: Propagate POI embeddings through graph (F^l)\n",
    "        print(\"  Propagating POI embeddings through graph...\")\n",
    "        \n",
    "        # Find which POIs are in graph\n",
    "        graph_nodes = set(G.nodes())\n",
    "        level_poi_set = set(poi_ids)\n",
    "        valid_pois = list(level_poi_set & graph_nodes)\n",
    "        \n",
    "        if len(valid_pois) > 0:\n",
    "            print(f\"    Graph coverage: {len(valid_pois)}/{n_pois} ({100*len(valid_pois)/n_pois:.1f}%)\")\n",
    "            \n",
    "            # Build subgraph adjacency\n",
    "            valid_indices = [poi_to_idx[p] for p in valid_pois]\n",
    "            subG = G.subgraph(valid_pois)\n",
    "            \n",
    "            # Local index mapping\n",
    "            valid_list = sorted(valid_pois)\n",
    "            local_idx = {p: i for i, p in enumerate(valid_list)}\n",
    "            \n",
    "            A = lil_matrix((len(valid_pois), len(valid_pois)))\n",
    "            for u, v, d in subG.edges(data=True):\n",
    "                if u in local_idx and v in local_idx:\n",
    "                    w = d.get('weight_normalized', d.get('weight', 1.0))\n",
    "                    A[local_idx[u], local_idx[v]] = w\n",
    "            \n",
    "            A = A.tocsr()\n",
    "            row_sums = np.array(A.sum(axis=1)).flatten()\n",
    "            row_sums[row_sums == 0] = 1\n",
    "            A_norm = diags(1.0/row_sums) @ A\n",
    "            \n",
    "            # Propagate\n",
    "            alpha = 0.15\n",
    "            F_valid = poi_embeddings[valid_indices]\n",
    "            F_prop = F_valid.copy()\n",
    "            \n",
    "            for it in range(10):\n",
    "                F_new = (1-alpha) * (A_norm @ F_prop) + alpha * F_valid\n",
    "                if np.abs(F_new - F_prop).max() < 1e-4:\n",
    "                    break\n",
    "                F_prop = F_new\n",
    "            \n",
    "            # Merge back\n",
    "            F_l = poi_embeddings.copy()\n",
    "            F_l[valid_indices] = F_prop\n",
    "        else:\n",
    "            print(f\"    No graph coverage, using original embeddings\")\n",
    "            F_l = poi_embeddings\n",
    "        \n",
    "        # Step 3: Build U^l (User representations)\n",
    "        print(\"  Building U^l (user representations)...\")\n",
    "        \n",
    "        beta = 0.5\n",
    "        \n",
    "        # Component 1: Interaction-based (R @ F normalized)\n",
    "        interaction_comp = R @ F_l\n",
    "        row_sums = np.array(R.sum(axis=1)).flatten()\n",
    "        row_sums[row_sums == 0] = 1\n",
    "        interaction_comp = interaction_comp / row_sums[:, np.newaxis]\n",
    "        \n",
    "        # Component 2: Project explicit user features to match dimension\n",
    "        if U_explicit.shape[1] != F_l.shape[1]:\n",
    "            # Simple linear projection (could use PCA or learned weights)\n",
    "            proj = np.random.randn(U_explicit.shape[1], F_l.shape[1]) * 0.01\n",
    "            U_proj = U_explicit @ proj\n",
    "        else:\n",
    "            U_proj = U_explicit\n",
    "        \n",
    "        U_l = beta * interaction_comp + (1 - beta) * U_proj\n",
    "        \n",
    "        # Step 4: Compute G^l = U^l @ F^l^T\n",
    "        print(\"  Computing G^l = U^l @ F^l^T...\")\n",
    "        G_l = U_l @ F_l.T\n",
    "        \n",
    "        print(f\"    G^{level} shape: {G_l.shape}\")\n",
    "        print(f\"    Stats: min={G_l.min():.2f}, max={G_l.max():.2f}, mean={G_l.mean():.2f}\")\n",
    "        \n",
    "        results[level_key] = {\n",
    "            'G_matrix': G_l,\n",
    "            'U_matrix': U_l,\n",
    "            'F_matrix': F_l,\n",
    "            'R_matrix': R,\n",
    "            'poi_ids': poi_ids,\n",
    "            'user_ids': user_ids\n",
    "        }\n",
    "    \n",
    "    # Save results\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"SAVING RESULTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    save_data = {\n",
    "        'G_matrices': {k: v['G_matrix'] for k, v in results.items()},\n",
    "        'U_matrices': {k: v['U_matrix'] for k, v in results.items()},\n",
    "        'F_matrices': {k: v['F_matrix'] for k, v in results.items()},\n",
    "        'R_matrices_sparse': {k: v['R_matrix'] for k, v in results.items()},\n",
    "        'metadata': {\n",
    "            'n_users': n_users,\n",
    "            'levels': list(results.keys()),\n",
    "            'formula': 'G^l = (beta*(R^l @ F^l / norm) + (1-beta)*U_explicit) @ F^l^T',\n",
    "            'beta': 0.5,\n",
    "            'alpha': 0.15\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'wb') as f:\n",
    "        pickle.dump(save_data, f)\n",
    "    \n",
    "    print(f\"✓ Saved to {output_path}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\nSUMMARY:\")\n",
    "    for level_key, data in results.items():\n",
    "        G = data['G_matrix']\n",
    "        R_density = data['R_matrix'].nnz / (data['R_matrix'].shape[0] * data['R_matrix'].shape[1])\n",
    "        print(f\"{level_key}: G∈{G.shape}, R density={R_density:.4f}, G range=[{G.min():.1f}, {G.max():.1f}]\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df414ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "✓ Loaded 567 interactions from CSV\n",
      "✓ POI Tree: 6100 POIs mapped\n",
      "✓ Graph: 235 nodes, 11471 edges\n",
      "✓ Users: 21\n",
      "\n",
      "Processing CSV...\n",
      "✓ Valid interactions: 567/567\n",
      "  Users: 21\n",
      "  POIs: 235\n",
      "\n",
      "======================================================================\n",
      "Building Level 0 (G^0)\n",
      "======================================================================\n",
      "  POIs at level: 4696\n",
      "  Interactions: 567\n",
      "  Building R^l (interaction matrix)...\n",
      "    R^0 shape: (21, 4696), nnz: 0, density: 0.0000\n",
      "  Propagating POI embeddings through graph...\n",
      "    No graph coverage, using original embeddings\n",
      "  Building U^l (user representations)...\n",
      "  Computing G^l = U^l @ F^l^T...\n",
      "    G^0 shape: (21, 4696)\n",
      "    Stats: min=-3.80, max=4.17, mean=0.01\n",
      "\n",
      "======================================================================\n",
      "Building Level 1 (G^1)\n",
      "======================================================================\n",
      "  No interactions for level 1, skipping\n",
      "\n",
      "======================================================================\n",
      "Building Level 2 (G^2)\n",
      "======================================================================\n",
      "  No interactions for level 2, skipping\n",
      "\n",
      "======================================================================\n",
      "Building Level 3 (G^3)\n",
      "======================================================================\n",
      "  No interactions for level 3, skipping\n",
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "✓ Saved to ../../Sources/Embeddings v3/historical_checkin_matrices.pkl\n",
      "\n",
      "SUMMARY:\n",
      "level_0: G∈(21, 4696), R density=0.0000, G range=[-3.8, 4.2]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = build_historical_matrices(\n",
    "        csv_path='../../Sources/Files/user_poi_interactions.csv',\n",
    "        poi_tree_path='../../Sources/Files/poi_tree_with_uuids.json',\n",
    "        poi_emb_path='../../Sources/Embeddings v3/poi_embeddings.pkl',\n",
    "        user_emb_path='../../Sources/Embeddings v3/user_embeddings.pkl',\n",
    "        graph_path='../../Sources/Embeddings v3/poi_context_graph.pkl',\n",
    "        output_path='../../Sources/Embeddings v3/historical_checkin_matrices.pkl'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d541412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
