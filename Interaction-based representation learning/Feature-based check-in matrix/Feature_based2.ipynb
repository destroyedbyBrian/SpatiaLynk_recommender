{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cd5ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pickle\n",
    "from typing import Dict, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5c54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureCheckInMatrix(nn.Module):\n",
    "    def __init__(self, \n",
    "\t\t\t\t\t\t\t\tlevel: int,\n",
    "\t\t\t\t\t\t\t\tX_A: np.ndarray,           # U_u: (n_users, d_Uu)\n",
    "\t\t\t\t\t\t\t\tX_T: np.ndarray,           # H^l_u: (n_users, d_Hu)\n",
    "\t\t\t\t\t\t\t\tY_A: np.ndarray,           # U^l_p: (n_pois, d_Up)\n",
    "\t\t\t\t\t\t\t\tY_T: np.ndarray,           # H^l_p: (n_pois, d_Hp)\n",
    "\t\t\t\t\t\t\t\tA_lp: np.ndarray,          # A^l_p: (n_pois, r_l) - inter-level features\n",
    "\t\t\t\t\t\t\t\tlatent_dim: Optional[int] = None,  # Projection dim if user/poi dims differ\n",
    "\t\t\t\t\t\t\t\tinit_std: float = 0.01):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.level = level\n",
    "        self.n_users = X_A.shape[0]\n",
    "        self.n_pois = Y_A.shape[0]\n",
    "        \n",
    "        # Register precomputed features as buffers (non-trainable)\n",
    "        self.register_buffer('X_A', torch.tensor(X_A, dtype=torch.float32))\n",
    "        self.register_buffer('X_T', torch.tensor(X_T, dtype=torch.float32))\n",
    "        self.register_buffer('Y_A', torch.tensor(Y_A, dtype=torch.float32))\n",
    "        self.register_buffer('Y_T', torch.tensor(Y_T, dtype=torch.float32))\n",
    "        self.register_buffer('A_lp', torch.tensor(A_lp, dtype=torch.float32))\n",
    "        \n",
    "        # Dimension of inter-level features (r_l)\n",
    "        self.r_l = A_lp.shape[1]\n",
    "        \n",
    "        # Trainable parameter: A^l (implicit user features to match A^l_p space)\n",
    "        # Shape: (n_users, r_l) - same second dimension as A^l_p\n",
    "        self.A_u = nn.Parameter(torch.randn(self.n_users, self.r_l) * init_std)\n",
    "        \n",
    "        # Calculate total dimensions\n",
    "        self.user_total_dim = X_A.shape[1] + X_T.shape[1] + self.r_l\n",
    "        self.poi_total_dim = Y_A.shape[1] + Y_T.shape[1] + self.r_l\n",
    "        \n",
    "        print(f\"[Level {level}] Initializing FeatureCheckInMatrix:\")\n",
    "        print(f\"  P^l components: U_u({X_A.shape[1]}) || H^l_u({X_T.shape[1]}) || A^l({self.r_l}) = {self.user_total_dim}\")\n",
    "        print(f\"  Q^l components: U_p({Y_A.shape[1]}) || H^l_p({Y_T.shape[1]}) || A^l_p({self.r_l}) = {self.poi_total_dim}\")\n",
    "        \n",
    "        # Handle dimension mismatch via projection layers\n",
    "        if self.user_total_dim != self.poi_total_dim:\n",
    "            if latent_dim is None:\n",
    "                # Auto-select latent dim as max of the two, or you can set manually\n",
    "                latent_dim = max(self.user_total_dim, self.poi_total_dim)\n",
    "                print(f\"  ⚠️ Dimension mismatch detected. Projecting both to dim {latent_dim}\")\n",
    "            else:\n",
    "                print(f\"  Projecting to latent dim {latent_dim}\")\n",
    "            \n",
    "            self.W_user = nn.Linear(self.user_total_dim, latent_dim)\n",
    "            self.W_poi = nn.Linear(self.poi_total_dim, latent_dim)\n",
    "            self.latent_dim = latent_dim\n",
    "            self.use_projection = True\n",
    "        else:\n",
    "            self.latent_dim = self.user_total_dim\n",
    "            self.use_projection = False\n",
    "            print(f\"  ✓ Dimensions match: {self.user_total_dim}\")\n",
    "            \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "    def get_P_l(self, user_indices: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        if user_indices is None:\n",
    "            X_A_batch = self.X_A\n",
    "            X_T_batch = self.X_T\n",
    "            A_u_batch = self.A_u\n",
    "        else:\n",
    "            X_A_batch = self.X_A[user_indices]\n",
    "            X_T_batch = self.X_T[user_indices]\n",
    "            A_u_batch = self.A_u[user_indices]\n",
    "            \n",
    "        # Concatenate: [Explicit || Implicit || Trainable]\n",
    "        P_l = torch.cat([X_A_batch, X_T_batch, A_u_batch], dim=-1)\n",
    "        return P_l\n",
    "    \n",
    "    def get_Q_l(self, poi_indices: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        if poi_indices is None:\n",
    "            Y_A_batch = self.Y_A\n",
    "            Y_T_batch = self.Y_T\n",
    "            A_lp_batch = self.A_lp\n",
    "        else:\n",
    "            Y_A_batch = self.Y_A[poi_indices]\n",
    "            Y_T_batch = self.Y_T[poi_indices]\n",
    "            A_lp_batch = self.A_lp[poi_indices]\n",
    "            \n",
    "        # Concatenate: [Explicit || Implicit || Inter-level]\n",
    "        Q_l = torch.cat([Y_A_batch, Y_T_batch, A_lp_batch], dim=-1)\n",
    "        return Q_l\n",
    "    \n",
    "    def project_to_latent(self, P_l: torch.Tensor, Q_l: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Apply projection layers if dimensions differ\"\"\"\n",
    "        if self.use_projection:\n",
    "            P_proj = self.W_user(P_l)\n",
    "            Q_proj = self.W_poi(Q_l)\n",
    "            return P_proj, Q_proj\n",
    "        return P_l, Q_l\n",
    "    \n",
    "    def forward(self, user_indices: torch.Tensor, poi_indices: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute scores for specific user-POI pairs (batch mode)\n",
    "        \n",
    "        Args:\n",
    "            user_indices: (batch_size,) tensor of user indices\n",
    "            poi_indices: (batch_size,) tensor of poi indices\n",
    "            \n",
    "        Returns:\n",
    "            scores: (batch_size,) similarity scores\n",
    "        \"\"\"\n",
    "        # Get representations\n",
    "        P_l = self.get_P_l(user_indices)    # (batch, user_total_dim)\n",
    "        Q_l = self.get_Q_l(poi_indices)     # (batch, poi_total_dim)\n",
    "        \n",
    "        # Project if needed\n",
    "        P_proj, Q_proj = self.project_to_latent(P_l, Q_l)\n",
    "        \n",
    "        # Apply dropout\n",
    "        P_proj = self.dropout(P_proj)\n",
    "        Q_proj = self.dropout(Q_proj)\n",
    "        \n",
    "        # Compute dot product for each pair: sum over latent dim\n",
    "        scores = torch.sum(P_proj * Q_proj, dim=1)  # (batch,)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def compute_matrix(self, batch_size: int = 512) -> torch.Tensor:\n",
    "        self.eval()\n",
    "        S_l_chunks = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Process users in batches to avoid memory issues\n",
    "            for i in range(0, self.n_users, batch_size):\n",
    "                end_i = min(i + batch_size, self.n_users)\n",
    "                \n",
    "                # Get P^l for this user batch\n",
    "                user_idx = torch.arange(i, end_i)\n",
    "                P_l = self.get_P_l(user_idx)  # (batch, user_total_dim)\n",
    "                \n",
    "                if self.use_projection:\n",
    "                    P_proj = self.W_user(P_l)  # (batch, latent_dim)\n",
    "                else:\n",
    "                    P_proj = P_l\n",
    "                \n",
    "                # Get full Q^l\n",
    "                Q_l = self.get_Q_l()  # (n_pois, poi_total_dim)\n",
    "                \n",
    "                if self.use_projection:\n",
    "                    Q_proj = self.W_poi(Q_l)  # (n_pois, latent_dim)\n",
    "                else:\n",
    "                    Q_proj = Q_l\n",
    "                \n",
    "                # Compute batch of S^l: (batch, latent) @ (latent, n_pois) -> (batch, n_pois)\n",
    "                S_batch = torch.matmul(P_proj, Q_proj.t())\n",
    "                S_l_chunks.append(S_batch.cpu())\n",
    "                \n",
    "        S_l = torch.cat(S_l_chunks, dim=0)\n",
    "        return S_l\n",
    "    \n",
    "    def get_top_k(self, user_idx: int, k: int = 10) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Get top-k POI recommendations for a specific user\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Compute scores for this user against all POIs\n",
    "            user_tensor = torch.tensor([user_idx])\n",
    "            all_pois = torch.arange(self.n_pois)\n",
    "            \n",
    "            # Batch compute to avoid memory issues if n_pois is large\n",
    "            scores_list = []\n",
    "            batch_size = 1024\n",
    "            for i in range(0, self.n_pois, batch_size):\n",
    "                end_i = min(i + batch_size, self.n_pois)\n",
    "                poi_batch = torch.arange(i, end_i)\n",
    "                user_batch = user_tensor.repeat(end_i - i)\n",
    "                \n",
    "                batch_scores = self.forward(user_batch, poi_batch)\n",
    "                scores_list.append(batch_scores)\n",
    "                \n",
    "            scores = torch.cat(scores_list)\n",
    "            top_scores, top_indices = torch.topk(scores, k)\n",
    "            \n",
    "        return top_scores, top_indices\n",
    "\n",
    "\n",
    "def load_and_initialize_level(level: int, \n",
    "                              user_emb_path: str,\n",
    "                              poi_emb_path: str, \n",
    "                              interlevel_path: str,\n",
    "                              latent_dim: Optional[int] = None) -> FeatureCheckInMatrix:\n",
    "    level_key = f'level_{level}'\n",
    "    \n",
    "    # Load user features (U_u and H^l_u)\n",
    "    with open(user_emb_path, 'rb') as f:\n",
    "        user_data = pickle.load(f)\n",
    "        X_A = user_data['X_A']  # Explicit\n",
    "        X_T = user_data['X_T']  # Implicit\n",
    "        \n",
    "    # Load POI explicit/implicit features (U^l_p and H^l_p)\n",
    "    with open(poi_emb_path, 'rb') as f:\n",
    "        poi_data = pickle.load(f)\n",
    "        Y_A = poi_data['poi_embeddings'][level_key]['Y_A']\n",
    "        Y_T = poi_data['poi_embeddings'][level_key]['Y_T']\n",
    "        \n",
    "    # Load inter-level features A^l_p\n",
    "    with open(interlevel_path, 'rb') as f:\n",
    "        inter_data = pickle.load(f)\n",
    "        A_lp = inter_data['A_lp'][level_key]\n",
    "        \n",
    "    # Initialize model\n",
    "    model = FeatureCheckInMatrix(\n",
    "        level=level,\n",
    "        X_A=X_A,\n",
    "        X_T=X_T,\n",
    "        Y_A=Y_A,\n",
    "        Y_T=Y_T,\n",
    "        A_lp=A_lp,\n",
    "        latent_dim=latent_dim\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f5f84f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    user_emb_path = \"../../Sources/Embeddings v3/user_embeddings.pkl\"\n",
    "    poi_emb_path = \"../../Sources/Embeddings v3/poi_embeddings.pkl\"\n",
    "    interlevel_path = \"../../Sources/Embeddings v3/poi_interlevel_features.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632442aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Initializing Level 0...\n",
      "[Level 0] Initializing FeatureCheckInMatrix:\n",
      "  P^l components: U_u(39) || H^l_u(32) || A^l(221) = 292\n",
      "  Q^l components: U_p(149) || H^l_p(72) || A^l_p(221) = 442\n",
      "  Projecting to latent dim 256\n",
      "Computing S^0...\n",
      "S^0 shape: torch.Size([21, 4696])\n",
      "S^0 stats: μ=-0.040, σ=0.873, range=[-16.763, 26.042]\n",
      "\n",
      "============================================================\n",
      "Initializing Level 1...\n",
      "[Level 1] Initializing FeatureCheckInMatrix:\n",
      "  P^l components: U_u(39) || H^l_u(32) || A^l(171) = 242\n",
      "  Q^l components: U_p(99) || H^l_p(72) || A^l_p(171) = 342\n",
      "  Projecting to latent dim 256\n",
      "Computing S^1...\n",
      "S^1 shape: torch.Size([21, 1355])\n",
      "S^1 stats: μ=0.032, σ=1.082, range=[-14.222, 20.153]\n",
      "\n",
      "============================================================\n",
      "Initializing Level 2...\n",
      "[Level 2] Initializing FeatureCheckInMatrix:\n",
      "  P^l components: U_u(39) || H^l_u(32) || A^l(125) = 196\n",
      "  Q^l components: U_p(53) || H^l_p(72) || A^l_p(125) = 250\n",
      "  Projecting to latent dim 256\n",
      "Computing S^2...\n",
      "S^2 shape: torch.Size([21, 44])\n",
      "S^2 stats: μ=-0.072, σ=1.503, range=[-7.142, 6.339]\n",
      "\n",
      "============================================================\n",
      "Initializing Level 3...\n",
      "[Level 3] Initializing FeatureCheckInMatrix:\n",
      "  P^l components: U_u(39) || H^l_u(32) || A^l(105) = 176\n",
      "  Q^l components: U_p(33) || H^l_p(72) || A^l_p(105) = 210\n",
      "  Projecting to latent dim 256\n",
      "Computing S^3...\n",
      "S^3 shape: torch.Size([21, 5])\n",
      "S^3 stats: μ=-0.016, σ=1.766, range=[-5.328, 4.270]\n"
     ]
    }
   ],
   "source": [
    "def initialize_all_levels(user_emb_path, poi_emb_path, interlevel_path, latent_dim=256):\n",
    "    \"\"\"Initialize FeatureCheckInMatrix for all 4 levels\"\"\"\n",
    "    models = {}\n",
    "    S_matrices = {}\n",
    "    \n",
    "    for level in range(4):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Initializing Level {level}...\")\n",
    "        \n",
    "        model = load_and_initialize_level(\n",
    "            level=level,\n",
    "            user_emb_path=user_emb_path,\n",
    "            poi_emb_path=poi_emb_path,\n",
    "            interlevel_path=interlevel_path,\n",
    "            latent_dim=latent_dim\n",
    "        )\n",
    "        \n",
    "        # Compute S^l immediately\n",
    "        print(f\"Computing S^{level}...\")\n",
    "        S_l = model.compute_matrix(batch_size=256)\n",
    "        \n",
    "        print(f\"S^{level} shape: {S_l.shape}\")\n",
    "        print(f\"S^{level} stats: μ={S_l.mean():.3f}, σ={S_l.std():.3f}, range=[{S_l.min():.3f}, {S_l.max():.3f}]\")\n",
    "        \n",
    "        models[f'level_{level}'] = model\n",
    "        S_matrices[f'level_{level}'] = S_l\n",
    "        \n",
    "        # Save individual level\n",
    "        torch.save(model.state_dict(), f\"../../Sources/Weights/feature_model_level{level}_init.pt\")\n",
    "    \n",
    "    # Save all S matrices together\n",
    "    with open(\"../../Sources/Embeddings v3/S_matrices_feature.pkl\", 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'S_matrices': S_matrices,\n",
    "            'metadata': {\n",
    "                'formula': 'S^l = P^l(Q^l)^T',\n",
    "                'levels': [0, 1, 2, 3],\n",
    "                'latent_dim': latent_dim,\n",
    "                'note': 'A^l parameters randomly initialized, not yet trained'\n",
    "            }\n",
    "        }, f)\n",
    "    \n",
    "    return models, S_matrices\n",
    "\n",
    "models, S_matrices = initialize_all_levels(\n",
    "    user_emb_path=user_emb_path,\n",
    "    poi_emb_path=poi_emb_path,\n",
    "    interlevel_path=interlevel_path,\n",
    "    latent_dim=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeecef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
