{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5803017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd848561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Inspecting: User Embeddings\n",
      "============================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['user_embeddings', 'poi_embeddings']\n",
      "  user_embeddings: dict with keys ['966592ed-5bfd-4113-9c4d-d93cd3637b40', '6fea97cb-757c-47f2-9e34-3ccbb6714c80', '91d45a60-1f23-45f2-a343-a51017f818d9', '4fbee9f0-804a-4e5d-834e-553670746410', 'ed4d4ddf-8829-49c2-b540-b0c8aa36dfcf', '6b60d5cf-63cc-4dc4-9bbe-74da03df19db', '13e7ba11-c5a9-4f73-86d2-0f2c058891c7', 'af0e718d-4cca-4308-a72e-221b3f2fbe9e', '11069943-47a6-46e4-87ca-fa7d38142abc', '84273d4e-1e2c-4baf-8f0d-7b4f2ef833d0', '79dfa2c9-fcaf-4ac0-9cf6-acdc3165f1db', '0fa06458-d7df-42c6-9de2-c32c36c16707', 'bc6799a8-00d1-4ab5-80bf-eeffc36ba029', 'd9093d18-b959-4ff3-b69a-a1748460cb5e', 'bdfc5ba3-1843-4148-aef4-5f25b90608d4', '6c32074e-c671-44f7-951a-422b74159885', 'da4ea5cf-d90f-4105-9a6e-f9f38252d01c', '20fa62fd-59ef-4d4f-8cb4-9389b70ac389', 'dc678a8d-37ff-4a54-9a6a-da7252d1b855', '985b9ad3-79dc-4c6a-9159-27f4dda0e235', 'e84b1e1f-de1f-4d49-85fc-28d7b0e8b86b']\n",
      "    966592ed-5bfd-4113-9c4d-d93cd3637b40: numpy array, shape (71,)\n",
      "    6fea97cb-757c-47f2-9e34-3ccbb6714c80: numpy array, shape (71,)\n",
      "    91d45a60-1f23-45f2-a343-a51017f818d9: numpy array, shape (71,)\n",
      "    4fbee9f0-804a-4e5d-834e-553670746410: numpy array, shape (71,)\n",
      "    ed4d4ddf-8829-49c2-b540-b0c8aa36dfcf: numpy array, shape (71,)\n",
      "    6b60d5cf-63cc-4dc4-9bbe-74da03df19db: numpy array, shape (71,)\n",
      "    13e7ba11-c5a9-4f73-86d2-0f2c058891c7: numpy array, shape (71,)\n",
      "    af0e718d-4cca-4308-a72e-221b3f2fbe9e: numpy array, shape (71,)\n",
      "    11069943-47a6-46e4-87ca-fa7d38142abc: numpy array, shape (71,)\n",
      "    84273d4e-1e2c-4baf-8f0d-7b4f2ef833d0: numpy array, shape (71,)\n",
      "    79dfa2c9-fcaf-4ac0-9cf6-acdc3165f1db: numpy array, shape (71,)\n",
      "    0fa06458-d7df-42c6-9de2-c32c36c16707: numpy array, shape (71,)\n",
      "    bc6799a8-00d1-4ab5-80bf-eeffc36ba029: numpy array, shape (71,)\n",
      "    d9093d18-b959-4ff3-b69a-a1748460cb5e: numpy array, shape (71,)\n",
      "    bdfc5ba3-1843-4148-aef4-5f25b90608d4: numpy array, shape (71,)\n",
      "    6c32074e-c671-44f7-951a-422b74159885: numpy array, shape (71,)\n",
      "    da4ea5cf-d90f-4105-9a6e-f9f38252d01c: numpy array, shape (71,)\n",
      "    20fa62fd-59ef-4d4f-8cb4-9389b70ac389: numpy array, shape (71,)\n",
      "    dc678a8d-37ff-4a54-9a6a-da7252d1b855: numpy array, shape (71,)\n",
      "    985b9ad3-79dc-4c6a-9159-27f4dda0e235: numpy array, shape (71,)\n",
      "    e84b1e1f-de1f-4d49-85fc-28d7b0e8b86b: numpy array, shape (71,)\n",
      "  poi_embeddings: dict with keys []\n",
      "\n",
      "============================================================\n",
      "Inspecting: User Personalised Preferences\n",
      "============================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['A_lu', 'P_l', 'dimensions', 'info']\n",
      "  A_lu: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: numpy array, shape (21, 221)\n",
      "    level_1: numpy array, shape (21, 171)\n",
      "    level_2: numpy array, shape (21, 125)\n",
      "    level_3: numpy array, shape (21, 105)\n",
      "  P_l: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: numpy array, shape (21, 221)\n",
      "    level_1: numpy array, shape (21, 171)\n",
      "    level_2: numpy array, shape (21, 125)\n",
      "    level_3: numpy array, shape (21, 105)\n",
      "  dimensions: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  info: dict with keys ['created_at', 'aggregation_method', 'components']\n",
      "    created_at: <class 'str'>\n",
      "    aggregation_method: <class 'str'>\n",
      "    components: <class 'list'>\n",
      "\n",
      "============================================================\n",
      "Inspecting: POI Embeddings\n",
      "============================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['poi_embeddings', 'encoders', 'poi_tree', 'metadata', 'poi_id_to_idx', 'feature_names']\n",
      "  poi_embeddings: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  encoders: dict with keys [0, 'user_interests_encoder', 'user_age_encoder', 'user_price_encoder', 1, 2, 3]\n",
      "    0: <class 'dict'>\n",
      "    user_interests_encoder: <class 'sklearn.preprocessing._label.MultiLabelBinarizer'>\n",
      "    user_age_encoder: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "    user_price_encoder: <class 'sklearn.preprocessing._label.LabelEncoder'>\n",
      "    1: <class 'dict'>\n",
      "    2: <class 'dict'>\n",
      "    3: <class 'dict'>\n",
      "  poi_tree: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  metadata: dict with keys ['levels', 'n_users', 'n_interactions', 'created_at', 'embedding_dimensions']\n",
      "    levels: <class 'list'>\n",
      "    n_users: <class 'int'>\n",
      "    n_interactions: <class 'int'>\n",
      "    created_at: <class 'str'>\n",
      "    embedding_dimensions: <class 'dict'>\n",
      "  poi_id_to_idx: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  feature_names: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "\n",
      "============================================================\n",
      "Inspecting: POI Interlevel Features\n",
      "============================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['A_lp', 'Q_l', 'attention_weights', 'aggregator_weights', 'aggregator_config', 'dimensions', 'info']\n",
      "  A_lp: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: numpy array, shape (4696, 221)\n",
      "    level_1: numpy array, shape (1355, 171)\n",
      "    level_2: numpy array, shape (44, 125)\n",
      "    level_3: numpy array, shape (5, 105)\n",
      "  Q_l: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: numpy array, shape (4696, 442)\n",
      "    level_1: numpy array, shape (1355, 342)\n",
      "    level_2: numpy array, shape (44, 250)\n",
      "    level_3: numpy array, shape (5, 210)\n",
      "  attention_weights: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'NoneType'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  aggregator_weights: dict with keys [1, 2, 3]\n",
      "    1: <class 'dict'>\n",
      "    2: <class 'dict'>\n",
      "    3: <class 'dict'>\n",
      "  aggregator_config: dict with keys ['hidden_dim', 'dropout_rate']\n",
      "    hidden_dim: <class 'int'>\n",
      "    dropout_rate: <class 'float'>\n",
      "  dimensions: dict with keys ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "    level_0: <class 'dict'>\n",
      "    level_1: <class 'dict'>\n",
      "    level_2: <class 'dict'>\n",
      "    level_3: <class 'dict'>\n",
      "  info: dict with keys ['created_at', 'formula', 'aggregation', 'hidden_dim', 'framework', 'tf_version']\n",
      "    created_at: <class 'str'>\n",
      "    formula: <class 'str'>\n",
      "    aggregation: <class 'str'>\n",
      "    hidden_dim: <class 'int'>\n",
      "    framework: <class 'str'>\n",
      "    tf_version: <class 'str'>\n",
      "\n",
      "============================================================\n",
      "Inspecting: Meta Data\n",
      "============================================================\n",
      "Type: <class 'dict'>\n",
      "Keys: ['mappings', 'counts', 'user_ids', 'poi_ids', 'level_names', 'info']\n",
      "  mappings: dict with keys ['user', 'poi']\n",
      "    user: <class 'dict'>\n",
      "    poi: <class 'dict'>\n",
      "  counts: dict with keys ['users', 'pois_level_0', 'pois_level_1', 'pois_level_2', 'pois_level_3', 'pois_total']\n",
      "    users: <class 'int'>\n",
      "    pois_level_0: <class 'int'>\n",
      "    pois_level_1: <class 'int'>\n",
      "    pois_level_2: <class 'int'>\n",
      "    pois_level_3: <class 'int'>\n",
      "    pois_total: <class 'int'>\n",
      "  user_ids: <class 'list'>\n",
      "  poi_ids: dict with keys [0, 1, 2, 3]\n",
      "    0: <class 'list'>\n",
      "    1: <class 'list'>\n",
      "    2: <class 'list'>\n",
      "    3: <class 'list'>\n",
      "  level_names: dict with keys [0, 1, 2, 3]\n",
      "    0: <class 'str'>\n",
      "    1: <class 'str'>\n",
      "    2: <class 'str'>\n",
      "    3: <class 'str'>\n",
      "  info: dict with keys ['created_at', 'source_files', 'version']\n",
      "    created_at: <class 'str'>\n",
      "    source_files: <class 'dict'>\n",
      "    version: <class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Windows\\Temp\\ipykernel_18924\\3827501806.py:11: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  data = pickle.load(f)\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def inspect_pickle_structure(filepath, name):\n",
    "    \"\"\"Inspect the structure of a pickle file\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Inspecting: {name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    with open(filepath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    print(f\"Type: {type(data)}\")\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        print(f\"Keys: {list(data.keys())}\")\n",
    "        for key in data.keys():\n",
    "            value = data[key]\n",
    "            if isinstance(value, np.ndarray):\n",
    "                print(f\"  {key}: numpy array, shape {value.shape}, dtype {value.dtype}\")\n",
    "            elif isinstance(value, dict):\n",
    "                print(f\"  {key}: dict with keys {list(value.keys())}\")\n",
    "                for subkey in value.keys():\n",
    "                    subvalue = value[subkey]\n",
    "                    if isinstance(subvalue, np.ndarray):\n",
    "                        print(f\"    {subkey}: numpy array, shape {subvalue.shape}\")\n",
    "                    else:\n",
    "                        print(f\"    {subkey}: {type(subvalue)}\")\n",
    "            else:\n",
    "                print(f\"  {key}: {type(value)}\")\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Dtype: {data.dtype}\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Inspect all files\n",
    "user_emb = inspect_pickle_structure(\"../../Sources/Embeddings/user_embeddings.pkl\", 'User Embeddings')\n",
    "user_pers = inspect_pickle_structure(\"../../Sources/Embeddings/user_personalized_preferences.pkl\", 'User Personalised Preferences')\n",
    "poi_emb = inspect_pickle_structure(\"../../Sources/Embeddings/poi_embeddings.pkl\", 'POI Embeddings')\n",
    "poi_inter = inspect_pickle_structure(\"../../Sources/Embeddings/poi_interlevel_features.pkl\", 'POI Interlevel Features')\n",
    "meta = inspect_pickle_structure(\"../../Sources/Embeddings/metadata.pkl\", 'Meta Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "55687acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User Personalised Dimensions:\n",
      "============================================================\n",
      "\n",
      "Level 0:\n",
      "  A_lu_shape: (21, 221)\n",
      "  P_l_shape: (21, 221)\n",
      "\n",
      "Level 1:\n",
      "  A_lu_shape: (21, 171)\n",
      "  P_l_shape: (21, 171)\n",
      "\n",
      "Level 2:\n",
      "  A_lu_shape: (21, 125)\n",
      "  P_l_shape: (21, 125)\n",
      "\n",
      "Level 3:\n",
      "  A_lu_shape: (21, 105)\n",
      "  P_l_shape: (21, 105)\n",
      "\n",
      "============================================================\n",
      "POI Interlevel Dimensions:\n",
      "============================================================\n",
      "\n",
      "Level 0:\n",
      "  A_lp_shape: (4696, 221)\n",
      "  Q_l_shape: (4696, 442)\n",
      "\n",
      "Level 1:\n",
      "  A_lp_shape: (1355, 171)\n",
      "  Q_l_shape: (1355, 342)\n",
      "\n",
      "Level 2:\n",
      "  A_lp_shape: (44, 125)\n",
      "  Q_l_shape: (44, 250)\n",
      "\n",
      "Level 3:\n",
      "  A_lp_shape: (5, 105)\n",
      "  Q_l_shape: (5, 210)\n",
      "\n",
      "============================================================\n",
      "Checking what P_l and Q_l actually represent:\n",
      "============================================================\n",
      "user_pers['info']: {'created_at': '2026-01-16T17:02:33.853975', 'aggregation_method': 'weighted_mean', 'components': ['X_A', 'X_T', 'A_lu']}\n",
      "\n",
      "poi_inter['info']: {'created_at': '2026-02-02T19:10:11.206820', 'formula': 'Q^l = [Y_A || Y_T || A^l_p]', 'aggregation': 'MLP Attention (TensorFlow)', 'hidden_dim': 64, 'framework': 'tensorflow', 'tf_version': '2.10.1'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"User Personalised Dimensions:\")\n",
    "print(\"=\"*60)\n",
    "for level in range(4):\n",
    "    dims = user_pers['dimensions'][f'level_{level}']\n",
    "    print(f\"\\nLevel {level}:\")\n",
    "    for key, value in dims.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"POI Interlevel Dimensions:\")\n",
    "print(\"=\"*60)\n",
    "for level in range(4):\n",
    "    dims = poi_inter['dimensions'][f'level_{level}']\n",
    "    print(f\"\\nLevel {level}:\")\n",
    "    for key, value in dims.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checking what P_l and Q_l actually represent:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"user_pers['info']: {user_pers['info']}\")\n",
    "print(f\"\\npoi_inter['info']: {poi_inter['info']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4de2c40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Looking for user feature components...\n",
      "============================================================\n",
      "\n",
      "user_embeddings.pkl structure:\n",
      "Found 'poi_embeddings' key (might contain derived user features)\n",
      "  Empty dict\n",
      "\n",
      "Checking poi_embeddings.pkl for user features:\n",
      "\n",
      "Level 0 keys: ['embeddings', 'poi_ids', 'Y_A', 'Y_T', 'Y_A_feature_names', 'Y_T_feature_names', 'all_feature_names', 'n_explicit_features', 'n_derived_features', 'level_name']\n",
      "  embeddings: (4696, 221)\n",
      "  Y_A: (4696, 149)\n",
      "  Y_T: (4696, 72)\n",
      "\n",
      "Level 1 keys: ['embeddings', 'poi_ids', 'Y_A', 'Y_T', 'Y_A_feature_names', 'Y_T_feature_names', 'all_feature_names', 'n_explicit_features', 'n_derived_features', 'level_name']\n",
      "  embeddings: (1355, 171)\n",
      "  Y_A: (1355, 99)\n",
      "  Y_T: (1355, 72)\n",
      "\n",
      "Level 2 keys: ['embeddings', 'poi_ids', 'Y_A', 'Y_T', 'Y_A_feature_names', 'Y_T_feature_names', 'all_feature_names', 'n_explicit_features', 'n_derived_features', 'level_name']\n",
      "  embeddings: (44, 125)\n",
      "  Y_A: (44, 53)\n",
      "  Y_T: (44, 72)\n",
      "\n",
      "Level 3 keys: ['embeddings', 'poi_ids', 'Y_A', 'Y_T', 'Y_A_feature_names', 'Y_T_feature_names', 'all_feature_names', 'n_explicit_features', 'n_derived_features', 'level_name']\n",
      "  embeddings: (5, 105)\n",
      "  Y_A: (5, 33)\n",
      "  Y_T: (5, 72)\n",
      "\n",
      "User-related pickle files found: []\n"
     ]
    }
   ],
   "source": [
    "# Check if explicit and derived user features are stored separately\n",
    "print(\"=\"*60)\n",
    "print(\"Looking for user feature components...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check user_embeddings structure more carefully\n",
    "print(\"\\nuser_embeddings.pkl structure:\")\n",
    "if 'poi_embeddings' in user_emb:\n",
    "    print(\"Found 'poi_embeddings' key (might contain derived user features)\")\n",
    "    if user_emb['poi_embeddings']:\n",
    "        print(f\"  Keys: {list(user_emb['poi_embeddings'].keys())}\")\n",
    "    else:\n",
    "        print(\"  Empty dict\")\n",
    "\n",
    "# Check POI embeddings for user-related features\n",
    "print(\"\\nChecking poi_embeddings.pkl for user features:\")\n",
    "for level in range(4):\n",
    "    level_key = f'level_{level}'\n",
    "    level_data = poi_emb['poi_embeddings'][level_key]\n",
    "    print(f\"\\nLevel {level} keys: {list(level_data.keys())}\")\n",
    "    \n",
    "    # Check sizes\n",
    "    for key, value in level_data.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            print(f\"  {key}: {value.shape}\")\n",
    "\n",
    "# Most importantly, check if there's a separate user features file\n",
    "import os\n",
    "user_feature_files = [f for f in os.listdir('.') if 'user' in f.lower() and f.endswith('.pkl')]\n",
    "print(f\"\\nUser-related pickle files found: {user_feature_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc46497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Deep inspection of user_embeddings.pkl\n",
      "============================================================\n",
      "\n",
      "Sample user embedding:\n",
      "  User ID: 966592ed-5bfd-4113-9c4d-d93cd3637b40\n",
      "  Embedding shape: (71,)\n",
      "  Embedding: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]...\n",
      "\n",
      "ğŸ” Analysis:\n",
      "  User embedding dim: 71\n",
      "  POI Y_T dim: 72\n",
      "  These are very close - might be the derived features!\n",
      "\n",
      "============================================================\n",
      "Checking if user_preferences.csv provides explicit features...\n",
      "============================================================\n",
      "\n",
      "user_preferences.csv columns: ['uudi', 'name', 'age_group', 'area_of_residence', 'interests', 'transportation_modes', 'price_sensitivity']\n",
      "Number of users: 21\n",
      "\n",
      "Sample row:\n",
      "uudi                    966592ed-5bfd-4113-9c4d-d93cd3637b40\n",
      "name                                                   Aiden\n",
      "age_group                                              18-24\n",
      "area_of_residence                                Jurong East\n",
      "interests                             food; shopping; movies\n",
      "transportation_modes                                MRT; bus\n",
      "price_sensitivity                                        low\n",
      "Name: 0, dtype: object\n",
      "\n",
      "âœ“ This can provide X_A (explicit user attributes)!\n"
     ]
    }
   ],
   "source": [
    "# Deep dive into user_embeddings structure\n",
    "print(\"=\"*60)\n",
    "print(\"Deep inspection of user_embeddings.pkl\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Check the 71-dimensional user vectors\n",
    "sample_user_id = list(user_emb['user_embeddings'].keys())[0]\n",
    "sample_embedding = user_emb['user_embeddings'][sample_user_id]\n",
    "\n",
    "print(f\"\\nSample user embedding:\")\n",
    "print(f\"  User ID: {sample_user_id}\")\n",
    "print(f\"  Embedding shape: {sample_embedding.shape}\")\n",
    "print(f\"  Embedding: {sample_embedding[:10]}...\")  # First 10 values\n",
    "\n",
    "# The 71-dimensional vector might already be [X_A || X_T]\n",
    "# Let's check if 71 relates to the Y_T dimension (which is 72 for POIs)\n",
    "print(f\"\\nğŸ” Analysis:\")\n",
    "print(f\"  User embedding dim: 71\")\n",
    "print(f\"  POI Y_T dim: 72\")\n",
    "print(f\"  These are very close - might be the derived features!\")\n",
    "\n",
    "# Let's also check if there's user preference data\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Checking if user_preferences.csv provides explicit features...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import pandas as pd\n",
    "try:\n",
    "    user_prefs = pd.read_csv('../../Sources/Files/user_preferences.csv')\n",
    "    print(f\"\\nuser_preferences.csv columns: {list(user_prefs.columns)}\")\n",
    "    print(f\"Number of users: {len(user_prefs)}\")\n",
    "    print(f\"\\nSample row:\")\n",
    "    print(user_prefs.iloc[0])\n",
    "    \n",
    "    # These should give us X_A (explicit attributes)\n",
    "    print(\"\\nâœ“ This can provide X_A (explicit user attributes)!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"user_preferences.csv not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27259a4",
   "metadata": {},
   "source": [
    "### Step 1 : P^l = explicit user attributes + derived user attributes + trainable matrix parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc54687",
   "metadata": {},
   "source": [
    "### Step 2 : Q^l = explicit poi attributes + derived poi attributes + inter-level poi feature matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203fee1",
   "metadata": {},
   "source": [
    "### Step 3 : Feature based check-in matrix (S^l) = (P^l*(Q^l))^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0172493f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "               FEATURE-BASED CHECK-IN MATRIX COMPUTATION\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "                               LEVEL 0                                \n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š User embeddings split:\n",
      "  X_A (explicit): (21, 39)\n",
      "  X_T (derived):  (21, 32)\n",
      "  Total:          (21, 71)\n",
      "\n",
      "ğŸ”¨ Level 0 - P^l construction:\n",
      "  X_A:      (21, 39)\n",
      "  X_T:      (21, 32)\n",
      "  A^l_u:    (21, 221)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  P^l:      (21, 292)\n",
      "âœ“ Q^l verified\n",
      "\n",
      "ğŸ”¨ Level 0 - Q^l structure:\n",
      "  Y_A:      (4696, 149)\n",
      "  Y_T:      (4696, 72)\n",
      "  A^l_p:    (4696, 221)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Q^l:      (4696, 442)\n",
      "\n",
      "ğŸ“ Dimension check:\n",
      "  P^0: 292 features\n",
      "  Q^0: 442 features\n",
      "  âœ— Dimension mismatch!\n",
      "\n",
      "  P^0 components: 39 + 32 + 221 = 292\n",
      "  Q^0 components: 149 + 72 + 221 = 442\n",
      "  â†’ Padded P^0 to (21, 442)\n",
      "\n",
      "ğŸ”¢ Computing S^0 = P^0 @ (Q^0)^T\n",
      "\n",
      "ğŸ“Š S^0 statistics:\n",
      "  Shape:           21 users Ã—  4696 POIs\n",
      "  Range:        [ -4.2910,  11.9947]\n",
      "  Mean Â± Std:     0.7048 Â± 1.3809\n",
      "  Median:         0.5723\n",
      "  Non-zero:        98616 / 98616\n",
      "\n",
      "======================================================================\n",
      "                               LEVEL 1                                \n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š User embeddings split:\n",
      "  X_A (explicit): (21, 39)\n",
      "  X_T (derived):  (21, 32)\n",
      "  Total:          (21, 71)\n",
      "\n",
      "ğŸ”¨ Level 1 - P^l construction:\n",
      "  X_A:      (21, 39)\n",
      "  X_T:      (21, 32)\n",
      "  A^l_u:    (21, 171)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  P^l:      (21, 242)\n",
      "âœ“ Q^l verified\n",
      "\n",
      "ğŸ”¨ Level 1 - Q^l structure:\n",
      "  Y_A:      (1355, 99)\n",
      "  Y_T:      (1355, 72)\n",
      "  A^l_p:    (1355, 171)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Q^l:      (1355, 342)\n",
      "\n",
      "ğŸ“ Dimension check:\n",
      "  P^1: 242 features\n",
      "  Q^1: 342 features\n",
      "  âœ— Dimension mismatch!\n",
      "\n",
      "  P^1 components: 39 + 32 + 171 = 242\n",
      "  Q^1 components: 99 + 72 + 171 = 342\n",
      "  â†’ Padded P^1 to (21, 342)\n",
      "\n",
      "ğŸ”¢ Computing S^1 = P^1 @ (Q^1)^T\n",
      "\n",
      "ğŸ“Š S^1 statistics:\n",
      "  Shape:           21 users Ã—  1355 POIs\n",
      "  Range:        [ -5.1297,  37.5195]\n",
      "  Mean Â± Std:     0.2166 Â± 1.0730\n",
      "  Median:        -0.0719\n",
      "  Non-zero:        28455 / 28455\n",
      "\n",
      "======================================================================\n",
      "                               LEVEL 2                                \n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š User embeddings split:\n",
      "  X_A (explicit): (21, 39)\n",
      "  X_T (derived):  (21, 32)\n",
      "  Total:          (21, 71)\n",
      "\n",
      "ğŸ”¨ Level 2 - P^l construction:\n",
      "  X_A:      (21, 39)\n",
      "  X_T:      (21, 32)\n",
      "  A^l_u:    (21, 125)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  P^l:      (21, 196)\n",
      "âœ“ Q^l verified\n",
      "\n",
      "ğŸ”¨ Level 2 - Q^l structure:\n",
      "  Y_A:      (44, 53)\n",
      "  Y_T:      (44, 72)\n",
      "  A^l_p:    (44, 125)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Q^l:      (44, 250)\n",
      "\n",
      "ğŸ“ Dimension check:\n",
      "  P^2: 196 features\n",
      "  Q^2: 250 features\n",
      "  âœ— Dimension mismatch!\n",
      "\n",
      "  P^2 components: 39 + 32 + 125 = 196\n",
      "  Q^2 components: 53 + 72 + 125 = 250\n",
      "  â†’ Padded P^2 to (21, 250)\n",
      "\n",
      "ğŸ”¢ Computing S^2 = P^2 @ (Q^2)^T\n",
      "\n",
      "ğŸ“Š S^2 statistics:\n",
      "  Shape:           21 users Ã—    44 POIs\n",
      "  Range:        [-10.7821,  26.3632]\n",
      "  Mean Â± Std:     0.6273 Â± 4.2765\n",
      "  Median:         0.2431\n",
      "  Non-zero:          924 / 924\n",
      "\n",
      "======================================================================\n",
      "                               LEVEL 3                                \n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š User embeddings split:\n",
      "  X_A (explicit): (21, 39)\n",
      "  X_T (derived):  (21, 32)\n",
      "  Total:          (21, 71)\n",
      "\n",
      "ğŸ”¨ Level 3 - P^l construction:\n",
      "  X_A:      (21, 39)\n",
      "  X_T:      (21, 32)\n",
      "  A^l_u:    (21, 105)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  P^l:      (21, 176)\n",
      "âœ“ Q^l verified\n",
      "\n",
      "ğŸ”¨ Level 3 - Q^l structure:\n",
      "  Y_A:      (5, 33)\n",
      "  Y_T:      (5, 72)\n",
      "  A^l_p:    (5, 105)\n",
      "  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "  Q^l:      (5, 210)\n",
      "\n",
      "ğŸ“ Dimension check:\n",
      "  P^3: 176 features\n",
      "  Q^3: 210 features\n",
      "  âœ— Dimension mismatch!\n",
      "\n",
      "  P^3 components: 39 + 32 + 105 = 176\n",
      "  Q^3 components: 33 + 72 + 105 = 210\n",
      "  â†’ Padded P^3 to (21, 210)\n",
      "\n",
      "ğŸ”¢ Computing S^3 = P^3 @ (Q^3)^T\n",
      "\n",
      "ğŸ“Š S^3 statistics:\n",
      "  Shape:           21 users Ã—     5 POIs\n",
      "  Range:        [-16.4600,  18.2514]\n",
      "  Mean Â± Std:     0.5588 Â± 5.9576\n",
      "  Median:         0.6630\n",
      "  Non-zero:          105 / 105\n",
      "\n",
      "======================================================================\n",
      "âœ… SUCCESS: Feature-based check-in matrices computed and saved!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Saved to: feature_checkin_matrices.pkl\n",
      "\n",
      "ğŸ“‹ Summary:\n",
      "  Level 0: 21 users Ã—  442 POIs, scores [  -4.29,   11.99]\n",
      "  Level 1: 21 users Ã—  342 POIs, scores [  -5.13,   37.52]\n",
      "  Level 2: 21 users Ã—  250 POIs, scores [ -10.78,   26.36]\n",
      "  Level 3: 21 users Ã—  210 POIs, scores [ -16.46,   18.25]\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def split_user_embeddings(user_emb, meta):\n",
    "    \"\"\"\n",
    "    Split the 71-dim user embeddings into X_A (39) and X_T (32)\n",
    "    \n",
    "    Returns:\n",
    "        X_A: (n_users, 39) - Explicit user attributes\n",
    "        X_T: (n_users, 32) - Derived user attributes\n",
    "    \"\"\"\n",
    "    user_ids = meta['user_ids']\n",
    "    n_users = len(user_ids)\n",
    "    \n",
    "    # Extract embeddings in correct user order\n",
    "    user_embedding_matrix = np.zeros((n_users, 71))\n",
    "    for idx, user_id in enumerate(user_ids):\n",
    "        if user_id in user_emb['user_embeddings']:\n",
    "            user_embedding_matrix[idx] = user_emb['user_embeddings'][user_id]\n",
    "        else:\n",
    "            print(f\"âš ï¸  Warning: User {user_id} not found in embeddings\")\n",
    "    \n",
    "    # Split into X_A and X_T\n",
    "    X_A = user_embedding_matrix[:, :39]   # First 39 dims = explicit\n",
    "    X_T = user_embedding_matrix[:, 39:]   # Last 32 dims = derived\n",
    "    \n",
    "    print(f\"\\nğŸ“Š User embeddings split:\")\n",
    "    print(f\"  X_A (explicit): {X_A.shape}\")\n",
    "    print(f\"  X_T (derived):  {X_T.shape}\")\n",
    "    print(f\"  Total:          {user_embedding_matrix.shape}\")\n",
    "    \n",
    "    return X_A, X_T\n",
    "\n",
    "\n",
    "def construct_P_l_correct(user_emb, user_pers, meta, level):\n",
    "    \"\"\"\n",
    "    Construct P^l = [X_A || X_T || A^l_u]\n",
    "    \n",
    "    This matches the structure of Q^l = [Y_A || Y_T || A^l_p]\n",
    "    \"\"\"\n",
    "    level_key = f'level_{level}'\n",
    "    \n",
    "    # Split user embeddings\n",
    "    X_A, X_T = split_user_embeddings(user_emb, meta)\n",
    "    \n",
    "    # Get inter-level user features\n",
    "    A_lu = user_pers['A_lu'][level_key]\n",
    "    \n",
    "    # Concatenate: P^l = [X_A || X_T || A^l_u]\n",
    "    P_l = np.concatenate([X_A, X_T, A_lu], axis=1)\n",
    "    \n",
    "    print(f\"\\nğŸ”¨ Level {level} - P^l construction:\")\n",
    "    print(f\"  X_A:      {X_A.shape}\")\n",
    "    print(f\"  X_T:      {X_T.shape}\")\n",
    "    print(f\"  A^l_u:    {A_lu.shape}\")\n",
    "    print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"  P^l:      {P_l.shape}\")\n",
    "    \n",
    "    return P_l, (X_A, X_T, A_lu)\n",
    "\n",
    "\n",
    "def verify_Q_l_structure(poi_emb, poi_inter, level):\n",
    "    \"\"\"\n",
    "    Verify Q^l = [Y_A || Y_T || A^l_p] structure\n",
    "    \"\"\"\n",
    "    level_key = f'level_{level}'\n",
    "    \n",
    "    Y_A = poi_emb['poi_embeddings'][level_key]['Y_A']\n",
    "    Y_T = poi_emb['poi_embeddings'][level_key]['Y_T']\n",
    "    A_lp = poi_inter['A_lp'][level_key]\n",
    "    Q_l = poi_inter['Q_l'][level_key]\n",
    "    \n",
    "    # Verify concatenation\n",
    "    Q_l_reconstructed = np.concatenate([Y_A, Y_T, A_lp], axis=1)\n",
    "    \n",
    "    if np.allclose(Q_l, Q_l_reconstructed):\n",
    "        print(f\"âœ“ Q^l verified\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Q^l structure mismatch\")\n",
    "    \n",
    "    print(f\"\\nğŸ”¨ Level {level} - Q^l structure:\")\n",
    "    print(f\"  Y_A:      {Y_A.shape}\")\n",
    "    print(f\"  Y_T:      {Y_T.shape}\")\n",
    "    print(f\"  A^l_p:    {A_lp.shape}\")\n",
    "    print(f\"  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"  Q^l:      {Q_l.shape}\")\n",
    "    \n",
    "    return Q_l, (Y_A, Y_T, A_lp)\n",
    "\n",
    "\n",
    "def build_feature_checkin_matrices_correct(user_emb, user_pers, poi_emb, poi_inter, meta):\n",
    "    \"\"\"\n",
    "    Build S^l = P^l @ (Q^l)^T with correct component concatenation\n",
    "    \n",
    "    P^l = [X_A || X_T || A^l_u]  (User: explicit || derived || inter-level)\n",
    "    Q^l = [Y_A || Y_T || A^l_p]  (POI:  explicit || derived || inter-level)\n",
    "    \n",
    "    S^l = P^l @ (Q^l)^T          (Feature-based check-in matrix)\n",
    "    \"\"\"\n",
    "    S_matrices = {}\n",
    "    P_components = {}\n",
    "    Q_components = {}\n",
    "    dimension_info = {}\n",
    "    \n",
    "    for level in range(4):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"{'LEVEL ' + str(level):^70}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Construct P^l\n",
    "        P_l, (X_A, X_T, A_lu) = construct_P_l_correct(user_emb, user_pers, meta, level)\n",
    "        \n",
    "        # Verify Q^l\n",
    "        Q_l, (Y_A, Y_T, A_lp) = verify_Q_l_structure(poi_emb, poi_inter, level)\n",
    "        \n",
    "        # Check dimension compatibility\n",
    "        print(f\"\\nğŸ“ Dimension check:\")\n",
    "        print(f\"  P^{level}: {P_l.shape[1]} features\")\n",
    "        print(f\"  Q^{level}: {Q_l.shape[1]} features\")\n",
    "        \n",
    "        if P_l.shape[1] == Q_l.shape[1]:\n",
    "            print(f\"  âœ“ Dimensions match!\")\n",
    "        else:\n",
    "            print(f\"  âœ— Dimension mismatch!\")\n",
    "            print(f\"\\n  P^{level} components: {X_A.shape[1]} + {X_T.shape[1]} + {A_lu.shape[1]} = {P_l.shape[1]}\")\n",
    "            print(f\"  Q^{level} components: {Y_A.shape[1]} + {Y_T.shape[1]} + {A_lp.shape[1]} = {Q_l.shape[1]}\")\n",
    "            \n",
    "            # Adjust if needed\n",
    "            if P_l.shape[1] < Q_l.shape[1]:\n",
    "                padding = np.zeros((P_l.shape[0], Q_l.shape[1] - P_l.shape[1]))\n",
    "                P_l = np.concatenate([P_l, padding], axis=1)\n",
    "                print(f\"  â†’ Padded P^{level} to {P_l.shape}\")\n",
    "            elif P_l.shape[1] > Q_l.shape[1]:\n",
    "                P_l = P_l[:, :Q_l.shape[1]]\n",
    "                print(f\"  â†’ Truncated P^{level} to {P_l.shape}\")\n",
    "        \n",
    "        # Compute S^l = P^l @ (Q^l)^T\n",
    "        print(f\"\\nğŸ”¢ Computing S^{level} = P^{level} @ (Q^{level})^T\")\n",
    "        S_l = np.matmul(P_l, Q_l.T)\n",
    "        \n",
    "        # Validate\n",
    "        assert not np.isnan(S_l).any(), f\"Level {level}: NaN values detected!\"\n",
    "        assert not np.isinf(S_l).any(), f\"Level {level}: Inf values detected!\"\n",
    "        \n",
    "        # Statistics\n",
    "        print(f\"\\nğŸ“Š S^{level} statistics:\")\n",
    "        print(f\"  Shape:        {S_l.shape[0]:>5} users Ã— {S_l.shape[1]:>5} POIs\")\n",
    "        print(f\"  Range:        [{S_l.min():>8.4f}, {S_l.max():>8.4f}]\")\n",
    "        print(f\"  Mean Â± Std:   {S_l.mean():>8.4f} Â± {S_l.std():.4f}\")\n",
    "        print(f\"  Median:       {np.median(S_l):>8.4f}\")\n",
    "        print(f\"  Non-zero:     {np.count_nonzero(S_l):>8} / {S_l.size}\")\n",
    "        \n",
    "        # Store results\n",
    "        S_matrices[level_key] = S_l\n",
    "        P_components[level_key] = {'X_A': X_A, 'X_T': X_T, 'A_lu': A_lu, 'P_l': P_l}\n",
    "        Q_components[level_key] = {'Y_A': Y_A, 'Y_T': Y_T, 'A_lp': A_lp, 'Q_l': Q_l}\n",
    "        \n",
    "        dimension_info[level_key] = {\n",
    "            'n_users': P_l.shape[0],\n",
    "            'n_pois': Q_l.shape[1],\n",
    "            'P_l_dims': {\n",
    "                'X_A': X_A.shape[1],\n",
    "                'X_T': X_T.shape[1],\n",
    "                'A_lu': A_lu.shape[1],\n",
    "                'total': P_l.shape[1]\n",
    "            },\n",
    "            'Q_l_dims': {\n",
    "                'Y_A': Y_A.shape[1],\n",
    "                'Y_T': Y_T.shape[1],\n",
    "                'A_lp': A_lp.shape[1],\n",
    "                'total': Q_l.shape[1]\n",
    "            },\n",
    "            'S_l_shape': S_l.shape,\n",
    "            'S_l_stats': {\n",
    "                'min': float(S_l.min()),\n",
    "                'max': float(S_l.max()),\n",
    "                'mean': float(S_l.mean()),\n",
    "                'std': float(S_l.std()),\n",
    "                'median': float(np.median(S_l))\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return S_matrices, P_components, Q_components, dimension_info\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXECUTE\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \"*15 + \"FEATURE-BASED CHECK-IN MATRIX COMPUTATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "S_matrices, P_components, Q_components, dimension_info = build_feature_checkin_matrices_correct(\n",
    "    user_emb, user_pers, poi_emb, poi_inter, meta\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "output = {\n",
    "    'S_matrices': S_matrices,\n",
    "    'P_components': P_components,\n",
    "    'Q_components': Q_components,\n",
    "    'dimension_info': dimension_info,\n",
    "    'metadata': {\n",
    "        'formula': 'S^l = P^l @ (Q^l)^T',\n",
    "        'P_l_formula': 'P^l = [X_A || X_T || A^l_u]',\n",
    "        'Q_l_formula': 'Q^l = [Y_A || Y_T || A^l_p]',\n",
    "        'X_A_dims': 39,\n",
    "        'X_T_dims': 32,\n",
    "        'user_embedding_dims': 71,\n",
    "        'created_at': str(np.datetime64('now')),\n",
    "        'levels': [0, 1, 2, 3]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('feature_checkin_matrices.pkl', 'wb') as f:\n",
    "    pickle.dump(output, f)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… SUCCESS: Feature-based check-in matrices computed and saved!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nğŸ“ Saved to: feature_checkin_matrices.pkl\")\n",
    "print(\"\\nğŸ“‹ Summary:\")\n",
    "for level in range(4):\n",
    "    info = dimension_info[f'level_{level}']\n",
    "    print(f\"  Level {level}: {info['n_users']:>2} users Ã— {info['n_pois']:>4} POIs, \"\n",
    "          f\"scores [{info['S_l_stats']['min']:>7.2f}, {info['S_l_stats']['max']:>7.2f}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a23d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
