{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f7cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, optimizers, losses\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8783eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionAggregator(Model):\n",
    "    \"\"\"\n",
    "    MLP-based Attention Aggregator for inter-level POI feature propagation (TensorFlow)\n",
    "    \n",
    "    Steps:\n",
    "    1. Compute attention scores via MLP\n",
    "    2. Apply softmax normalization\n",
    "    3. Weighted aggregation of child embedding,s\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "\t\t\t\tinput_dim: int, \n",
    "                output_dim: int,\n",
    "\t\t\t\thidden_dim: int = 64, \n",
    "\t\t\t\tdropout_rate: float = 0.1, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: Dimension of child POI embeddings\n",
    "            hidden_dim: Hidden dimension for attention MLP\n",
    "            dropout_rate: Dropout rate\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # MLP for attention score computation\n",
    "        self.attention_dense1 = layers.Dense(\n",
    "            hidden_dim, \n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='attention_dense1'\n",
    "        )\n",
    "        self.attention_dropout1 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.attention_dense2 = layers.Dense(\n",
    "            hidden_dim // 2,\n",
    "            activation='relu',\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='attention_dense2'\n",
    "        )\n",
    "        self.attention_dropout2 = layers.Dropout(dropout_rate)\n",
    "        \n",
    "        self.attention_output = layers.Dense(\n",
    "            1,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='attention_output'\n",
    "        )\n",
    "        \n",
    "        # Output transformation\n",
    "        self.output_dense = layers.Dense(\n",
    "            input_dim,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            name='output_dense'\n",
    "        )\n",
    "        self.output_layernorm = layers.LayerNormalization(name='output_layernorm')\n",
    "        self.output_activation = layers.ReLU()\n",
    "    \n",
    "    def call(self, child_embeddings: tf.Tensor, mask: Optional[tf.Tensor] = None, training: bool = False) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "        \"\"\"\n",
    "        Aggregate child embeddings using attention\n",
    "        \n",
    "        Args:\n",
    "            child_embeddings: (num_children, embed_dim) or (batch, max_children, embed_dim)\n",
    "            mask: Optional mask for padding (1 = valid, 0 = padding)\n",
    "            training: Whether in training mode\n",
    "        \n",
    "        Returns:\n",
    "            aggregated: (embed_dim,) or (batch, embed_dim)\n",
    "            attention_weights: (num_children,) or (batch, max_children)\n",
    "        \"\"\"\n",
    "        # Handle single parent case (2D input)\n",
    "        squeeze_output = False\n",
    "        if len(child_embeddings.shape) == 2:\n",
    "            child_embeddings = tf.expand_dims(child_embeddings, 0)  # (1, num_children, embed_dim)\n",
    "            squeeze_output = True\n",
    "            if mask is not None:\n",
    "                mask = tf.expand_dims(mask, 0)\n",
    "        \n",
    "        batch_size = tf.shape(child_embeddings)[0]\n",
    "        num_children = tf.shape(child_embeddings)[1]\n",
    "        \n",
    "        # Step 1: Compute attention scores via MLP\n",
    "        # (batch, num_children, embed_dim) -> (batch, num_children, hidden_dim)\n",
    "        x = self.attention_dense1(child_embeddings)\n",
    "        x = self.attention_dropout1(x, training=training)\n",
    "        x = self.attention_dense2(x)\n",
    "        x = self.attention_dropout2(x, training=training)\n",
    "        \n",
    "        # (batch, num_children, 1) -> (batch, num_children)\n",
    "        attention_scores = tf.squeeze(self.attention_output(x), axis=-1)\n",
    "        \n",
    "        # Apply mask if provided (set padded positions to -inf)\n",
    "        if mask is not None:\n",
    "            mask = tf.cast(mask, tf.float32)\n",
    "            attention_scores = attention_scores + (1.0 - mask) * (-1e9)\n",
    "        \n",
    "        # Step 2: Softmax normalization\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=-1)  # (batch, num_children)\n",
    "        \n",
    "        # Handle NaN from empty sequences\n",
    "        attention_weights = tf.where(\n",
    "            tf.math.is_nan(attention_weights),\n",
    "            tf.zeros_like(attention_weights),\n",
    "            attention_weights\n",
    "        )\n",
    "        \n",
    "        # Step 3: Weighted aggregation\n",
    "        # (batch, 1, num_children) @ (batch, num_children, embed_dim) -> (batch, 1, embed_dim)\n",
    "        attention_weights_expanded = tf.expand_dims(attention_weights, 1)\n",
    "        aggregated = tf.matmul(attention_weights_expanded, child_embeddings)\n",
    "        aggregated = tf.squeeze(aggregated, axis=1)  # (batch, embed_dim)\n",
    "        \n",
    "        # Output transformation\n",
    "        aggregated = self.projection(aggregated)  # (batch, output_dim)\n",
    "        aggregated = self.output_layernorm(aggregated)\n",
    "        \n",
    "        if squeeze_output:\n",
    "            aggregated = tf.squeeze(aggregated, axis=0)\n",
    "            attention_weights = tf.squeeze(attention_weights, axis=0)\n",
    "        \n",
    "        return aggregated, attention_weights\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'input_dim': self.input_dim,\n",
    "            'output_dim': self.output_dim,\n",
    "            'hidden_dim': self.hidden_dim,\n",
    "            'dropout_rate': self.dropout_rate\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class InterLevelPOIAggregator:\n",
    "    \"\"\"\n",
    "    Build A^l_p: Inter-level POI Feature Matrix (TensorFlow)\n",
    "    \n",
    "    Propagates features from child POIs to parent POIs using attention mechanism.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "\t\t\t\tpoi_tree_file: str,\n",
    "\t\t\t\tpoi_embeddings_file: str,\n",
    "\t\t\t\tmetadata_file: str,\n",
    "\t\t\t\thidden_dim: int = 64,\n",
    "\t\t\t\tdropout_rate: float = 0.1):\n",
    "        \"\"\"\n",
    "        Initialize aggregator\n",
    "        \n",
    "        Args:\n",
    "            poi_tree_file: Path to poi_tree_with_uuids.json\n",
    "            poi_embeddings_file: Path to poi_embeddings.pkl\n",
    "            metadata_file: Path to metadata.pkl\n",
    "            hidden_dim: Hidden dimension for attention MLP\n",
    "            dropout_rate: Dropout rate\n",
    "        \"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"Initializing Inter-Level POI Aggregator (TensorFlow)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Load POI tree\n",
    "        print(f\"\\nLoading POI tree from: {poi_tree_file}\")\n",
    "        with open(poi_tree_file, 'r', encoding='utf-8') as f:\n",
    "            self.poi_tree = json.load(f)\n",
    "        \n",
    "        # Load POI embeddings\n",
    "        print(f\"Loading POI embeddings from: {poi_embeddings_file}\")\n",
    "        with open(poi_embeddings_file, 'rb') as f:\n",
    "            self.poi_embeddings_data = pickle.load(f)\n",
    "        \n",
    "        # Load metadata\n",
    "        print(f\"Loading metadata from: {metadata_file}\")\n",
    "        with open(metadata_file, 'rb') as f:\n",
    "            self.metadata = pickle.load(f)\n",
    "        \n",
    "        # Build parent-children mappings\n",
    "        print(\"\\nBuilding parent-children mappings...\")\n",
    "        self.parent_to_children = self._build_parent_children_mapping()\n",
    "        \n",
    "        # Initialize attention aggregators for each level transition\n",
    "        self.aggregators: Dict[int, AttentionAggregator] = {}\n",
    "        \n",
    "        # Store results\n",
    "        self.A_lp: Dict[str, np.ndarray] = {}\n",
    "        self.attention_weights: Dict[str, Dict] = {}\n",
    "        \n",
    "        print(\"\\nInitialization complete!\")\n",
    "        self._print_summary()\n",
    "    \n",
    "    def _print_summary(self):\n",
    "        \"\"\"Print data summary\"\"\"\n",
    "        print(\"\\n\" + \"-\" * 40)\n",
    "        print(\"Data Summary:\")\n",
    "        for level in range(4):\n",
    "            level_key = f'level_{level}'\n",
    "            if level_key in self.poi_embeddings_data['poi_embeddings']:\n",
    "                shape = self.poi_embeddings_data['poi_embeddings'][level_key]['embeddings'].shape\n",
    "                n_children = sum(\n",
    "                    len(children) \n",
    "                    for children in self.parent_to_children.get(level, {}).values()\n",
    "                )\n",
    "                print(f\"  Level {level}: {shape[0]} POIs, embed_dim={shape[1]}, total_children={n_children}\")\n",
    "    \n",
    "    def _build_parent_children_mapping(self) -> Dict[int, Dict[str, List[str]]]:\n",
    "        \"\"\"\n",
    "        Build mapping: parent_level -> {parent_id -> [child_ids]}\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary: level -> {parent_poi_id -> [child_poi_ids]}\n",
    "        \"\"\"\n",
    "        parent_to_children = {1: {}, 2: {}, 3: {}}\n",
    "        \n",
    "        # For each level, find children from the level below\n",
    "        for child_level in range(3):  # 0, 1, 2\n",
    "            parent_level = child_level + 1\n",
    "            child_level_key = f'level_{child_level}'\n",
    "            \n",
    "            if child_level_key not in self.poi_tree:\n",
    "                continue\n",
    "            \n",
    "            for child_id, child_data in self.poi_tree[child_level_key].items():\n",
    "                parent_id = child_data.get('parent')\n",
    "                \n",
    "                if parent_id:\n",
    "                    if parent_id not in parent_to_children[parent_level]:\n",
    "                        parent_to_children[parent_level][parent_id] = []\n",
    "                    parent_to_children[parent_level][parent_id].append(child_id)\n",
    "        \n",
    "        # Print statistics\n",
    "        for level in [1, 2, 3]:\n",
    "            n_parents = len(parent_to_children[level])\n",
    "            if n_parents > 0:\n",
    "                avg_children = np.mean([len(c) for c in parent_to_children[level].values()])\n",
    "                max_children = max(len(c) for c in parent_to_children[level].values())\n",
    "                print(f\"  Level {level}: {n_parents} parents, avg_children={avg_children:.1f}, max={max_children}\")\n",
    "        \n",
    "        return parent_to_children\n",
    "    \n",
    "    def _get_level_embeddings(self, level: int) -> Tuple[np.ndarray, List[str]]:\n",
    "        \"\"\"Get all embeddings at a level\"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        level_data = self.poi_embeddings_data['poi_embeddings'][level_key]\n",
    "        return level_data['embeddings'], level_data['poi_ids']\n",
    "    \n",
    "    def build_A_lp_level0(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build A^0_p for Level 0 (Building)\n",
    "        \n",
    "        At level 0, there are no children to aggregate.\n",
    "        A^0_p is simply the base POI embeddings Y^0.\n",
    "        \n",
    "        Returns:\n",
    "            A^0_p: (n_pois_level0, embed_dim)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(\"Building A^0_p (Level 0 - Building)\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        Y_0, poi_ids = self._get_level_embeddings(level=0)\n",
    "        \n",
    "        # A^0_p = Y^0 (base embeddings, no aggregation needed)\n",
    "        A_0_p = Y_0.copy()\n",
    "        \n",
    "        print(f\"  A^0_p = Y^0 (base POI embeddings)\")\n",
    "        print(f\"  Shape: {A_0_p.shape}\")\n",
    "        \n",
    "        self.A_lp['level_0'] = A_0_p\n",
    "        self.attention_weights['level_0'] = None  # No attention at level 0\n",
    "        \n",
    "        return A_0_p\n",
    "    \n",
    "    def build_A_lp_higher_level(self,\n",
    "\t\t\t\t\t\t\t\tlevel: int,\n",
    "\t\t\t\t\t\t\t\ttrain_attention: bool = True,\n",
    "\t\t\t\t\t\t\t\tn_epochs: int = 100,\n",
    "\t\t\t\t\t\t\t\tlr: float = 0.001,\n",
    "\t\t\t\t\t\t\t\tbatch_size: int = 32) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build A^l_p for Level 1, 2, or 3 using attention aggregation\n",
    "        \n",
    "        Args:\n",
    "            level: Target level (1, 2, or 3)\n",
    "            train_attention: Whether to train attention weights\n",
    "            n_epochs: Training epochs for attention\n",
    "            lr: Learning rate\n",
    "            batch_size: Batch size for training\n",
    "        \n",
    "        Returns:\n",
    "            A^l_p: (n_pois_at_level, embed_dim)\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Building A^{level}_p (Level {level})\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        child_level = level - 1\n",
    "        child_level_key = f'level_{child_level}'\n",
    "        \n",
    "        # Get child embeddings (use A^(l-1)_p, not raw Y^(l-1))\n",
    "        if child_level_key not in self.A_lp:\n",
    "            raise ValueError(f\"Must build A^{child_level}_p before A^{level}_p\")\n",
    "        \n",
    "        child_A_lp = self.A_lp[child_level_key]\n",
    "        child_poi_ids = self.poi_embeddings_data['poi_embeddings'][child_level_key]['poi_ids']\n",
    "        child_id_to_idx = {pid: idx for idx, pid in enumerate(child_poi_ids)}\n",
    "        \n",
    "        child_embed_dim = child_A_lp.shape[1]\n",
    "        \n",
    "        # Get parent POI IDs at this level\n",
    "        level_key = f'level_{level}'\n",
    "        parent_embeddings, parent_poi_ids = self._get_level_embeddings(level)\n",
    "        n_parents = len(parent_poi_ids)\n",
    "        \n",
    "        print(f\"  Child level {child_level}: {len(child_poi_ids)} POIs, embed_dim={child_embed_dim}\")\n",
    "        print(f\"  Parent level {level}: {n_parents} POIs\")\n",
    "        \n",
    "        # Initialize attention aggregator\n",
    "        aggregator = AttentionAggregator(\n",
    "            input_dim=child_embed_dim,\n",
    "            output_dim=child_embed_dim,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            dropout_rate=self.dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Build the model by calling it once\n",
    "        dummy_input = tf.zeros((1, 1, child_embed_dim))\n",
    "        _ = aggregator(dummy_input)\n",
    "        \n",
    "        self.aggregators[level] = aggregator\n",
    "        \n",
    "        # Get parent-children mapping for this level\n",
    "        parent_children_map = self.parent_to_children.get(level, {})\n",
    "        \n",
    "        if train_attention:\n",
    "            # Training mode: Learn attention weights\n",
    "            print(f\"\\n  Training attention aggregator ({n_epochs} epochs)...\")\n",
    "            self._train_attention_aggregator(\n",
    "                aggregator=aggregator,\n",
    "                child_A_lp=child_A_lp,\n",
    "                child_id_to_idx=child_id_to_idx,\n",
    "                parent_poi_ids=parent_poi_ids,\n",
    "                parent_children_map=parent_children_map,\n",
    "                parent_embeddings=parent_embeddings,\n",
    "                n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "        \n",
    "        # Inference: Compute aggregated embeddings\n",
    "        print(f\"\\n  Computing aggregated embeddings...\")\n",
    "        \n",
    "        parent_aggregated = []\n",
    "        parent_attn_weights = {}\n",
    "        \n",
    "        for parent_idx, parent_id in enumerate(parent_poi_ids):\n",
    "            children_ids = parent_children_map.get(parent_id, [])\n",
    "            \n",
    "            if len(children_ids) == 0:\n",
    "                # No children: Use parent's own embedding from Y^l\n",
    "                aggregated = parent_embeddings[parent_idx]\n",
    "                attn_weights = np.array([1.0])\n",
    "            else:\n",
    "                # Get children embeddings\n",
    "                child_indices = [\n",
    "                    child_id_to_idx[cid]\n",
    "                    for cid in children_ids\n",
    "                    if cid in child_id_to_idx\n",
    "                ]\n",
    "                \n",
    "                if len(child_indices) == 0:\n",
    "                    aggregated = parent_embeddings[parent_idx]\n",
    "                    attn_weights = np.array([1.0])\n",
    "                else:\n",
    "                    child_embeds = tf.constant(\n",
    "                        child_A_lp[child_indices],\n",
    "                        dtype=tf.float32\n",
    "                    )\n",
    "                    \n",
    "                    aggregated, attn_weights = aggregator(child_embeds, training=False)\n",
    "                    aggregated = aggregated.numpy()\n",
    "                    attn_weights = attn_weights.numpy()\n",
    "            \n",
    "            parent_aggregated.append(aggregated)\n",
    "            parent_attn_weights[parent_id] = {\n",
    "                'children': children_ids[:len(attn_weights)] if len(children_ids) > 0 else [],\n",
    "                'weights': attn_weights.tolist()\n",
    "            }\n",
    "        \n",
    "        A_lp = np.stack(parent_aggregated, axis=0).astype(np.float32)\n",
    "        \n",
    "        print(f\"\\n  A^{level}_p shape: {A_lp.shape}\")\n",
    "        print(f\"  Value range: [{A_lp.min():.4f}, {A_lp.max():.4f}]\")\n",
    "        \n",
    "        self.A_lp[level_key] = A_lp\n",
    "        self.attention_weights[level_key] = parent_attn_weights\n",
    "        \n",
    "        return A_lp\n",
    "    \n",
    "    def _train_attention_aggregator(self,\n",
    "                                    aggregator: AttentionAggregator,\n",
    "                                    child_A_lp: np.ndarray,\n",
    "                                    child_id_to_idx: Dict[str, int],\n",
    "                                    parent_poi_ids: List[str],\n",
    "                                    parent_children_map: Dict[str, List[str]],\n",
    "                                    parent_embeddings: np.ndarray,\n",
    "                                    n_epochs: int,\n",
    "                                    lr: float,\n",
    "                                    batch_size: int):\n",
    "        \"\"\"\n",
    "        Train attention aggregator using reconstruction loss\n",
    "        \n",
    "        Objective: Aggregated children embeddings should reconstruct parent embedding\n",
    "        Loss = MSE(aggregated_children, parent_embedding)\n",
    "        \"\"\"\n",
    "        optimizer = optimizers.Adam(learning_rate=lr)\n",
    "        mse_loss = losses.MeanSquaredError()\n",
    "        \n",
    "        # Prepare training data\n",
    "        training_data = []\n",
    "        \n",
    "        for parent_idx, parent_id in enumerate(parent_poi_ids):\n",
    "            children_ids = parent_children_map.get(parent_id, [])\n",
    "            child_indices = [\n",
    "                child_id_to_idx[cid]\n",
    "                for cid in children_ids\n",
    "                if cid in child_id_to_idx\n",
    "            ]\n",
    "            \n",
    "            if len(child_indices) > 0:\n",
    "                training_data.append({\n",
    "                    'parent_idx': parent_idx,\n",
    "                    'child_indices': child_indices,\n",
    "                    'parent_embed': parent_embeddings[parent_idx]\n",
    "                })\n",
    "        \n",
    "        if len(training_data) == 0:\n",
    "            print(\"    No training data available, using uniform attention\")\n",
    "            return\n",
    "        \n",
    "        print(f\"    Training samples: {len(training_data)}\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(n_epochs):\n",
    "            total_loss = 0.0\n",
    "            n_batches = 0\n",
    "            \n",
    "            # Shuffle training data\n",
    "            np.random.shuffle(training_data)\n",
    "            \n",
    "            for data in training_data:\n",
    "                child_embeds = tf.constant(\n",
    "                    child_A_lp[data['child_indices']],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "                parent_embed = tf.constant(\n",
    "                    data['parent_embed'],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "                \n",
    "                with tf.GradientTape() as tape:\n",
    "                    aggregated, _ = aggregator(child_embeds, training=True)\n",
    "                    loss = mse_loss(parent_embed, aggregated)\n",
    "                \n",
    "                gradients = tape.gradient(loss, aggregator.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, aggregator.trainable_variables))\n",
    "                \n",
    "                total_loss += loss.numpy()\n",
    "                n_batches += 1\n",
    "            \n",
    "            avg_loss = total_loss / n_batches\n",
    "            \n",
    "            if (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "                print(f\"    Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    def build_all_A_lp(self,\n",
    "\t\t\t\t\ttrain_attention: bool = True,\n",
    "\t\t\t\t\tn_epochs: int = 100,\n",
    "\t\t\t\t\tlr: float = 0.001,\n",
    "\t\t\t\t\tbatch_size: int = 32) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Build A^l_p for all levels (0 to 3)\n",
    "        \n",
    "        Must be built in order: Level 0 -> 1 -> 2 -> 3\n",
    "        \n",
    "        Args:\n",
    "            train_attention: Whether to train attention weights\n",
    "            n_epochs: Training epochs\n",
    "            lr: Learning rate\n",
    "            batch_size: Batch size\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary: level_key -> A^l_p matrix\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"Building A^l_p for All Levels\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Level 0: Base embeddings\n",
    "        self.build_A_lp_level0()\n",
    "        \n",
    "        # Levels 1, 2, 3: Attention aggregation from children\n",
    "        for level in [1, 2, 3]:\n",
    "            self.build_A_lp_higher_level(\n",
    "                level=level,\n",
    "                train_attention=train_attention,\n",
    "                n_epochs=n_epochs,\n",
    "                lr=lr,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "        \n",
    "        return self.A_lp\n",
    "    \n",
    "    def build_Q_l(self, level: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Build complete POI representation Q^l = [Y_A || Y_T || A^l_p]\n",
    "        \n",
    "        Args:\n",
    "            level: Target level\n",
    "        \n",
    "        Returns:\n",
    "            Q^l: (n_pois, total_dim)\n",
    "        \"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Get Y_A and Y_T from poi_embeddings\n",
    "        poi_data = self.poi_embeddings_data['poi_embeddings'][level_key]\n",
    "        \n",
    "        Y_A = poi_data.get('Y_A')\n",
    "        Y_T = poi_data.get('Y_T')\n",
    "        A_lp = self.A_lp[level_key]\n",
    "        \n",
    "        components = []\n",
    "        component_names = []\n",
    "        \n",
    "        if Y_A is not None:\n",
    "            components.append(Y_A)\n",
    "            component_names.append(f'Y_A ({Y_A.shape[1]})')\n",
    "        \n",
    "        if Y_T is not None:\n",
    "            components.append(Y_T)\n",
    "            component_names.append(f'Y_T ({Y_T.shape[1]})')\n",
    "        \n",
    "        components.append(A_lp)\n",
    "        component_names.append(f'A^{level}_p ({A_lp.shape[1]})')\n",
    "        \n",
    "        # Ensure same number of POIs\n",
    "        n_pois = min(c.shape[0] for c in components)\n",
    "        components = [c[:n_pois] for c in components]\n",
    "        \n",
    "        Q_l = np.hstack(components).astype(np.float32)\n",
    "        \n",
    "        print(f\"\\n  Q^{level} = [{' || '.join(component_names)}]\")\n",
    "        print(f\"  Shape: {Q_l.shape}\")\n",
    "        \n",
    "        return Q_l\n",
    "    \n",
    "    def build_all_Q_l(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Build Q^l for all levels\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary: level_key -> Q^l matrix\n",
    "        \"\"\"\n",
    "        Q_l_all = {}\n",
    "        \n",
    "        print(\"\\n\" + \"-\" * 40)\n",
    "        print(\"Building Q^l = [Y_A || Y_T || A^l_p] for all levels\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        for level in range(4):\n",
    "            Q_l_all[f'level_{level}'] = self.build_Q_l(level)\n",
    "        \n",
    "        return Q_l_all\n",
    "    \n",
    "    def save_results(self, output_file: str = 'poi_interlevel_features.pkl'):\n",
    "        \"\"\"\n",
    "        Save A^l_p and Q^l for all levels\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Saving results to: {output_file}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Build Q^l for all levels\n",
    "        Q_l_all = self.build_all_Q_l()\n",
    "        \n",
    "        # Save aggregator weights\n",
    "        aggregator_weights = {}\n",
    "        for level, agg in self.aggregators.items():\n",
    "            aggregator_weights[level] = {\n",
    "                name: var.numpy() \n",
    "                for name, var in zip(\n",
    "                    [v.name for v in agg.trainable_variables],\n",
    "                    agg.trainable_variables\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        save_data = {\n",
    "            # Inter-level POI features\n",
    "            'A_lp': self.A_lp,\n",
    "            \n",
    "            # Complete POI representations\n",
    "            'Q_l': Q_l_all,\n",
    "            \n",
    "            # Attention weights (for interpretability)\n",
    "            'attention_weights': self.attention_weights,\n",
    "            \n",
    "            # Trained aggregator weights\n",
    "            'aggregator_weights': aggregator_weights,\n",
    "            \n",
    "            # Aggregator config for reconstruction\n",
    "            'aggregator_config': {\n",
    "                'hidden_dim': self.hidden_dim,\n",
    "                'dropout_rate': self.dropout_rate\n",
    "            },\n",
    "            \n",
    "            # Dimensions\n",
    "            'dimensions': {\n",
    "                f'level_{level}': {\n",
    "                    'A_lp_shape': self.A_lp[f'level_{level}'].shape,\n",
    "                    'Q_l_shape': Q_l_all[f'level_{level}'].shape\n",
    "                }\n",
    "                for level in range(4)\n",
    "            },\n",
    "            \n",
    "            # Metadata\n",
    "            'info': {\n",
    "                'created_at': datetime.now().isoformat(),\n",
    "                'formula': 'Q^l = [Y_A || Y_T || A^l_p]',\n",
    "                'aggregation': 'MLP Attention (TensorFlow)',\n",
    "                'hidden_dim': self.hidden_dim,\n",
    "                'framework': 'tensorflow',\n",
    "                'tf_version': tf.__version__\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump(save_data, f)\n",
    "        \n",
    "        file_size = os.path.getsize(output_file) / (1024 * 1024)\n",
    "        print(f\"\\n  File size: {file_size:.2f} MB\")\n",
    "        \n",
    "        print(\"\\n  Saved matrices:\")\n",
    "        for level in range(4):\n",
    "            level_key = f'level_{level}'\n",
    "            print(f\"    Level {level}:\")\n",
    "            print(f\"      A^{level}_p: {self.A_lp[level_key].shape}\")\n",
    "            print(f\"      Q^{level}: {Q_l_all[level_key].shape}\")\n",
    "        \n",
    "        return save_data\n",
    "\n",
    "\n",
    "def build_A_lp_and_Q_l(poi_tree_file: str = 'poi_tree_with_uuids.json',\n",
    "                        poi_embeddings_file: str = 'poi_embeddings.pkl',\n",
    "                        metadata_file: str = 'metadata.pkl',\n",
    "                        output_file: str = 'poi_interlevel_features.pkl',\n",
    "                        hidden_dim: int = 64,\n",
    "                        dropout_rate: float = 0.1,\n",
    "                        n_epochs: int = 100,\n",
    "                        lr: float = 0.001) -> Dict:\n",
    "    \"\"\"\n",
    "    Main function to build A^l_p and Q^l for all levels\n",
    "    \n",
    "    Args:\n",
    "        poi_tree_file: Path to POI tree JSON\n",
    "        poi_embeddings_file: Path to POI embeddings pickle\n",
    "        metadata_file: Path to metadata pickle\n",
    "        output_file: Output file path\n",
    "        hidden_dim: Hidden dimension for attention MLP\n",
    "        dropout_rate: Dropout rate\n",
    "        n_epochs: Training epochs\n",
    "        lr: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with A^l_p and Q^l for all levels\n",
    "    \"\"\"\n",
    "    aggregator = InterLevelPOIAggregator(\n",
    "        poi_tree_file=poi_tree_file,\n",
    "        poi_embeddings_file=poi_embeddings_file,\n",
    "        metadata_file=metadata_file,\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout_rate=dropout_rate\n",
    "    )\n",
    "    \n",
    "    # Build A^l_p for all levels\n",
    "    aggregator.build_all_A_lp(\n",
    "        train_attention=True,\n",
    "        n_epochs=n_epochs,\n",
    "        lr=lr\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    save_data = aggregator.save_results(output_file)\n",
    "    \n",
    "    return save_data\n",
    "\n",
    "\n",
    "class AttentionAggregatorLoader:\n",
    "    \"\"\"\n",
    "    Utility class to load and use trained attention aggregators\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, saved_file: str = 'poi_interlevel_features.pkl'):\n",
    "        \"\"\"\n",
    "        Load saved attention aggregators\n",
    "        \n",
    "        Args:\n",
    "            saved_file: Path to saved pickle file\n",
    "        \"\"\"\n",
    "        with open(saved_file, 'rb') as f:\n",
    "            self.data = pickle.load(f)\n",
    "        \n",
    "        self.A_lp = self.data['A_lp']\n",
    "        self.Q_l = self.data['Q_l']\n",
    "        self.attention_weights = self.data['attention_weights']\n",
    "        self.config = self.data['aggregator_config']\n",
    "    \n",
    "    def get_A_lp(self, level: int) -> np.ndarray:\n",
    "        \"\"\"Get A^l_p for a specific level\"\"\"\n",
    "        return self.A_lp[f'level_{level}']\n",
    "    \n",
    "    def get_Q_l(self, level: int) -> np.ndarray:\n",
    "        \"\"\"Get Q^l for a specific level\"\"\"\n",
    "        return self.Q_l[f'level_{level}']\n",
    "    \n",
    "    def get_attention_weights(self, level: int, parent_id: str) -> Dict:\n",
    "        \"\"\"Get attention weights for a specific parent POI\"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        if level_key in self.attention_weights and self.attention_weights[level_key]:\n",
    "            return self.attention_weights[level_key].get(parent_id, {})\n",
    "        return {}\n",
    "    \n",
    "    def get_top_k_children(self, level: int, parent_id: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get top-k children by attention weight for a parent POI\n",
    "        \n",
    "        Args:\n",
    "            level: Parent level\n",
    "            parent_id: Parent POI ID\n",
    "            k: Number of top children to return\n",
    "        \n",
    "        Returns:\n",
    "            List of (child_id, attention_weight) tuples\n",
    "        \"\"\"\n",
    "        attn_data = self.get_attention_weights(level, parent_id)\n",
    "        \n",
    "        if not attn_data or 'children' not in attn_data:\n",
    "            return []\n",
    "        \n",
    "        children = attn_data['children']\n",
    "        weights = attn_data['weights']\n",
    "        \n",
    "        pairs = list(zip(children, weights))\n",
    "        pairs.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return pairs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7f55b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTER-LEVEL POI FEATURE (A^l_p) GENERATION - TensorFlow\n",
      "============================================================\n",
      "============================================================\n",
      "Initializing Inter-Level POI Aggregator (TensorFlow)\n",
      "============================================================\n",
      "\n",
      "Loading POI tree from: ../../Sources/Files/poi_tree_with_uuids.json\n",
      "Loading POI embeddings from: ../../Sources/Embeddings/poi_embeddings.pkl\n",
      "Loading metadata from: ../../Sources/Embeddings/metadata.pkl\n",
      "\n",
      "Building parent-children mappings...\n",
      "  Level 1: 968 parents, avg_children=4.9, max=561\n",
      "  Level 2: 44 parents, avg_children=30.8, max=125\n",
      "  Level 3: 5 parents, avg_children=8.8, max=20\n",
      "\n",
      "Initialization complete!\n",
      "\n",
      "----------------------------------------\n",
      "Data Summary:\n",
      "  Level 0: 4696 POIs, embed_dim=221, total_children=0\n",
      "  Level 1: 1355 POIs, embed_dim=171, total_children=4696\n",
      "  Level 2: 44 POIs, embed_dim=125, total_children=1355\n",
      "  Level 3: 5 POIs, embed_dim=105, total_children=44\n",
      "\n",
      "============================================================\n",
      "Building A^l_p for All Levels\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Building A^0_p (Level 0 - Building)\n",
      "============================================================\n",
      "  A^0_p = Y^0 (base POI embeddings)\n",
      "  Shape: (4696, 221)\n",
      "\n",
      "============================================================\n",
      "Building A^1_p (Level 1)\n",
      "============================================================\n",
      "  Child level 0: 4696 POIs, embed_dim=221\n",
      "  Parent level 1: 1355 POIs\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling layer \"attention_aggregator_1\" \"                 f\"(type AttentionAggregator).\n\n'AttentionAggregator' object has no attribute 'projection'\n\nCall arguments received by layer \"attention_aggregator_1\" \"                 f\"(type AttentionAggregator):\n  • child_embeddings=tf.Tensor(shape=(1, 1, 221), dtype=float32)\n  • mask=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Build A^l_p and Q^l\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_A_lp_and_Q_l\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoi_tree_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoi_tree_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoi_embeddings_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoi_embeddings_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Summary\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 691\u001b[0m, in \u001b[0;36mbuild_A_lp_and_Q_l\u001b[1;34m(poi_tree_file, poi_embeddings_file, metadata_file, output_file, hidden_dim, dropout_rate, n_epochs, lr)\u001b[0m\n\u001b[0;32m    682\u001b[0m aggregator \u001b[38;5;241m=\u001b[39m InterLevelPOIAggregator(\n\u001b[0;32m    683\u001b[0m     poi_tree_file\u001b[38;5;241m=\u001b[39mpoi_tree_file,\n\u001b[0;32m    684\u001b[0m     poi_embeddings_file\u001b[38;5;241m=\u001b[39mpoi_embeddings_file,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    687\u001b[0m     dropout_rate\u001b[38;5;241m=\u001b[39mdropout_rate\n\u001b[0;32m    688\u001b[0m )\n\u001b[0;32m    690\u001b[0m \u001b[38;5;66;03m# Build A^l_p for all levels\u001b[39;00m\n\u001b[1;32m--> 691\u001b[0m \u001b[43maggregator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_all_A_lp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[0;32m    698\u001b[0m save_data \u001b[38;5;241m=\u001b[39m aggregator\u001b[38;5;241m.\u001b[39msave_results(output_file)\n",
      "Cell \u001b[1;32mIn[7], line 509\u001b[0m, in \u001b[0;36mInterLevelPOIAggregator.build_all_A_lp\u001b[1;34m(self, train_attention, n_epochs, lr, batch_size)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# Levels 1, 2, 3: Attention aggregation from children\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m level \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_A_lp_higher_level\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_attention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mA_lp\n",
      "Cell \u001b[1;32mIn[7], line 333\u001b[0m, in \u001b[0;36mInterLevelPOIAggregator.build_A_lp_higher_level\u001b[1;34m(self, level, train_attention, n_epochs, lr, batch_size)\u001b[0m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# Build the model by calling it once\u001b[39;00m\n\u001b[0;32m    332\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, child_embed_dim))\n\u001b[1;32m--> 333\u001b[0m _ \u001b[38;5;241m=\u001b[39m \u001b[43maggregator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregators[level] \u001b[38;5;241m=\u001b[39m aggregator\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Get parent-children mapping for this level\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[1;32mIn[7], line 118\u001b[0m, in \u001b[0;36mAttentionAggregator.call\u001b[1;34m(self, child_embeddings, mask, training)\u001b[0m\n\u001b[0;32m    115\u001b[0m aggregated \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msqueeze(aggregated, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch, embed_dim)\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Output transformation\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m aggregated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojection\u001b[49m(aggregated)  \u001b[38;5;66;03m# (batch, output_dim)\u001b[39;00m\n\u001b[0;32m    119\u001b[0m aggregated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layernorm(aggregated)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m squeeze_output:\n",
      "\u001b[1;31mAttributeError\u001b[0m: Exception encountered when calling layer \"attention_aggregator_1\" \"                 f\"(type AttentionAggregator).\n\n'AttentionAggregator' object has no attribute 'projection'\n\nCall arguments received by layer \"attention_aggregator_1\" \"                 f\"(type AttentionAggregator):\n  • child_embeddings=tf.Tensor(shape=(1, 1, 221), dtype=float32)\n  • mask=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    poi_tree_file = \"../../Sources/Files/poi_tree_with_uuids.json\"\n",
    "    poi_embeddings_file = \"../../Sources/Embeddings/poi_embeddings.pkl\"\n",
    "    metadata_file = \"../../Sources/Embeddings/metadata.pkl\"\n",
    "    output_file = \"../../Sources/Embeddings/poi_interlevel_features.pkl\"\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"INTER-LEVEL POI FEATURE (A^l_p) GENERATION - TensorFlow\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Build A^l_p and Q^l\n",
    "    result = build_A_lp_and_Q_l(\n",
    "        poi_tree_file=poi_tree_file,\n",
    "        poi_embeddings_file=poi_embeddings_file,\n",
    "        metadata_file=metadata_file,\n",
    "        output_file=output_file,\n",
    "        hidden_dim=64,\n",
    "        dropout_rate=0.1,\n",
    "        n_epochs=100,\n",
    "        lr=0.001\n",
    "    )\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\nA^l_p (Inter-level POI Features):\")\n",
    "    for level in range(4):\n",
    "        shape = result['A_lp'][f'level_{level}'].shape\n",
    "        print(f\"  Level {level}: {shape}\")\n",
    "    \n",
    "    print(\"\\nQ^l (Complete POI Representations):\")\n",
    "    for level in range(4):\n",
    "        shape = result['Q_l'][f'level_{level}'].shape\n",
    "        print(f\"  Level {level}: {shape}\")\n",
    "    \n",
    "    # Demo: Load and use\n",
    "    print(\"\\n\" + \"-\" * 40)\n",
    "    print(\"DEMO: Using AttentionAggregatorLoader\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    loader = AttentionAggregatorLoader(output_file)\n",
    "    \n",
    "    print(\"\\nQ^l matrices loaded:\")\n",
    "    for level in range(4):\n",
    "        Q = loader.get_Q_l(level)\n",
    "        print(f\"  Level {level}: {Q.shape}\")\n",
    "    \n",
    "    # Example: Get top children for a parent (if attention weights available)\n",
    "    if loader.attention_weights.get('level_1'):\n",
    "        sample_parent = list(loader.attention_weights['level_1'].keys())[0]\n",
    "        top_children = loader.get_top_k_children(level=1, parent_id=sample_parent, k=3)\n",
    "        print(f\"\\nTop 3 children for parent '{sample_parent}' at level 1:\")\n",
    "        for child_id, weight in top_children:\n",
    "            print(f\"  - {child_id}: {weight:.4f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"COMPLETE\")\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2939e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
