{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f7cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, optimizers, losses\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8783eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionAggregator(Model):\n",
    "\t\"\"\"\n",
    "\tMLP-based Attention Aggregator for inter-level POI feature propagation (TensorFlow)\n",
    "\t\n",
    "\tSteps:\n",
    "\t1. Compute attention scores via MLP\n",
    "\t2. Apply softmax normalization\n",
    "\t3. Weighted aggregation of child embedding,s\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self, \n",
    "\t\t\t\tinput_dim: int, \n",
    "\t\t\t\toutput_dim: int,\n",
    "\t\t\t\thidden_dim: int = 64, \n",
    "\t\t\t\tdropout_rate: float = 0.1, \n",
    "\t\t\t\t **kwargs):\n",
    "\t\t\"\"\"\n",
    "\t\tArgs:\n",
    "\t\t\tinput_dim: Dimension of child POI embeddings\n",
    "\t\t\thidden_dim: Hidden dimension for attention MLP\n",
    "\t\t\tdropout_rate: Dropout rate\n",
    "\t\t\"\"\"\n",
    "\t\tsuper().__init__(**kwargs)\n",
    "\t\t\n",
    "\t\tself.input_dim = input_dim\n",
    "\t\tself.output_dim = output_dim\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.dropout_rate = dropout_rate\n",
    "\t\t\n",
    "\t\t# MLP for attention score computation\n",
    "\t\tself.attention_dense1 = layers.Dense(\n",
    "\t\t\thidden_dim, \n",
    "\t\t\tactivation='relu',\n",
    "\t\t\tkernel_initializer='glorot_uniform',\n",
    "\t\t\tname='attention_dense1'\n",
    "\t\t)\n",
    "\t\tself.attention_dropout1 = layers.Dropout(dropout_rate)\n",
    "\t\t\n",
    "\t\tself.attention_dense2 = layers.Dense(\n",
    "\t\t\thidden_dim // 2,\n",
    "\t\t\tactivation='relu',\n",
    "\t\t\tkernel_initializer='glorot_uniform',\n",
    "\t\t\tname='attention_dense2'\n",
    "\t\t)\n",
    "\t\tself.attention_dropout2 = layers.Dropout(dropout_rate)\n",
    "\t\t\n",
    "\t\tself.attention_output = layers.Dense(\n",
    "\t\t\t1,\n",
    "\t\t\tkernel_initializer='glorot_uniform',\n",
    "\t\t\tname='attention_output'\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Output transformation\n",
    "\t\tself.projection = layers.Dense(\n",
    "\t\t\toutput_dim,\n",
    "\t\t\tkernel_initializer='glorot_uniform',\n",
    "\t\t\tname='projection'\n",
    "\t\t)\n",
    "\t\tself.output_layernorm = layers.LayerNormalization(name='output_layernorm')\n",
    "\t\tself.output_activation = layers.ReLU()\n",
    "\t\n",
    "\tdef call(self, child_embeddings: tf.Tensor, mask: Optional[tf.Tensor] = None, training: bool = False) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "\t\t\"\"\"\n",
    "\t\tAggregate child embeddings using attention\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tchild_embeddings: (num_children, embed_dim) or (batch, max_children, embed_dim)\n",
    "\t\t\tmask: Optional mask for padding (1 = valid, 0 = padding)\n",
    "\t\t\ttraining: Whether in training mode\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\taggregated: (embed_dim,) or (batch, embed_dim)\n",
    "\t\t\tattention_weights: (num_children,) or (batch, max_children)\n",
    "\t\t\"\"\"\n",
    "\t\t# Handle single parent case (2D input)\n",
    "\t\tsqueeze_output = False\n",
    "\t\tif len(child_embeddings.shape) == 2:\n",
    "\t\t\tchild_embeddings = tf.expand_dims(child_embeddings, 0)  # (1, num_children, embed_dim)\n",
    "\t\t\tsqueeze_output = True\n",
    "\t\t\tif mask is not None:\n",
    "\t\t\t\tmask = tf.expand_dims(mask, 0)\n",
    "\t\t\n",
    "\t\tbatch_size = tf.shape(child_embeddings)[0]\n",
    "\t\tnum_children = tf.shape(child_embeddings)[1]\n",
    "\t\t\n",
    "\t\t# Step 1: Compute attention scores via MLP\n",
    "\t\t# (batch, num_children, embed_dim) -> (batch, num_children, hidden_dim)\n",
    "\t\tx = self.attention_dense1(child_embeddings)\n",
    "\t\tx = self.attention_dropout1(x, training=training)\n",
    "\t\tx = self.attention_dense2(x)\n",
    "\t\tx = self.attention_dropout2(x, training=training)\n",
    "\t\t\n",
    "\t\t# (batch, num_children, 1) -> (batch, num_children)\n",
    "\t\tattention_scores = tf.squeeze(self.attention_output(x), axis=-1)\n",
    "\t\t\n",
    "\t\t# Apply mask if provided (set padded positions to -inf)\n",
    "\t\tif mask is not None:\n",
    "\t\t\tmask = tf.cast(mask, tf.float32)\n",
    "\t\t\tattention_scores = attention_scores + (1.0 - mask) * (-1e9)\n",
    "\t\t\n",
    "\t\t# Step 2: Softmax normalization\n",
    "\t\tattention_weights = tf.nn.softmax(attention_scores, axis=-1)  # (batch, num_children)\n",
    "\t\t\n",
    "\t\t# Handle NaN from empty sequences\n",
    "\t\tattention_weights = tf.where(\n",
    "\t\t\ttf.math.is_nan(attention_weights),\n",
    "\t\t\ttf.zeros_like(attention_weights),\n",
    "\t\t\tattention_weights\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Step 3: Weighted aggregation\n",
    "\t\t# (batch, 1, num_children) @ (batch, num_children, embed_dim) -> (batch, 1, embed_dim)\n",
    "\t\tattention_weights_expanded = tf.expand_dims(attention_weights, 1)\n",
    "\t\taggregated = tf.matmul(attention_weights_expanded, child_embeddings)\n",
    "\t\taggregated = tf.squeeze(aggregated, axis=1)  # (batch, embed_dim)\n",
    "\t\t\n",
    "\t\t# Output transformation\n",
    "\t\taggregated = self.projection(aggregated)  # (batch, output_dim)\n",
    "\t\taggregated = self.output_layernorm(aggregated)\n",
    "\t\t\n",
    "\t\tif squeeze_output:\n",
    "\t\t\taggregated = tf.squeeze(aggregated, axis=0)\n",
    "\t\t\tattention_weights = tf.squeeze(attention_weights, axis=0)\n",
    "\t\t\n",
    "\t\treturn aggregated, attention_weights\n",
    "\t\n",
    "\tdef get_config(self):\n",
    "\t\tconfig = super().get_config()\n",
    "\t\tconfig.update({\n",
    "\t\t\t'input_dim': self.input_dim,\n",
    "\t\t\t'output_dim': self.output_dim,\n",
    "\t\t\t'hidden_dim': self.hidden_dim,\n",
    "\t\t\t'dropout_rate': self.dropout_rate\n",
    "\t\t})\n",
    "\t\treturn config\n",
    "\n",
    "\n",
    "class InterLevelPOIAggregator:\n",
    "\t\"\"\"\n",
    "\tBuild A^l_p: Inter-level POI Feature Matrix (TensorFlow)\n",
    "\t\n",
    "\tPropagates features from child POIs to parent POIs using attention mechanism.\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self,\n",
    "\t\t\t\tpoi_tree_file: str,\n",
    "\t\t\t\tpoi_embeddings_file: str,\n",
    "\t\t\t\tmetadata_file: str,\n",
    "\t\t\t\thidden_dim: int = 64,\n",
    "\t\t\t\tdropout_rate: float = 0.1):\n",
    "\t\t\"\"\"\n",
    "\t\tInitialize aggregator\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tpoi_tree_file: Path to poi_tree_with_uuids.json\n",
    "\t\t\tpoi_embeddings_file: Path to poi_embeddings.pkl\n",
    "\t\t\tmetadata_file: Path to metadata.pkl\n",
    "\t\t\thidden_dim: Hidden dimension for attention MLP\n",
    "\t\t\tdropout_rate: Dropout rate\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\tprint(\"Initializing Inter-Level POI Aggregator (TensorFlow)\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\tself.hidden_dim = hidden_dim\n",
    "\t\tself.dropout_rate = dropout_rate\n",
    "\t\t\n",
    "\t\t# Load POI tree\n",
    "\t\tprint(f\"\\nLoading POI tree from: {poi_tree_file}\")\n",
    "\t\twith open(poi_tree_file, 'r', encoding='utf-8') as f:\n",
    "\t\t\tself.poi_tree = json.load(f)\n",
    "\t\t\n",
    "\t\t# Load POI embeddings\n",
    "\t\tprint(f\"Loading POI embeddings from: {poi_embeddings_file}\")\n",
    "\t\twith open(poi_embeddings_file, 'rb') as f:\n",
    "\t\t\tself.poi_embeddings_data = pickle.load(f)\n",
    "\t\t\n",
    "\t\t# Load metadata\n",
    "\t\tprint(f\"Loading metadata from: {metadata_file}\")\n",
    "\t\twith open(metadata_file, 'rb') as f:\n",
    "\t\t\tself.metadata = pickle.load(f)\n",
    "\t\t\n",
    "\t\t# Build parent-children mappings\n",
    "\t\tprint(\"\\nBuilding parent-children mappings...\")\n",
    "\t\tself.parent_to_children = self._build_parent_children_mapping()\n",
    "\t\t\n",
    "\t\t# Initialize attention aggregators for each level transition\n",
    "\t\tself.aggregators: Dict[int, AttentionAggregator] = {}\n",
    "\t\t\n",
    "\t\t# Store results\n",
    "\t\tself.A_lp: Dict[str, np.ndarray] = {}\n",
    "\t\tself.attention_weights: Dict[str, Dict] = {}\n",
    "\t\t\n",
    "\t\tprint(\"\\nInitialization complete!\")\n",
    "\t\tself._print_summary()\n",
    "\t\n",
    "\tdef _print_summary(self):\n",
    "\t\t\"\"\"Print data summary\"\"\"\n",
    "\t\tprint(\"\\n\" + \"-\" * 40)\n",
    "\t\tprint(\"Data Summary:\")\n",
    "\t\tfor level in range(4):\n",
    "\t\t\tlevel_key = f'level_{level}'\n",
    "\t\t\tif level_key in self.poi_embeddings_data['poi_embeddings']:\n",
    "\t\t\t\tshape = self.poi_embeddings_data['poi_embeddings'][level_key]['embeddings'].shape\n",
    "\t\t\t\tn_children = sum(\n",
    "\t\t\t\t\tlen(children) \n",
    "\t\t\t\t\tfor children in self.parent_to_children.get(level, {}).values()\n",
    "\t\t\t\t)\n",
    "\t\t\t\tprint(f\"  Level {level}: {shape[0]} POIs, embed_dim={shape[1]}, total_children={n_children}\")\n",
    "\t\n",
    "\tdef _build_parent_children_mapping(self) -> Dict[int, Dict[str, List[str]]]:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild mapping: parent_level -> {parent_id -> [child_ids]}\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary: level -> {parent_poi_id -> [child_poi_ids]}\n",
    "\t\t\"\"\"\n",
    "\t\tparent_to_children = {1: {}, 2: {}, 3: {}}\n",
    "\t\t\n",
    "\t\t# For each level, find children from the level below\n",
    "\t\tfor child_level in range(3):  # 0, 1, 2\n",
    "\t\t\tparent_level = child_level + 1\n",
    "\t\t\tchild_level_key = f'level_{child_level}'\n",
    "\t\t\t\n",
    "\t\t\tif child_level_key not in self.poi_tree:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\t\tfor child_id, child_data in self.poi_tree[child_level_key].items():\n",
    "\t\t\t\tparent_id = child_data.get('parent')\n",
    "\t\t\t\t\n",
    "\t\t\t\tif parent_id:\n",
    "\t\t\t\t\tif parent_id not in parent_to_children[parent_level]:\n",
    "\t\t\t\t\t\tparent_to_children[parent_level][parent_id] = []\n",
    "\t\t\t\t\tparent_to_children[parent_level][parent_id].append(child_id)\n",
    "\t\t\n",
    "\t\t# Print statistics\n",
    "\t\tfor level in [1, 2, 3]:\n",
    "\t\t\tn_parents = len(parent_to_children[level])\n",
    "\t\t\tif n_parents > 0:\n",
    "\t\t\t\tavg_children = np.mean([len(c) for c in parent_to_children[level].values()])\n",
    "\t\t\t\tmax_children = max(len(c) for c in parent_to_children[level].values())\n",
    "\t\t\t\tprint(f\"  Level {level}: {n_parents} parents, avg_children={avg_children:.1f}, max={max_children}\")\n",
    "\t\t\n",
    "\t\treturn parent_to_children\n",
    "\t\n",
    "\tdef _get_level_embeddings(self, level: int) -> Tuple[np.ndarray, List[str]]:\n",
    "\t\t\"\"\"Get all embeddings at a level\"\"\"\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\tlevel_data = self.poi_embeddings_data['poi_embeddings'][level_key]\n",
    "\t\treturn level_data['embeddings'], level_data['poi_ids']\n",
    "\t\n",
    "\tdef build_A_lp_level0(self) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild A^0_p for Level 0 (Building)\n",
    "\t\t\n",
    "\t\tAt level 0, there are no children to aggregate.\n",
    "\t\tA^0_p is simply the base POI embeddings Y^0.\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tA^0_p: (n_pois_level0, embed_dim)\n",
    "\t\t\"\"\"\n",
    "\t\tprint(f\"\\n{'=' * 60}\")\n",
    "\t\tprint(\"Building A^0_p (Level 0 - Building)\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\tY_0, poi_ids = self._get_level_embeddings(level=0)\n",
    "\t\t\n",
    "\t\t# A^0_p = Y^0 (base embeddings, no aggregation needed)\n",
    "\t\tA_0_p = Y_0.copy()\n",
    "\t\t\n",
    "\t\tprint(f\"  A^0_p = Y^0 (base POI embeddings)\")\n",
    "\t\tprint(f\"  Shape: {A_0_p.shape}\")\n",
    "\t\t\n",
    "\t\tself.A_lp['level_0'] = A_0_p\n",
    "\t\tself.attention_weights['level_0'] = None  # No attention at level 0\n",
    "\t\t\n",
    "\t\treturn A_0_p\n",
    "\t\n",
    "\tdef build_A_lp_higher_level(self,\n",
    "\t\t\t\t\t\t\t\tlevel: int,\n",
    "\t\t\t\t\t\t\t\ttrain_attention: bool = True,\n",
    "\t\t\t\t\t\t\t\tn_epochs: int = 100,\n",
    "\t\t\t\t\t\t\t\tlr: float = 0.001,\n",
    "\t\t\t\t\t\t\t\tbatch_size: int = 32) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild A^l_p for Level 1, 2, or 3 using attention aggregation\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tlevel: Target level (1, 2, or 3)\n",
    "\t\t\ttrain_attention: Whether to train attention weights\n",
    "\t\t\tn_epochs: Training epochs for attention\n",
    "\t\t\tlr: Learning rate\n",
    "\t\t\tbatch_size: Batch size for training\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tA^l_p: (n_pois_at_level, embed_dim)\n",
    "\t\t\"\"\"\n",
    "\t\tprint(f\"\\n{'=' * 60}\")\n",
    "\t\tprint(f\"Building A^{level}_p (Level {level})\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\tchild_level = level - 1\n",
    "\t\tchild_level_key = f'level_{child_level}'\n",
    "\t\t\n",
    "\t\t# Get child embeddings (use A^(l-1)_p, not raw Y^(l-1))\n",
    "\t\tif child_level_key not in self.A_lp:\n",
    "\t\t\traise ValueError(f\"Must build A^{child_level}_p before A^{level}_p\")\n",
    "\t\t\n",
    "\t\tchild_A_lp = self.A_lp[child_level_key]\n",
    "\t\tchild_poi_ids = self.poi_embeddings_data['poi_embeddings'][child_level_key]['poi_ids']\n",
    "\t\tchild_id_to_idx = {pid: idx for idx, pid in enumerate(child_poi_ids)}\n",
    "\t\t\n",
    "\t\tchild_embed_dim = child_A_lp.shape[1]\n",
    "\t\t\n",
    "\t\t# Get parent POI IDs at this level\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\tparent_embeddings, parent_poi_ids = self._get_level_embeddings(level)\n",
    "\t\tn_parents = len(parent_poi_ids)\n",
    "\n",
    "\t\tparent_embed_dim = parent_embeddings.shape[1]\n",
    "\t\t\n",
    "\t\tprint(f\"  Child level {child_level}: {len(child_poi_ids)} POIs, embed_dim={child_embed_dim}\")\n",
    "\t\tprint(f\"  Parent level {level}: {n_parents} POIs\")\n",
    "\t\t\n",
    "\t\t# Initialize attention aggregator\n",
    "\t\taggregator = AttentionAggregator(\n",
    "\t\t\tinput_dim=child_embed_dim,\n",
    "\t\t\toutput_dim=parent_embed_dim,\n",
    "\t\t\thidden_dim=self.hidden_dim,\n",
    "\t\t\tdropout_rate=self.dropout_rate\n",
    "\t\t)\n",
    "\t\t\n",
    "\t\t# Build the model by calling it once\n",
    "\t\tdummy_input = tf.zeros((1, 1, child_embed_dim))\n",
    "\t\t_ = aggregator(dummy_input)\n",
    "\t\t\n",
    "\t\tself.aggregators[level] = aggregator\n",
    "\t\t\n",
    "\t\t# Get parent-children mapping for this level\n",
    "\t\tparent_children_map = self.parent_to_children.get(level, {})\n",
    "\t\t\n",
    "\t\tif train_attention:\n",
    "\t\t\t# Training mode: Learn attention weights\n",
    "\t\t\tprint(f\"\\n  Training attention aggregator ({n_epochs} epochs)...\")\n",
    "\t\t\tself._train_attention_aggregator(\n",
    "\t\t\t\taggregator=aggregator,\n",
    "\t\t\t\tchild_A_lp=child_A_lp,\n",
    "\t\t\t\tchild_id_to_idx=child_id_to_idx,\n",
    "\t\t\t\tparent_poi_ids=parent_poi_ids,\n",
    "\t\t\t\tparent_children_map=parent_children_map,\n",
    "\t\t\t\tparent_embeddings=parent_embeddings,\n",
    "\t\t\t\tn_epochs=n_epochs,\n",
    "\t\t\t\tlr=lr,\n",
    "\t\t\t\tbatch_size=batch_size\n",
    "\t\t\t)\n",
    "\t\t\n",
    "\t\t# Inference: Compute aggregated embeddings\n",
    "\t\tprint(f\"\\n  Computing aggregated embeddings...\")\n",
    "\t\t\n",
    "\t\tparent_aggregated = []\n",
    "\t\tparent_attn_weights = {}\n",
    "\t\t\n",
    "\t\tfor parent_idx, parent_id in enumerate(parent_poi_ids):\n",
    "\t\t\tchildren_ids = parent_children_map.get(parent_id, [])\n",
    "\t\t\t\n",
    "\t\t\tif len(children_ids) == 0:\n",
    "\t\t\t\t# No children: Use parent's own embedding from Y^l\n",
    "\t\t\t\taggregated = parent_embeddings[parent_idx]\n",
    "\t\t\t\tattn_weights = np.array([1.0])\n",
    "\t\t\telse:\n",
    "\t\t\t\t# Get children embeddings\n",
    "\t\t\t\tchild_indices = [\n",
    "\t\t\t\t\tchild_id_to_idx[cid]\n",
    "\t\t\t\t\tfor cid in children_ids\n",
    "\t\t\t\t\tif cid in child_id_to_idx\n",
    "\t\t\t\t]\n",
    "\t\t\t\t\n",
    "\t\t\t\tif len(child_indices) == 0:\n",
    "\t\t\t\t\taggregated = parent_embeddings[parent_idx]\n",
    "\t\t\t\t\tattn_weights = np.array([1.0])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tchild_embeds = tf.constant(\n",
    "\t\t\t\t\t\tchild_A_lp[child_indices],\n",
    "\t\t\t\t\t\tdtype=tf.float32\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\taggregated, attn_weights = aggregator(child_embeds, training=False)\n",
    "\t\t\t\t\taggregated = aggregated.numpy()\n",
    "\t\t\t\t\tattn_weights = attn_weights.numpy()\n",
    "\t\t\t\n",
    "\t\t\tparent_aggregated.append(aggregated)\n",
    "\t\t\tparent_attn_weights[parent_id] = {\n",
    "\t\t\t\t'children': children_ids[:len(attn_weights)] if len(children_ids) > 0 else [],\n",
    "\t\t\t\t'weights': attn_weights.tolist()\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\tA_lp = np.stack(parent_aggregated, axis=0).astype(np.float32)\n",
    "\t\t\n",
    "\t\tprint(f\"\\n  A^{level}_p shape: {A_lp.shape}\")\n",
    "\t\tprint(f\"  Value range: [{A_lp.min():.4f}, {A_lp.max():.4f}]\")\n",
    "\t\t\n",
    "\t\tself.A_lp[level_key] = A_lp\n",
    "\t\tself.attention_weights[level_key] = parent_attn_weights\n",
    "\t\t\n",
    "\t\treturn A_lp\n",
    "\t\n",
    "\tdef _train_attention_aggregator(self,\n",
    "\t\t\t\t\t\t\t\t\taggregator: AttentionAggregator,\n",
    "\t\t\t\t\t\t\t\t\tchild_A_lp: np.ndarray,\n",
    "\t\t\t\t\t\t\t\t\tchild_id_to_idx: Dict[str, int],\n",
    "\t\t\t\t\t\t\t\t\tparent_poi_ids: List[str],\n",
    "\t\t\t\t\t\t\t\t\tparent_children_map: Dict[str, List[str]],\n",
    "\t\t\t\t\t\t\t\t\tparent_embeddings: np.ndarray,\n",
    "\t\t\t\t\t\t\t\t\tn_epochs: int,\n",
    "\t\t\t\t\t\t\t\t\tlr: float,\n",
    "\t\t\t\t\t\t\t\t\tbatch_size: int):\n",
    "\t\t\"\"\"\n",
    "\t\tTrain attention aggregator using reconstruction loss\n",
    "\t\t\n",
    "\t\tObjective: Aggregated children embeddings should reconstruct parent embedding\n",
    "\t\tLoss = MSE(aggregated_children, parent_embedding)\n",
    "\t\t\"\"\"\n",
    "\t\toptimizer = optimizers.Adam(learning_rate=lr)\n",
    "\t\tmse_loss = losses.MeanSquaredError()\n",
    "\t\t\n",
    "\t\t# Prepare training data\n",
    "\t\ttraining_data = []\n",
    "\t\t\n",
    "\t\tfor parent_idx, parent_id in enumerate(parent_poi_ids):\n",
    "\t\t\tchildren_ids = parent_children_map.get(parent_id, [])\n",
    "\t\t\tchild_indices = [\n",
    "\t\t\t\tchild_id_to_idx[cid]\n",
    "\t\t\t\tfor cid in children_ids\n",
    "\t\t\t\tif cid in child_id_to_idx\n",
    "\t\t\t]\n",
    "\t\t\t\n",
    "\t\t\tif len(child_indices) > 0:\n",
    "\t\t\t\ttraining_data.append({\n",
    "\t\t\t\t\t'parent_idx': parent_idx,\n",
    "\t\t\t\t\t'child_indices': child_indices,\n",
    "\t\t\t\t\t'parent_embed': parent_embeddings[parent_idx]\n",
    "\t\t\t\t})\n",
    "\t\t\n",
    "\t\tif len(training_data) == 0:\n",
    "\t\t\tprint(\"    No training data available, using uniform attention\")\n",
    "\t\t\treturn\n",
    "\t\t\n",
    "\t\tprint(f\"    Training samples: {len(training_data)}\")\n",
    "\t\t\n",
    "\t\t# Training loop\n",
    "\t\tfor epoch in range(n_epochs):\n",
    "\t\t\ttotal_loss = 0.0\n",
    "\t\t\tn_batches = 0\n",
    "\t\t\t\n",
    "\t\t\t# Shuffle training data\n",
    "\t\t\tnp.random.shuffle(training_data)\n",
    "\t\t\t\n",
    "\t\t\tfor data in training_data:\n",
    "\t\t\t\tchild_embeds = tf.constant(\n",
    "\t\t\t\t\tchild_A_lp[data['child_indices']],\n",
    "\t\t\t\t\tdtype=tf.float32\n",
    "\t\t\t\t)\n",
    "\t\t\t\tparent_embed = tf.constant(\n",
    "\t\t\t\t\tdata['parent_embed'],\n",
    "\t\t\t\t\tdtype=tf.float32\n",
    "\t\t\t\t)\n",
    "\t\t\t\t\n",
    "\t\t\t\twith tf.GradientTape() as tape:\n",
    "\t\t\t\t\taggregated, _ = aggregator(child_embeds, training=True)\n",
    "\t\t\t\t\tloss = mse_loss(parent_embed, aggregated)\n",
    "\t\t\t\t\n",
    "\t\t\t\tgradients = tape.gradient(loss, aggregator.trainable_variables)\n",
    "\t\t\t\toptimizer.apply_gradients(zip(gradients, aggregator.trainable_variables))\n",
    "\t\t\t\t\n",
    "\t\t\t\ttotal_loss += loss.numpy()\n",
    "\t\t\t\tn_batches += 1\n",
    "\t\t\t\n",
    "\t\t\tavg_loss = total_loss / n_batches\n",
    "\t\t\t\n",
    "\t\t\tif (epoch + 1) % 20 == 0 or epoch == 0:\n",
    "\t\t\t\tprint(f\"    Epoch {epoch + 1}/{n_epochs}, Loss: {avg_loss:.6f}\")\n",
    "\t\n",
    "\tdef build_all_A_lp(self,\n",
    "\t\t\t\t\ttrain_attention: bool = True,\n",
    "\t\t\t\t\tn_epochs: int = 100,\n",
    "\t\t\t\t\tlr: float = 0.001,\n",
    "\t\t\t\t\tbatch_size: int = 32) -> Dict[str, np.ndarray]:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild A^l_p for all levels (0 to 3)\n",
    "\t\t\n",
    "\t\tMust be built in order: Level 0 -> 1 -> 2 -> 3\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\ttrain_attention: Whether to train attention weights\n",
    "\t\t\tn_epochs: Training epochs\n",
    "\t\t\tlr: Learning rate\n",
    "\t\t\tbatch_size: Batch size\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary: level_key -> A^l_p matrix\n",
    "\t\t\"\"\"\n",
    "\t\tprint(\"\\n\" + \"=\" * 60)\n",
    "\t\tprint(\"Building A^l_p for All Levels\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\t# Level 0: Base embeddings\n",
    "\t\tself.build_A_lp_level0()\n",
    "\t\t\n",
    "\t\t# Levels 1, 2, 3: Attention aggregation from children\n",
    "\t\tfor level in [1, 2, 3]:\n",
    "\t\t\tself.build_A_lp_higher_level(\n",
    "\t\t\t\tlevel=level,\n",
    "\t\t\t\ttrain_attention=train_attention,\n",
    "\t\t\t\tn_epochs=n_epochs,\n",
    "\t\t\t\tlr=lr,\n",
    "\t\t\t\tbatch_size=batch_size\n",
    "\t\t\t)\n",
    "\t\t\n",
    "\t\treturn self.A_lp\n",
    "\t\n",
    "\tdef build_Q_l(self, level: int) -> np.ndarray:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild complete POI representation Q^l = [Y_A || Y_T || A^l_p]\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tlevel: Target level\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tQ^l: (n_pois, total_dim)\n",
    "\t\t\"\"\"\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\t\n",
    "\t\t# Get Y_A and Y_T from poi_embeddings\n",
    "\t\tpoi_data = self.poi_embeddings_data['poi_embeddings'][level_key]\n",
    "\t\t\n",
    "\t\tY_A = poi_data.get('Y_A')\n",
    "\t\tY_T = poi_data.get('Y_T')\n",
    "\t\tA_lp = self.A_lp[level_key]\n",
    "\t\t\n",
    "\t\tcomponents = []\n",
    "\t\tcomponent_names = []\n",
    "\t\t\n",
    "\t\tif Y_A is not None:\n",
    "\t\t\tcomponents.append(Y_A)\n",
    "\t\t\tcomponent_names.append(f'Y_A ({Y_A.shape[1]})')\n",
    "\t\t\n",
    "\t\tif Y_T is not None:\n",
    "\t\t\tcomponents.append(Y_T)\n",
    "\t\t\tcomponent_names.append(f'Y_T ({Y_T.shape[1]})')\n",
    "\t\t\n",
    "\t\tcomponents.append(A_lp)\n",
    "\t\tcomponent_names.append(f'A^{level}_p ({A_lp.shape[1]})')\n",
    "\t\t\n",
    "\t\t# Ensure same number of POIs\n",
    "\t\tn_pois = min(c.shape[0] for c in components)\n",
    "\t\tcomponents = [c[:n_pois] for c in components]\n",
    "\t\t\n",
    "\t\tQ_l = np.hstack(components).astype(np.float32)\n",
    "\t\t\n",
    "\t\tprint(f\"\\n  Q^{level} = [{' || '.join(component_names)}]\")\n",
    "\t\tprint(f\"  Shape: {Q_l.shape}\")\n",
    "\t\t\n",
    "\t\treturn Q_l\n",
    "\t\n",
    "\tdef build_all_Q_l(self) -> Dict[str, np.ndarray]:\n",
    "\t\t\"\"\"\n",
    "\t\tBuild Q^l for all levels\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tDictionary: level_key -> Q^l matrix\n",
    "\t\t\"\"\"\n",
    "\t\tQ_l_all = {}\n",
    "\t\t\n",
    "\t\tprint(\"\\n\" + \"-\" * 40)\n",
    "\t\tprint(\"Building Q^l = [Y_A || Y_T || A^l_p] for all levels\")\n",
    "\t\tprint(\"-\" * 40)\n",
    "\t\t\n",
    "\t\tfor level in range(4):\n",
    "\t\t\tQ_l_all[f'level_{level}'] = self.build_Q_l(level)\n",
    "\t\t\n",
    "\t\treturn Q_l_all\n",
    "\t\n",
    "\tdef save_results(self, output_file: str = 'poi_interlevel_features.pkl'):\n",
    "\t\t\"\"\"\n",
    "\t\tSave A^l_p and Q^l for all levels\n",
    "\t\t\"\"\"\n",
    "\t\tprint(f\"\\n{'=' * 60}\")\n",
    "\t\tprint(f\"Saving results to: {output_file}\")\n",
    "\t\tprint(\"=\" * 60)\n",
    "\t\t\n",
    "\t\t# Build Q^l for all levels\n",
    "\t\tQ_l_all = self.build_all_Q_l()\n",
    "\t\t\n",
    "\t\t# Save aggregator weights\n",
    "\t\taggregator_weights = {}\n",
    "\t\tfor level, agg in self.aggregators.items():\n",
    "\t\t\taggregator_weights[level] = {\n",
    "\t\t\t\tname: var.numpy() \n",
    "\t\t\t\tfor name, var in zip(\n",
    "\t\t\t\t\t[v.name for v in agg.trainable_variables],\n",
    "\t\t\t\t\tagg.trainable_variables\n",
    "\t\t\t\t)\n",
    "\t\t\t}\n",
    "\t\t\n",
    "\t\tsave_data = {\n",
    "\t\t\t# Inter-level POI features\n",
    "\t\t\t'A_lp': self.A_lp,\n",
    "\t\t\t\n",
    "\t\t\t# Complete POI representations\n",
    "\t\t\t'Q_l': Q_l_all,\n",
    "\t\t\t\n",
    "\t\t\t# Attention weights (for interpretability)\n",
    "\t\t\t'attention_weights': self.attention_weights,\n",
    "\t\t\t\n",
    "\t\t\t# Trained aggregator weights\n",
    "\t\t\t'aggregator_weights': aggregator_weights,\n",
    "\t\t\t\n",
    "\t\t\t# Aggregator config for reconstruction\n",
    "\t\t\t'aggregator_config': {\n",
    "\t\t\t\t'hidden_dim': self.hidden_dim,\n",
    "\t\t\t\t'dropout_rate': self.dropout_rate\n",
    "\t\t\t},\n",
    "\t\t\t\n",
    "\t\t\t# Dimensions\n",
    "\t\t\t'dimensions': {\n",
    "\t\t\t\tf'level_{level}': {\n",
    "\t\t\t\t\t'A_lp_shape': self.A_lp[f'level_{level}'].shape,\n",
    "\t\t\t\t\t'Q_l_shape': Q_l_all[f'level_{level}'].shape\n",
    "\t\t\t\t}\n",
    "\t\t\t\tfor level in range(4)\n",
    "\t\t\t},\n",
    "\t\t\t\n",
    "\t\t\t# Metadata\n",
    "\t\t\t'info': {\n",
    "\t\t\t\t'created_at': datetime.now().isoformat(),\n",
    "\t\t\t\t'formula': 'Q^l = [Y_A || Y_T || A^l_p]',\n",
    "\t\t\t\t'aggregation': 'MLP Attention (TensorFlow)',\n",
    "\t\t\t\t'hidden_dim': self.hidden_dim,\n",
    "\t\t\t\t'framework': 'tensorflow',\n",
    "\t\t\t\t'tf_version': tf.__version__\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\twith open(output_file, 'wb') as f:\n",
    "\t\t\tpickle.dump(save_data, f)\n",
    "\t\t\n",
    "\t\tfile_size = os.path.getsize(output_file) / (1024 * 1024)\n",
    "\t\tprint(f\"\\n  File size: {file_size:.2f} MB\")\n",
    "\t\t\n",
    "\t\tprint(\"\\n  Saved matrices:\")\n",
    "\t\tfor level in range(4):\n",
    "\t\t\tlevel_key = f'level_{level}'\n",
    "\t\t\tprint(f\"    Level {level}:\")\n",
    "\t\t\tprint(f\"      A^{level}_p: {self.A_lp[level_key].shape}\")\n",
    "\t\t\tprint(f\"      Q^{level}: {Q_l_all[level_key].shape}\")\n",
    "\t\t\n",
    "\t\treturn save_data\n",
    "\n",
    "\n",
    "def build_A_lp_and_Q_l(poi_tree_file: str = 'poi_tree_with_uuids.json',\n",
    "\t\t\t\t\t\tpoi_embeddings_file: str = 'poi_embeddings.pkl',\n",
    "\t\t\t\t\t\tmetadata_file: str = 'metadata.pkl',\n",
    "\t\t\t\t\t\toutput_file: str = 'poi_interlevel_features.pkl',\n",
    "\t\t\t\t\t\thidden_dim: int = 64,\n",
    "\t\t\t\t\t\tdropout_rate: float = 0.1,\n",
    "\t\t\t\t\t\tn_epochs: int = 100,\n",
    "\t\t\t\t\t\tlr: float = 0.001) -> Dict:\n",
    "\t\"\"\"\n",
    "\tMain function to build A^l_p and Q^l for all levels\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tpoi_tree_file: Path to POI tree JSON\n",
    "\t\tpoi_embeddings_file: Path to POI embeddings pickle\n",
    "\t\tmetadata_file: Path to metadata pickle\n",
    "\t\toutput_file: Output file path\n",
    "\t\thidden_dim: Hidden dimension for attention MLP\n",
    "\t\tdropout_rate: Dropout rate\n",
    "\t\tn_epochs: Training epochs\n",
    "\t\tlr: Learning rate\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary with A^l_p and Q^l for all levels\n",
    "\t\"\"\"\n",
    "\taggregator = InterLevelPOIAggregator(\n",
    "\t\tpoi_tree_file=poi_tree_file,\n",
    "\t\tpoi_embeddings_file=poi_embeddings_file,\n",
    "\t\tmetadata_file=metadata_file,\n",
    "\t\thidden_dim=hidden_dim,\n",
    "\t\tdropout_rate=dropout_rate\n",
    "\t)\n",
    "\t\n",
    "\t# Build A^l_p for all levels\n",
    "\taggregator.build_all_A_lp(\n",
    "\t\ttrain_attention=True,\n",
    "\t\tn_epochs=n_epochs,\n",
    "\t\tlr=lr\n",
    "\t)\n",
    "\t\n",
    "\t# Save results\n",
    "\tsave_data = aggregator.save_results(output_file)\n",
    "\t\n",
    "\treturn save_data\n",
    "\n",
    "\n",
    "class AttentionAggregatorLoader:\n",
    "\t\"\"\"\n",
    "\tUtility class to load and use trained attention aggregators\n",
    "\t\"\"\"\n",
    "\t\n",
    "\tdef __init__(self, saved_file: str = 'poi_interlevel_features.pkl'):\n",
    "\t\t\"\"\"\n",
    "\t\tLoad saved attention aggregators\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tsaved_file: Path to saved pickle file\n",
    "\t\t\"\"\"\n",
    "\t\twith open(saved_file, 'rb') as f:\n",
    "\t\t\tself.data = pickle.load(f)\n",
    "\t\t\n",
    "\t\tself.A_lp = self.data['A_lp']\n",
    "\t\tself.Q_l = self.data['Q_l']\n",
    "\t\tself.attention_weights = self.data['attention_weights']\n",
    "\t\tself.config = self.data['aggregator_config']\n",
    "\t\n",
    "\tdef get_A_lp(self, level: int) -> np.ndarray:\n",
    "\t\t\"\"\"Get A^l_p for a specific level\"\"\"\n",
    "\t\treturn self.A_lp[f'level_{level}']\n",
    "\t\n",
    "\tdef get_Q_l(self, level: int) -> np.ndarray:\n",
    "\t\t\"\"\"Get Q^l for a specific level\"\"\"\n",
    "\t\treturn self.Q_l[f'level_{level}']\n",
    "\t\n",
    "\tdef get_attention_weights(self, level: int, parent_id: str) -> Dict:\n",
    "\t\t\"\"\"Get attention weights for a specific parent POI\"\"\"\n",
    "\t\tlevel_key = f'level_{level}'\n",
    "\t\tif level_key in self.attention_weights and self.attention_weights[level_key]:\n",
    "\t\t\treturn self.attention_weights[level_key].get(parent_id, {})\n",
    "\t\treturn {}\n",
    "\t\n",
    "\tdef get_top_k_children(self, level: int, parent_id: str, k: int = 5) -> List[Tuple[str, float]]:\n",
    "\t\t\"\"\"\n",
    "\t\tGet top-k children by attention weight for a parent POI\n",
    "\t\t\n",
    "\t\tArgs:\n",
    "\t\t\tlevel: Parent level\n",
    "\t\t\tparent_id: Parent POI ID\n",
    "\t\t\tk: Number of top children to return\n",
    "\t\t\n",
    "\t\tReturns:\n",
    "\t\t\tList of (child_id, attention_weight) tuples\n",
    "\t\t\"\"\"\n",
    "\t\tattn_data = self.get_attention_weights(level, parent_id)\n",
    "\t\t\n",
    "\t\tif not attn_data or 'children' not in attn_data:\n",
    "\t\t\treturn []\n",
    "\t\t\n",
    "\t\tchildren = attn_data['children']\n",
    "\t\tweights = attn_data['weights']\n",
    "\t\t\n",
    "\t\tpairs = list(zip(children, weights))\n",
    "\t\tpairs.sort(key=lambda x: x[1], reverse=True)\n",
    "\t\t\n",
    "\t\treturn pairs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f55b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INTER-LEVEL POI FEATURE (A^l_p) GENERATION - TensorFlow\n",
      "============================================================\n",
      "============================================================\n",
      "Initializing Inter-Level POI Aggregator (TensorFlow)\n",
      "============================================================\n",
      "\n",
      "Loading POI tree from: ../../Sources/Files/poi_tree_with_uuids.json\n",
      "Loading POI embeddings from: ../../Sources/Embeddings/poi_embeddings.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Windows\\Temp\\ipykernel_5212\\2572883960.py:176: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  self.poi_embeddings_data = pickle.load(f)\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from: ../../Sources/Embeddings/metadata.pkl\n",
      "\n",
      "Building parent-children mappings...\n",
      "  Level 1: 968 parents, avg_children=4.9, max=561\n",
      "  Level 2: 44 parents, avg_children=30.8, max=125\n",
      "  Level 3: 5 parents, avg_children=8.8, max=20\n",
      "\n",
      "Initialization complete!\n",
      "\n",
      "----------------------------------------\n",
      "Data Summary:\n",
      "  Level 0: 4696 POIs, embed_dim=221, total_children=0\n",
      "  Level 1: 1355 POIs, embed_dim=171, total_children=4696\n",
      "  Level 2: 44 POIs, embed_dim=125, total_children=1355\n",
      "  Level 3: 5 POIs, embed_dim=105, total_children=44\n",
      "\n",
      "============================================================\n",
      "Building A^l_p for All Levels\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Building A^0_p (Level 0 - Building)\n",
      "============================================================\n",
      "  A^0_p = Y^0 (base POI embeddings)\n",
      "  Shape: (4696, 221)\n",
      "\n",
      "============================================================\n",
      "Building A^1_p (Level 1)\n",
      "============================================================\n",
      "  Child level 0: 4696 POIs, embed_dim=221\n",
      "  Parent level 1: 1355 POIs\n",
      "\n",
      "  Training attention aggregator (100 epochs)...\n",
      "    Training samples: 968\n",
      "    Epoch 1/100, Loss: 0.549377\n",
      "    Epoch 20/100, Loss: 0.081326\n",
      "    Epoch 40/100, Loss: 0.057436\n",
      "    Epoch 60/100, Loss: 0.070533\n",
      "    Epoch 80/100, Loss: 0.063254\n",
      "    Epoch 100/100, Loss: 0.066653\n",
      "\n",
      "  Computing aggregated embeddings...\n",
      "\n",
      "  A^1_p shape: (1355, 171)\n",
      "  Value range: [-6.1297, 17.9075]\n",
      "\n",
      "============================================================\n",
      "Building A^2_p (Level 2)\n",
      "============================================================\n",
      "  Child level 1: 1355 POIs, embed_dim=171\n",
      "  Parent level 2: 44 POIs\n",
      "\n",
      "  Training attention aggregator (100 epochs)...\n",
      "    Training samples: 44\n",
      "    Epoch 1/100, Loss: 1.307462\n",
      "    Epoch 20/100, Loss: 0.141474\n",
      "    Epoch 40/100, Loss: 0.075960\n",
      "    Epoch 60/100, Loss: 0.048474\n",
      "    Epoch 80/100, Loss: 0.034238\n",
      "    Epoch 100/100, Loss: 0.024416\n",
      "\n",
      "  Computing aggregated embeddings...\n",
      "\n",
      "  A^2_p shape: (44, 125)\n",
      "  Value range: [-3.3566, 5.9361]\n",
      "\n",
      "============================================================\n",
      "Building A^3_p (Level 3)\n",
      "============================================================\n",
      "  Child level 2: 44 POIs, embed_dim=125\n",
      "  Parent level 3: 5 POIs\n",
      "\n",
      "  Training attention aggregator (100 epochs)...\n",
      "    Training samples: 5\n",
      "    Epoch 1/100, Loss: 1.420622\n",
      "    Epoch 20/100, Loss: 0.336409\n",
      "    Epoch 40/100, Loss: 0.095701\n",
      "    Epoch 60/100, Loss: 0.071949\n",
      "    Epoch 80/100, Loss: 0.050234\n",
      "    Epoch 100/100, Loss: 0.032496\n",
      "\n",
      "  Computing aggregated embeddings...\n",
      "\n",
      "  A^3_p shape: (5, 105)\n",
      "  Value range: [-1.9610, 2.5711]\n",
      "\n",
      "============================================================\n",
      "Saving results to: ../../Sources/Embeddings/poi_interlevel_features.pkl\n",
      "============================================================\n",
      "\n",
      "----------------------------------------\n",
      "Building Q^l = [Y_A || Y_T || A^l_p] for all levels\n",
      "----------------------------------------\n",
      "\n",
      "  Q^0 = [Y_A (149) || Y_T (72) || A^0_p (221)]\n",
      "  Shape: (4696, 442)\n",
      "\n",
      "  Q^1 = [Y_A (99) || Y_T (72) || A^1_p (171)]\n",
      "  Shape: (1355, 342)\n",
      "\n",
      "  Q^2 = [Y_A (53) || Y_T (72) || A^2_p (125)]\n",
      "  Shape: (44, 250)\n",
      "\n",
      "  Q^3 = [Y_A (33) || Y_T (72) || A^3_p (105)]\n",
      "  Shape: (5, 210)\n",
      "\n",
      "  File size: 15.31 MB\n",
      "\n",
      "  Saved matrices:\n",
      "    Level 0:\n",
      "      A^0_p: (4696, 221)\n",
      "      Q^0: (4696, 442)\n",
      "    Level 1:\n",
      "      A^1_p: (1355, 171)\n",
      "      Q^1: (1355, 342)\n",
      "    Level 2:\n",
      "      A^2_p: (44, 125)\n",
      "      Q^2: (44, 250)\n",
      "    Level 3:\n",
      "      A^3_p: (5, 105)\n",
      "      Q^3: (5, 210)\n",
      "\n",
      "============================================================\n",
      "FINAL SUMMARY\n",
      "============================================================\n",
      "\n",
      "A^l_p (Inter-level POI Features):\n",
      "  Level 0: (4696, 221)\n",
      "  Level 1: (1355, 171)\n",
      "  Level 2: (44, 125)\n",
      "  Level 3: (5, 105)\n",
      "\n",
      "Q^l (Complete POI Representations):\n",
      "  Level 0: (4696, 442)\n",
      "  Level 1: (1355, 342)\n",
      "  Level 2: (44, 250)\n",
      "  Level 3: (5, 210)\n",
      "\n",
      "----------------------------------------\n",
      "DEMO: Using AttentionAggregatorLoader\n",
      "----------------------------------------\n",
      "\n",
      "Q^l matrices loaded:\n",
      "  Level 0: (4696, 442)\n",
      "  Level 1: (1355, 342)\n",
      "  Level 2: (44, 250)\n",
      "  Level 3: (5, 210)\n",
      "\n",
      "Top 3 children for parent 'container_FairPrice' at level 1:\n",
      "\n",
      "============================================================\n",
      "COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tpoi_tree_file = \"../../Sources/Files/poi_tree_with_uuids.json\"\n",
    "\tpoi_embeddings_file = \"../../Sources/Embeddings/poi_embeddings.pkl\"\n",
    "\tmetadata_file = \"../../Sources/Embeddings/metadata.pkl\"\n",
    "\toutput_file = \"../../Sources/Embeddings/poi_interlevel_features.pkl\"\n",
    "\t\n",
    "\tprint(\"=\" * 60)\n",
    "\tprint(\"INTER-LEVEL POI FEATURE (A^l_p) GENERATION - TensorFlow\")\n",
    "\tprint(\"=\" * 60)\n",
    "\t\n",
    "\t# Build A^l_p and Q^l\n",
    "\tresult = build_A_lp_and_Q_l(\n",
    "\t\tpoi_tree_file=poi_tree_file,\n",
    "\t\tpoi_embeddings_file=poi_embeddings_file,\n",
    "\t\tmetadata_file=metadata_file,\n",
    "\t\toutput_file=output_file,\n",
    "\t\thidden_dim=64,\n",
    "\t\tdropout_rate=0.1,\n",
    "\t\tn_epochs=100,\n",
    "\t\tlr=0.001\n",
    "\t)\n",
    "\t\n",
    "\t# Summary\n",
    "\tprint(\"\\n\" + \"=\" * 60)\n",
    "\tprint(\"FINAL SUMMARY\")\n",
    "\tprint(\"=\" * 60)\n",
    "\t\n",
    "\tprint(\"\\nA^l_p (Inter-level POI Features):\")\n",
    "\tfor level in range(4):\n",
    "\t\tshape = result['A_lp'][f'level_{level}'].shape\n",
    "\t\tprint(f\"  Level {level}: {shape}\")\n",
    "\t\n",
    "\tprint(\"\\nQ^l (Complete POI Representations):\")\n",
    "\tfor level in range(4):\n",
    "\t\tshape = result['Q_l'][f'level_{level}'].shape\n",
    "\t\tprint(f\"  Level {level}: {shape}\")\n",
    "\t\n",
    "\t# Demo: Load and use\n",
    "\tprint(\"\\n\" + \"-\" * 40)\n",
    "\tprint(\"DEMO: Using AttentionAggregatorLoader\")\n",
    "\tprint(\"-\" * 40)\n",
    "\t\n",
    "\tloader = AttentionAggregatorLoader(output_file)\n",
    "\t\n",
    "\tprint(\"\\nQ^l matrices loaded:\")\n",
    "\tfor level in range(4):\n",
    "\t\tQ = loader.get_Q_l(level)\n",
    "\t\tprint(f\"  Level {level}: {Q.shape}\")\n",
    "\t\n",
    "\t# Example: Get top children for a parent (if attention weights available)\n",
    "\tif loader.attention_weights.get('level_1'):\n",
    "\t\tsample_parent = list(loader.attention_weights['level_1'].keys())[0]\n",
    "\t\ttop_children = loader.get_top_k_children(level=1, parent_id=sample_parent, k=3)\n",
    "\t\tprint(f\"\\nTop 3 children for parent '{sample_parent}' at level 1:\")\n",
    "\t\tfor child_id, weight in top_children:\n",
    "\t\t\tprint(f\"  - {child_id}: {weight:.4f}\")\n",
    "\t\n",
    "\tprint(\"\\n\" + \"=\" * 60)\n",
    "\tprint(\"COMPLETE\")\n",
    "\tprint(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2939e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
