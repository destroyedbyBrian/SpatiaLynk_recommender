{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55124c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import networkx as nx\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1470f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiGranularityRecommendationFramework:\n",
    "    \"\"\"\n",
    "    Complete Multi-Granularity POI Recommendation System\n",
    "    \n",
    "    Provides recommendations at multiple granularity levels:\n",
    "    - Level 0: Individual POIs (e.g., \"Starbucks @ VivoCity\")\n",
    "    - Level 1: Containers (e.g., \"VivoCity Mall\")\n",
    "    - Level 2: Districts (e.g., \"HarbourFront District\")\n",
    "    - Level 3: Regions (e.g., \"Southern Singapore\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 embeddings_file: str = 'embeddings.pkl',\n",
    "                 interaction_learning_file: str = 'interaction_learning.pkl',\n",
    "                 poi_tree_file: str = 'poi_tree.json',\n",
    "                 users_file: str = 'users.csv',\n",
    "                 interactions_file: str = 'user_poi_interactions.csv'):\n",
    "        \"\"\"Initialize the recommendation framework\"\"\"\n",
    "        print(\"=\"*70)\n",
    "        print(\"INITIALIZING MULTI-GRANULARITY RECOMMENDATION FRAMEWORK\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Load attribute-based embeddings\n",
    "        print(\"\\nLoading attribute-based embeddings...\")\n",
    "        with open(embeddings_file, 'rb') as f:\n",
    "            emb_data = pickle.load(f)\n",
    "        \n",
    "        self.user_embeddings = emb_data['user_embeddings']\n",
    "        self.poi_embeddings = emb_data['poi_embeddings']\n",
    "        self.user_id_to_idx = emb_data['user_id_to_idx']\n",
    "        self.X = emb_data['X']\n",
    "        self.X_A = emb_data['X_A']\n",
    "        self.X_T = emb_data['X_T']\n",
    "        \n",
    "        # Load interaction-based components\n",
    "        print(\"Loading interaction-based components...\")\n",
    "        with open(interaction_learning_file, 'rb') as f:\n",
    "            int_data = pickle.load(f)\n",
    "        \n",
    "        self.Theta_u = int_data['Theta_u']\n",
    "        self.A_l_p = int_data['A_l_p']\n",
    "        self.G_l = int_data['G_l']\n",
    "        self.P_l = int_data['P_l']\n",
    "        self.Q_l = int_data['Q_l']\n",
    "        self.S_l = int_data['S_l']\n",
    "        self.U_l_g = int_data['U_l_g']\n",
    "        \n",
    "        # Load POI tree\n",
    "        print(\"Loading POI tree...\")\n",
    "        with open(poi_tree_file, 'r') as f:\n",
    "            self.poi_tree = json.load(f)\n",
    "        \n",
    "        # Load raw data\n",
    "        print(\"Loading user profiles and interactions...\")\n",
    "        self.users_df = pd.read_csv(users_file)\n",
    "        self.interactions_df = pd.read_csv(interactions_file)\n",
    "        \n",
    "        # Build indices\n",
    "        self._build_indices()\n",
    "        \n",
    "        # Initialize hyperparameters\n",
    "        self.alpha = 0.5   # Weight for feature-based score\n",
    "        self.beta = 0.3    # Weight for graph-based score\n",
    "        self.gamma = 0.2   # Weight for hierarchical boost\n",
    "        \n",
    "        # Level weights (how much to trust each level)\n",
    "        self.level_weights = {\n",
    "            0: 0.6,  # Individual POIs\n",
    "            1: 0.25, # Containers\n",
    "            2: 0.10, # Districts\n",
    "            3: 0.05  # Regions\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"FRAMEWORK INITIALIZED SUCCESSFULLY\")\n",
    "        print(\"=\"*70)\n",
    "        print(f\"Users: {len(self.users_df)}\")\n",
    "        print(f\"POIs by level:\")\n",
    "        for level in [0, 1, 2, 3]:\n",
    "            print(f\"  Level {level}: {len(self.poi_tree[f'level_{level}'])} POIs\")\n",
    "        print(f\"Interactions: {len(self.interactions_df)}\")\n",
    "    \n",
    "    def _build_indices(self):\n",
    "        \"\"\"Build lookup indices for fast access\"\"\"\n",
    "        # User index\n",
    "        self.user_id_to_idx = {uid: idx for idx, uid in enumerate(self.users_df['uudi'])}\n",
    "        self.idx_to_user_id = {idx: uid for uid, idx in self.user_id_to_idx.items()}\n",
    "        \n",
    "        # POI indices for each level\n",
    "        self.poi_id_to_idx = {}\n",
    "        self.idx_to_poi_id = {}\n",
    "        \n",
    "        for level in [0, 1, 2, 3]:\n",
    "            level_key = f'level_{level}'\n",
    "            poi_ids = self.poi_embeddings[level_key]['poi_ids']\n",
    "            self.poi_id_to_idx[level] = {pid: idx for idx, pid in enumerate(poi_ids)}\n",
    "            self.idx_to_poi_id[level] = {idx: pid for pid, idx in self.poi_id_to_idx[level].items()}\n",
    "        \n",
    "        # Build user history lookup (at level 0)\n",
    "        self._build_user_history()\n",
    "    \n",
    "    def _build_user_history(self):\n",
    "        \"\"\"Build lookup table for user visit history\"\"\"\n",
    "        self.user_history = defaultdict(lambda: defaultdict(list))\n",
    "        \n",
    "        visits = self.interactions_df[self.interactions_df['interaction_type'] == 'visit']\n",
    "        \n",
    "        for _, row in visits.iterrows():\n",
    "            user_id = row['user_id']\n",
    "            poi_id = row['poi_id']\n",
    "            \n",
    "            # Store at level 0\n",
    "            if poi_id not in self.user_history[user_id][0]:\n",
    "                self.user_history[user_id][0].append(poi_id)\n",
    "            \n",
    "            # Propagate to higher levels\n",
    "            for level in [1, 2, 3]:\n",
    "                parent_id = self._get_parent_at_level(poi_id, level)\n",
    "                if parent_id and parent_id not in self.user_history[user_id][level]:\n",
    "                    self.user_history[user_id][level].append(parent_id)\n",
    "    \n",
    "    def _get_parent_at_level(self, poi_id: str, target_level: int) -> Optional[str]:\n",
    "        \"\"\"Get parent node of poi_id at target_level\"\"\"\n",
    "        current_level = 0\n",
    "        current_id = poi_id\n",
    "        \n",
    "        while current_level < target_level:\n",
    "            level_key = f'level_{current_level}'\n",
    "            if current_id in self.poi_tree[level_key]:\n",
    "                parent = self.poi_tree[level_key][current_id].get('parent')\n",
    "                if parent:\n",
    "                    current_id = parent\n",
    "                    current_level += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        return current_id if current_level == target_level else None\n",
    "    \n",
    "    # ========================================================================\n",
    "    # UNDERSTANDING PROMPTS (NLP)\n",
    "    # ========================================================================\n",
    "\n",
    "    def extract_categories(self, prompt: str) -> List[str]:\n",
    "        \"\"\"Extract POI categories from prompt\"\"\"\n",
    "        prompt_lower = prompt.lower()\n",
    "        \n",
    "        category_keywords = {\n",
    "            'cafe': ['cafe', 'coffee', 'starbucks'],\n",
    "            'restaurant': ['restaurant', 'food', 'dining', 'eat'],\n",
    "            'shopping_mall': ['mall', 'shopping', 'shop'],\n",
    "            'cinema': ['movie', 'cinema', 'film'],\n",
    "            'gym': ['gym', 'fitness', 'workout'],\n",
    "            'park': ['park', 'nature', 'outdoor']\n",
    "        }\n",
    "        \n",
    "        categories = []\n",
    "        for category, keywords in category_keywords.items():\n",
    "            if any(keyword in prompt_lower for keyword in keywords):\n",
    "                categories.append(category)\n",
    "        \n",
    "        return categories if categories else ['restaurant']  # Default\n",
    "\n",
    "    def extract_location(self, prompt: str) -> Optional[str]:\n",
    "        \"\"\"Extract location mention from prompt\"\"\"\n",
    "        locations = ['orchard', 'jurong', 'tampines', 'woodlands', 'bishan']\n",
    "        \n",
    "        prompt_lower = prompt.lower()\n",
    "        for location in locations:\n",
    "            if location in prompt_lower:\n",
    "                return location.title()\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def parse_user_prompt(self, prompt: str, current_location: Optional[Dict]) -> Dict:\n",
    "        \"\"\"Parse user prompt into structured intent\"\"\"\n",
    "        return {\n",
    "            'raw_prompt': prompt,\n",
    "            'categories': self.extract_categories(prompt),\n",
    "            'location_mentioned': self.extract_location(prompt),\n",
    "            'search_location': current_location,\n",
    "            'keywords': [],\n",
    "            'max_distance_km': 5.0\n",
    "        }\n",
    "    \n",
    "    # ========================================================================\n",
    "    # CORE SCORING FUNCTIONS (Multi-level)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def compute_feature_based_score(self, user_idx: int, poi_idx: int, level: int) -> float:\n",
    "        \"\"\"Get feature-based affinity score S^l[u, p]\"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        return float(self.S_l[level_key][user_idx, poi_idx])\n",
    "    \n",
    "    def compute_graph_based_score(self, user_idx: int, poi_idx: int, level: int) -> float:\n",
    "        \"\"\"Compute graph-based context score\"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        U_g_up = self.U_l_g[level_key][user_idx, poi_idx]\n",
    "        Q_p = self.Q_l[level_key][poi_idx]\n",
    "        \n",
    "        min_len = min(len(U_g_up), len(Q_p))\n",
    "        U_g_up = U_g_up[:min_len]\n",
    "        Q_p = Q_p[:min_len]\n",
    "        \n",
    "        if np.linalg.norm(U_g_up) == 0 or np.linalg.norm(Q_p) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        score = np.dot(U_g_up, Q_p) / (np.linalg.norm(U_g_up) * np.linalg.norm(Q_p))\n",
    "        return float(score)\n",
    "    \n",
    "    def compute_hierarchical_boost(self, poi_id: str, user_idx: int, level: int) -> float:\n",
    "        \"\"\"\n",
    "        Compute hierarchical boost from parent/child scores\n",
    "        \n",
    "        For coarse levels (2, 3): boost from children's popularity\n",
    "        For fine levels (0, 1): boost from parent's score\n",
    "        \"\"\"\n",
    "        if level >= 2:\n",
    "            # Coarse level: aggregate from children\n",
    "            children = self.poi_tree[f'level_{level}'].get(poi_id, {}).get('children', [])\n",
    "            if not children:\n",
    "                return 0.0\n",
    "            \n",
    "            child_scores = []\n",
    "            for child_id in children[:10]:  # Limit to top 10 children\n",
    "                if level == 2:\n",
    "                    child_level = 1\n",
    "                elif level == 3:\n",
    "                    child_level = 2\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                if child_id in self.poi_id_to_idx[child_level]:\n",
    "                    child_idx = self.poi_id_to_idx[child_level][child_id]\n",
    "                    score = self.compute_feature_based_score(user_idx, child_idx, child_level)\n",
    "                    child_scores.append(score)\n",
    "            \n",
    "            return np.mean(child_scores) if child_scores else 0.0\n",
    "        \n",
    "        else:\n",
    "            # Fine level: boost from parent\n",
    "            poi_data = self.poi_tree[f'level_{level}'].get(poi_id)\n",
    "            if not poi_data:\n",
    "                return 0.0\n",
    "            \n",
    "            parent_id = poi_data.get('parent')\n",
    "            if not parent_id:\n",
    "                return 0.0\n",
    "            \n",
    "            parent_level = level + 1\n",
    "            if parent_id in self.poi_id_to_idx[parent_level]:\n",
    "                parent_idx = self.poi_id_to_idx[parent_level][parent_id]\n",
    "                return self.compute_feature_based_score(user_idx, parent_idx, parent_level)\n",
    "            \n",
    "            return 0.0\n",
    "    \n",
    "    def compute_multi_granularity_score(self, \n",
    "                                        user_id: str, \n",
    "                                        poi_id: str,\n",
    "                                        level: int = 0,\n",
    "                                        use_hierarchical_boost: bool = True,\n",
    "                                        use_graph_context: bool = True,\n",
    "                                        use_distance_penalty: bool = True) -> float:\n",
    "        \"\"\"\n",
    "        Updated scoring with distance penalty\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_id_to_idx:\n",
    "            return 0.0\n",
    "        \n",
    "        if poi_id not in self.poi_id_to_idx[level]:\n",
    "            return 0.0\n",
    "        \n",
    "        user_idx = self.user_id_to_idx[user_id]\n",
    "        poi_idx = self.poi_id_to_idx[level][poi_id]\n",
    "        \n",
    "        # 1. Feature-based score\n",
    "        feature_score = self.compute_feature_based_score(user_idx, poi_idx, level)\n",
    "        \n",
    "        # 2. Graph-based score\n",
    "        graph_score = 0.0\n",
    "        if use_graph_context:\n",
    "            graph_score = self.compute_graph_based_score(user_idx, poi_idx, level)\n",
    "        \n",
    "        # 3. Hierarchical boost\n",
    "        hierarchical_score = 0.0\n",
    "        if use_hierarchical_boost:\n",
    "            hierarchical_score = self.compute_hierarchical_boost(poi_id, user_idx, level)\n",
    "        \n",
    "        # 4. Distance penalty\n",
    "        distance_penalty = 1.0\n",
    "        if use_distance_penalty and level == 0:\n",
    "            distance_penalty = self.compute_distance_penalty(user_id, poi_id, level)\n",
    "        \n",
    "        # 5. Interest match bonus\n",
    "        interest_bonus = self.compute_interest_match(user_id, poi_id, level)\n",
    "        \n",
    "        # Combine with updated weights\n",
    "        # REDUCE feature score weight, ADD distance penalty\n",
    "        final_score = (0.3 * feature_score +           \n",
    "                    0.2 * graph_score +              \n",
    "                    0.1 * hierarchical_score +       \n",
    "                    0.3 * distance_penalty * 100 +   \n",
    "                    0.1 * interest_bonus * 100)      \n",
    "        \n",
    "        return float(final_score)\n",
    "\n",
    "    def compute_interest_match(self, user_id: str, poi_id: str, level: int = 0) -> float:\n",
    "        \"\"\"\n",
    "        Match user interests to POI category/characteristics\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            poi_id: POI ID\n",
    "            level: Granularity level (default: 0)\n",
    "        \n",
    "        Returns:\n",
    "            Interest match score (0.0 - 1.0)\n",
    "        \"\"\"\n",
    "        user_row = self.users_df[self.users_df['uudi'] == user_id].iloc[0]\n",
    "        user_interests = set([i.strip().lower() for i in user_row['interests'].split(';')])\n",
    "        \n",
    "        # Only compute detailed interest match for level 0 (individual POIs)\n",
    "        if level != 0:\n",
    "            # For higher levels, return a moderate score (0.5)\n",
    "            # Or aggregate from children\n",
    "            return 0.5\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Check if POI exists at this level\n",
    "        if poi_id not in self.poi_tree[level_key]:\n",
    "            return 0.0\n",
    "        \n",
    "        poi_data = self.poi_tree[level_key][poi_id]\n",
    "        poi_category = poi_data['data'].get('category', '').lower()\n",
    "        poi_chars = poi_data['data'].get('characteristic', '').lower()\n",
    "        \n",
    "        # Check matches\n",
    "        matches = 0\n",
    "        \n",
    "        # Direct category match\n",
    "        if 'food' in user_interests and poi_category in ['restaurant', 'cafe', 'food_court']:\n",
    "            matches += 1\n",
    "        \n",
    "        if 'shopping' in user_interests and poi_category in ['shopping_mall', 'retail', 'store']:\n",
    "            matches += 1\n",
    "        \n",
    "        if 'movies' in user_interests and 'cinema' in poi_category:\n",
    "            matches += 2  # Strong match\n",
    "        \n",
    "        # Characteristic match\n",
    "        for interest in user_interests:\n",
    "            if interest in poi_chars:\n",
    "                matches += 0.5\n",
    "        \n",
    "        return min(matches / 3.0, 1.0)  # Normalize to 0-1\n",
    "    \n",
    "    def compute_distance_penalty(self, user_id: str, poi_id: str, level: int = 0) -> float:\n",
    "        \"\"\"\n",
    "        Compute distance penalty based on user's home location\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            poi_id: POI ID\n",
    "            level: Granularity level\n",
    "        \n",
    "        Returns:\n",
    "            Penalty factor (1.0 = nearby, 0.0 = very far)\n",
    "        \"\"\"\n",
    "        # Area to coordinates mapping\n",
    "        area_coords = {\n",
    "            'Jurong East': (1.3329, 103.7436),\n",
    "            'Yishun': (1.4304, 103.8354),\n",
    "            'Bishan': (1.3526, 103.8352),\n",
    "            'Tampines': (1.3496, 103.9568),\n",
    "            'Woodlands': (1.4382, 103.7891),\n",
    "            'Ang Mo Kio': (1.3691, 103.8454),\n",
    "            'Bedok': (1.3236, 103.9273),\n",
    "            'Clementi': (1.3162, 103.7649),\n",
    "            'Hougang': (1.3612, 103.8864),\n",
    "            'Punggol': (1.4054, 103.9021),\n",
    "            'Sengkang': (1.3868, 103.8914),\n",
    "            'Bukit Batok': (1.3590, 103.7637),\n",
    "            'Bukit Panjang': (1.3774, 103.7718),\n",
    "            'Choa Chu Kang': (1.3840, 103.7470),\n",
    "            'Pasir Ris': (1.3721, 103.9474),\n",
    "            'Sembawang': (1.4491, 103.8185),\n",
    "            'Serangoon': (1.3554, 103.8679),\n",
    "            'Toa Payoh': (1.3343, 103.8564),\n",
    "        }\n",
    "        \n",
    "        user_row = self.users_df[self.users_df['uudi'] == user_id].iloc[0]\n",
    "        user_area = user_row['area_of_residence']\n",
    "        \n",
    "        if user_area not in area_coords:\n",
    "            return 0.5  # Moderate penalty if unknown\n",
    "        \n",
    "        user_lat, user_lon = area_coords[user_area]\n",
    "        \n",
    "        # Get POI location based on level\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        if poi_id not in self.poi_tree[level_key]:\n",
    "            return 0.5\n",
    "        \n",
    "        poi_data = self.poi_tree[level_key][poi_id]\n",
    "        poi_spatial = poi_data.get('spatial')\n",
    "        \n",
    "        if not poi_spatial:\n",
    "            return 0.5  # No spatial data\n",
    "        \n",
    "        if isinstance(poi_spatial, str):\n",
    "            poi_spatial = eval(poi_spatial)\n",
    "        \n",
    "        poi_lat, poi_lon = poi_spatial\n",
    "        \n",
    "        # Calculate distance\n",
    "        distance = self._haversine_distance(user_lat, user_lon, poi_lat, poi_lon)\n",
    "        \n",
    "        # Transportation-based distance tolerance\n",
    "        user_transport = user_row['transportation_modes']\n",
    "        \n",
    "        if 'car' in user_transport or 'ride-hailing' in user_transport:\n",
    "            max_comfortable_distance = 15.0  # km\n",
    "        elif 'MRT' in user_transport or 'bus' in user_transport:\n",
    "            max_comfortable_distance = 8.0\n",
    "        else:\n",
    "            max_comfortable_distance = 3.0  # Walking\n",
    "        \n",
    "        # Adjust tolerance for higher levels (broader areas)\n",
    "        if level == 1:\n",
    "            max_comfortable_distance *= 1.2\n",
    "        elif level == 2:\n",
    "            max_comfortable_distance *= 1.5\n",
    "        elif level == 3:\n",
    "            max_comfortable_distance *= 2.0\n",
    "        \n",
    "        # Exponential decay penalty\n",
    "        penalty = np.exp(-distance / max_comfortable_distance)\n",
    "        \n",
    "        return float(penalty)\n",
    "    \n",
    "    def _diversify_by_category(self, poi_scores: List[Tuple[str, float]], top_k: int) -> List:\n",
    "        \"\"\"\n",
    "        Ensure recommendations span multiple categories\n",
    "        \"\"\"\n",
    "        selected = []\n",
    "        category_counts = defaultdict(int)\n",
    "        max_per_category = max(2, top_k // 3)  # Max 2-3 items per category\n",
    "        \n",
    "        for poi_id, score in poi_scores:\n",
    "            poi_data = self.poi_tree['level_0'][poi_id]\n",
    "            category = poi_data['data'].get('category', 'other')\n",
    "            \n",
    "            if category_counts[category] < max_per_category:\n",
    "                selected.append((poi_id, score))\n",
    "                category_counts[category] += 1\n",
    "            \n",
    "            if len(selected) >= top_k:\n",
    "                break\n",
    "        \n",
    "        return selected\n",
    "    \n",
    "    def _haversine_distance(self, lat1: float, lon1: float, \n",
    "                           lat2: float, lon2: float) -> float:\n",
    "        \"\"\"Calculate distance between two coordinates in km\"\"\"\n",
    "        R = 6371\n",
    "        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "        return R * c\n",
    "    \n",
    "    # ========================================================================\n",
    "    # MULTI-GRANULARITY RECOMMENDATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    def recommend_at_level(self,\n",
    "                          user_id: str,\n",
    "                          level: int,\n",
    "                          top_k: int = 10,\n",
    "                          filter_visited: bool = True,\n",
    "                          use_constraints: bool = False,\n",
    "                          **kwargs) -> List[Tuple[str, float, Dict]]:\n",
    "        \"\"\"\n",
    "        Generate recommendations at specific granularity level\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            level: Granularity level (0=individual, 1=container, 2=district, 3=region)\n",
    "            top_k: Number of recommendations\n",
    "            filter_visited: Filter out visited POIs\n",
    "            use_constraints: Apply user constraints (only for level 0)\n",
    "        \n",
    "        Returns:\n",
    "            List of (poi_id, score, poi_info) tuples\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_id_to_idx:\n",
    "            return []\n",
    "        \n",
    "        level_key = f'level_{level}'\n",
    "        all_poi_ids = list(self.poi_tree[level_key].keys())\n",
    "        \n",
    "        # Get visited POIs at this level\n",
    "        visited_pois = set(self.user_history.get(user_id, {}).get(level, []))\n",
    "        \n",
    "        # Score all POIs\n",
    "        poi_scores = []\n",
    "        \n",
    "        for poi_id in all_poi_ids:\n",
    "            if filter_visited and poi_id in visited_pois:\n",
    "                continue\n",
    "            \n",
    "            score = self.compute_multi_granularity_score(\n",
    "                user_id, poi_id, level, **kwargs\n",
    "            )\n",
    "            \n",
    "            poi_scores.append((poi_id, score))\n",
    "        \n",
    "        # Sort by score\n",
    "        poi_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Get top-K\n",
    "        top_pois = poi_scores[:top_k]\n",
    "        \n",
    "        # Add POI information\n",
    "        recommendations = []\n",
    "        for poi_id, score in top_pois:\n",
    "            poi_data = self.poi_tree[level_key][poi_id]\n",
    "            \n",
    "            # Build info based on level\n",
    "            if level == 0:\n",
    "                poi_info = {\n",
    "                    'name': poi_data['name'],\n",
    "                    'category': poi_data['data'].get('category', 'N/A'),\n",
    "                    'price': poi_data['data'].get('price', 'N/A'),\n",
    "                    'popularity': poi_data['data'].get('popularity', 'N/A'),\n",
    "                    'region': poi_data['data'].get('region', 'N/A'),\n",
    "                    'type': 'Individual POI'\n",
    "                }\n",
    "            elif level == 1:\n",
    "                # Container (e.g., mall, building)\n",
    "                children = poi_data.get('children', [])\n",
    "                poi_info = {\n",
    "                    'name': poi_data['name'],\n",
    "                    'textual': poi_data.get('textual', '')[:100],\n",
    "                    'num_pois': len(children),\n",
    "                    'type': 'Container/Venue'\n",
    "                }\n",
    "            elif level == 2:\n",
    "                # District\n",
    "                children = poi_data.get('children', [])\n",
    "                poi_info = {\n",
    "                    'name': poi_data['name'],\n",
    "                    'textual': poi_data.get('textual', '')[:100],\n",
    "                    'num_venues': len(children),\n",
    "                    'type': 'District'\n",
    "                }\n",
    "            else:  # level == 3\n",
    "                # Region\n",
    "                children = poi_data.get('children', [])\n",
    "                poi_info = {\n",
    "                    'name': poi_data['name'],\n",
    "                    'textual': poi_data.get('textual', '')[:100],\n",
    "                    'num_districts': len(children),\n",
    "                    'type': 'Region'\n",
    "                }\n",
    "            \n",
    "            recommendations.append((poi_id, score, poi_info))\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def recommend_multi_granularity(self,\n",
    "                                   user_id: str,\n",
    "                                   levels: List[int] = [0, 1, 2, 3],\n",
    "                                   top_k_per_level: int = 5,\n",
    "                                   filter_visited: bool = True,\n",
    "                                   **kwargs) -> Dict[int, List[Tuple[str, float, Dict]]]:\n",
    "        \"\"\"\n",
    "        Generate recommendations at multiple granularity levels\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            levels: List of levels to generate recommendations for\n",
    "            top_k_per_level: Number of recommendations per level\n",
    "            filter_visited: Filter visited POIs\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping level -> recommendations\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"MULTI-GRANULARITY RECOMMENDATIONS FOR USER: {user_id}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        level_names = {\n",
    "            0: \"INDIVIDUAL POIs\",\n",
    "            1: \"CONTAINERS/VENUES\",\n",
    "            2: \"DISTRICTS\",\n",
    "            3: \"REGIONS\"\n",
    "        }\n",
    "        \n",
    "        for level in levels:\n",
    "            print(f\"Generating Level {level} ({level_names[level]}) recommendations...\")\n",
    "            recommendations = self.recommend_at_level(\n",
    "                user_id=user_id,\n",
    "                level=level,\n",
    "                top_k=top_k_per_level,\n",
    "                filter_visited=filter_visited,\n",
    "                **kwargs\n",
    "            )\n",
    "            results[level] = recommendations\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def display_multi_granularity_recommendations(self, \n",
    "                                                 recommendations: Dict[int, List],\n",
    "                                                 show_details: bool = True):\n",
    "        \"\"\"\n",
    "        Pretty print multi-granularity recommendations\n",
    "        \n",
    "        Args:\n",
    "            recommendations: Dict mapping level -> list of recommendations\n",
    "            show_details: Show detailed information\n",
    "        \"\"\"\n",
    "        level_names = {\n",
    "            0: \"LEVEL 0: INDIVIDUAL POIs (Specific Entities)\",\n",
    "            1: \"LEVEL 1: CONTAINERS/VENUES (Malls, Buildings, etc.)\",\n",
    "            2: \"LEVEL 2: DISTRICTS (Geographic Clusters)\",\n",
    "            3: \"LEVEL 3: REGIONS (Large Areas)\"\n",
    "        }\n",
    "        \n",
    "        level_descriptions = {\n",
    "            0: \"Specific places you can visit right now\",\n",
    "            1: \"Venues containing multiple places of interest\",\n",
    "            2: \"Neighborhoods or districts to explore\",\n",
    "            3: \"Broader regions for day trips\"\n",
    "        }\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"MULTI-GRANULARITY RECOMMENDATIONS\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for level in sorted(recommendations.keys()):\n",
    "            recs = recommendations[level]\n",
    "            \n",
    "            print(f\"\\n{level_names[level]}\")\n",
    "            print(f\"({level_descriptions[level]})\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "            if not recs:\n",
    "                print(\"  No recommendations at this level\")\n",
    "                continue\n",
    "            \n",
    "            for rank, (poi_id, score, poi_info) in enumerate(recs, 1):\n",
    "                print(f\"\\n{rank}. {poi_info['name']}\")\n",
    "                print(f\"   Score: {score:.4f}\")\n",
    "                print(f\"   Type: {poi_info['type']}\")\n",
    "                \n",
    "                if show_details:\n",
    "                    if level == 0:\n",
    "                        print(f\"   Category: {poi_info.get('category', 'N/A')}\")\n",
    "                        print(f\"   Price: {poi_info.get('price', 'N/A')}\")\n",
    "                        print(f\"   Popularity: {poi_info.get('popularity', 'N/A')}\")\n",
    "                    elif level == 1:\n",
    "                        print(f\"   Contains: {poi_info.get('num_pois', 0)} POIs\")\n",
    "                        if poi_info.get('textual'):\n",
    "                            print(f\"   Description: {poi_info['textual']}\")\n",
    "                    elif level == 2:\n",
    "                        print(f\"   Contains: {poi_info.get('num_venues', 0)} venues\")\n",
    "                        if poi_info.get('textual'):\n",
    "                            print(f\"   Description: {poi_info['textual']}\")\n",
    "                    elif level == 3:\n",
    "                        print(f\"   Contains: {poi_info.get('num_districts', 0)} districts\")\n",
    "                        if poi_info.get('textual'):\n",
    "                            print(f\"   Description: {poi_info['textual']}\")\n",
    "    \n",
    "    def recommend_adaptive_granularity(self,\n",
    "                                      user_id: str,\n",
    "                                      context: str = 'general',\n",
    "                                      top_k: int = 10) -> List[Tuple[str, float, Dict, int]]:\n",
    "        \"\"\"\n",
    "        Adaptively select granularity level based on context\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            context: Context hint ('specific', 'venue', 'exploration', 'general')\n",
    "            top_k: Total number of recommendations\n",
    "        \n",
    "        Returns:\n",
    "            List of (poi_id, score, poi_info, level) tuples\n",
    "        \"\"\"\n",
    "        # Context-based level distribution\n",
    "        context_distributions = {\n",
    "            'specific': {0: 0.8, 1: 0.15, 2: 0.05, 3: 0.0},\n",
    "            'venue': {0: 0.3, 1: 0.5, 2: 0.15, 3: 0.05},\n",
    "            'exploration': {0: 0.2, 1: 0.3, 2: 0.3, 3: 0.2},\n",
    "            'general': {0: 0.5, 1: 0.3, 2: 0.15, 3: 0.05}\n",
    "        }\n",
    "        \n",
    "        distribution = context_distributions.get(context, context_distributions['general'])\n",
    "        \n",
    "        # Calculate number of recommendations per level\n",
    "        recs_per_level = {\n",
    "            level: max(1, int(top_k * weight))\n",
    "            for level, weight in distribution.items() if weight > 0\n",
    "        }\n",
    "        \n",
    "        # Generate recommendations at each level\n",
    "        all_recommendations = []\n",
    "        \n",
    "        for level, k in recs_per_level.items():\n",
    "            level_recs = self.recommend_at_level(user_id, level, top_k=k)\n",
    "            for poi_id, score, poi_info in level_recs:\n",
    "                all_recommendations.append((poi_id, score, poi_info, level))\n",
    "        \n",
    "        # Sort by score and return top-K\n",
    "        all_recommendations.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return all_recommendations[:top_k]\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXPORT & VISUALIZATION\n",
    "    # ========================================================================\n",
    "    \n",
    "    def export_multi_granularity_recommendations(self,\n",
    "                                                recommendations: Dict[int, List],\n",
    "                                                user_id: str,\n",
    "                                                output_prefix: str = 'multi_gran_recs'):\n",
    "        \"\"\"\n",
    "        Export multi-granularity recommendations to CSV files\n",
    "        \n",
    "        Args:\n",
    "            recommendations: Dict of recommendations by level\n",
    "            user_id: User ID\n",
    "            output_prefix: Prefix for output files\n",
    "        \"\"\"\n",
    "        user_name = self.users_df[self.users_df['uudi'] == user_id].iloc[0]['name']\n",
    "        \n",
    "        for level, recs in recommendations.items():\n",
    "            rows = []\n",
    "            for rank, (poi_id, score, poi_info) in enumerate(recs, 1):\n",
    "                row = {\n",
    "                    'user_id': user_id,\n",
    "                    'user_name': user_name,\n",
    "                    'level': level,\n",
    "                    'rank': rank,\n",
    "                    'poi_id': poi_id,\n",
    "                    'poi_name': poi_info['name'],\n",
    "                    'score': score,\n",
    "                    'type': poi_info['type']\n",
    "                }\n",
    "                \n",
    "                # Add level-specific fields\n",
    "                if level == 0:\n",
    "                    row.update({\n",
    "                        'category': poi_info.get('category', ''),\n",
    "                        'price': poi_info.get('price', ''),\n",
    "                        'popularity': poi_info.get('popularity', '')\n",
    "                    })\n",
    "                elif level == 1:\n",
    "                    row['num_pois'] = poi_info.get('num_pois', 0)\n",
    "                elif level == 2:\n",
    "                    row['num_venues'] = poi_info.get('num_venues', 0)\n",
    "                elif level == 3:\n",
    "                    row['num_districts'] = poi_info.get('num_districts', 0)\n",
    "                \n",
    "                rows.append(row)\n",
    "            \n",
    "            df = pd.DataFrame(rows)\n",
    "            output_file = f'{output_prefix}_level{level}_{user_name}.csv'\n",
    "            df.to_csv(output_file, index=False)\n",
    "            print(f\"Level {level} recommendations exported to: {output_file}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # EXPLAINABILITY \n",
    "    # ========================================================================\n",
    "\n",
    "    def build_reason_flags(self, \n",
    "                      user_id: str, \n",
    "                      poi_id: str,\n",
    "                      level: int = 0) -> Dict[str, bool]:\n",
    "        \"\"\"\n",
    "        Build interpretable boolean flags explaining WHY this POI is recommended\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            poi_id: POI ID\n",
    "            level: Granularity level\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary of reason flags (True/False)\n",
    "        \"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Get user profile\n",
    "        user_row = self.users_df[self.users_df['uudi'] == user_id].iloc[0]\n",
    "        user_interests = set([i.strip().lower() for i in user_row['interests'].split(';')])\n",
    "        user_area = user_row['area_of_residence']\n",
    "        \n",
    "        # Get POI data\n",
    "        poi_data = self.poi_tree[level_key][poi_id]\n",
    "        \n",
    "        # Initialize flags\n",
    "        flags = {}\n",
    "        \n",
    "        if level == 0:\n",
    "            # Individual POI flags\n",
    "            poi_category = poi_data['data'].get('category', '').lower()\n",
    "            poi_chars = poi_data['data'].get('characteristic', '').lower()\n",
    "            poi_popularity = float(poi_data['data'].get('popularity', 0))\n",
    "            poi_price = poi_data['data'].get('price', '')\n",
    "            \n",
    "            # 1. Category match\n",
    "            interest_category_map = {\n",
    "                'food': ['restaurant', 'cafe', 'food_court', 'hawker_centre'],\n",
    "                'shopping': ['shopping_mall', 'retail', 'store', 'boutique'],\n",
    "                'movies': ['cinema', 'theatre'],\n",
    "                'fitness': ['gym', 'sports', 'fitness'],\n",
    "                'entertainment': ['cinema', 'arcade', 'karaoke', 'bar']\n",
    "            }\n",
    "            \n",
    "            flags['matches_interest'] = any(\n",
    "                any(cat in poi_category for cat in interest_category_map.get(interest, []))\n",
    "                for interest in user_interests\n",
    "            )\n",
    "            \n",
    "            # 2. Previously visited\n",
    "            visited_pois = self.user_history.get(user_id, {}).get(0, [])\n",
    "            flags['visited_before'] = poi_id in visited_pois\n",
    "            \n",
    "            # 3. Nearby (distance check)\n",
    "            distance_penalty = self.compute_distance_penalty(user_id, poi_id)\n",
    "            flags['nearby'] = distance_penalty > 0.7  # Within comfortable distance\n",
    "            flags['very_nearby'] = distance_penalty > 0.9  # Very close\n",
    "            \n",
    "            # 4. Popular\n",
    "            flags['popular'] = poi_popularity >= 4.0\n",
    "            flags['highly_popular'] = poi_popularity >= 4.5\n",
    "            \n",
    "            # 5. Price match\n",
    "            user_price_sens = user_row['price_sensitivity'].lower()\n",
    "            flags['matches_budget'] = False\n",
    "            \n",
    "            if poi_price and poi_price != '':\n",
    "                try:\n",
    "                    if '-' in str(poi_price):\n",
    "                        prices = str(poi_price).split('-')\n",
    "                        avg_price = (float(prices[0].strip()) + float(prices[1].strip())) / 2\n",
    "                    else:\n",
    "                        avg_price = float(poi_price)\n",
    "                    \n",
    "                    if user_price_sens == 'low' and avg_price <= 20:\n",
    "                        flags['matches_budget'] = True\n",
    "                    elif user_price_sens == 'medium' and 15 <= avg_price <= 40:\n",
    "                        flags['matches_budget'] = True\n",
    "                    elif user_price_sens == 'high' and avg_price >= 30:\n",
    "                        flags['matches_budget'] = True\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # 6. Similar to previous visits\n",
    "            similar_visited = self._get_similar_visited_pois(user_id, poi_id)\n",
    "            flags['similar_to_past'] = len(similar_visited) > 0 and similar_visited[0][1] > 0.5\n",
    "            \n",
    "            # 7. Trending in area\n",
    "            poi_district = poi_data['data'].get('district', '')\n",
    "            flags['trending_in_area'] = False  # Placeholder - could compute from recent interactions\n",
    "            \n",
    "            # 8. Parent venue is popular (hierarchical)\n",
    "            parent_id = poi_data.get('parent')\n",
    "            if parent_id and parent_id in self.poi_id_to_idx[1]:\n",
    "                parent_idx = self.poi_id_to_idx[1][parent_id]\n",
    "                user_idx = self.user_id_to_idx[user_id]\n",
    "                parent_score = self.compute_feature_based_score(user_idx, parent_idx, level=1)\n",
    "                flags['in_popular_venue'] = parent_score > 50\n",
    "            else:\n",
    "                flags['in_popular_venue'] = False\n",
    "        \n",
    "        else:\n",
    "            # Container/District/Region flags\n",
    "            flags['matches_interest'] = True  # Simplified for higher levels\n",
    "            flags['visited_before'] = poi_id in self.user_history.get(user_id, {}).get(level, [])\n",
    "            flags['nearby'] = True  # Higher levels are broader\n",
    "            flags['popular'] = True  # Placeholder\n",
    "            flags['has_many_options'] = len(poi_data.get('children', [])) > 10\n",
    "        \n",
    "        return flags\n",
    "\n",
    "\n",
    "    def build_human_explanation(self,\n",
    "                            user_id: str,\n",
    "                            poi_id: str,\n",
    "                            level: int = 0,\n",
    "                            reason_flags: Dict[str, bool] = None,\n",
    "                            score_components: Dict[str, float] = None) -> str:\n",
    "        \"\"\"\n",
    "        Generate natural language explanation for a recommendation\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            poi_id: POI ID\n",
    "            level: Granularity level\n",
    "            reason_flags: Pre-computed reason flags (optional)\n",
    "            score_components: Score breakdown (optional)\n",
    "        \n",
    "        Returns:\n",
    "            Human-readable explanation string\n",
    "        \"\"\"\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # Get data\n",
    "        user_row = self.users_df[self.users_df['uudi'] == user_id].iloc[0]\n",
    "        user_name = user_row['name']\n",
    "        poi_data = self.poi_tree[level_key][poi_id]\n",
    "        poi_name = poi_data['name']\n",
    "        \n",
    "        # Get reason flags\n",
    "        if reason_flags is None:\n",
    "            reason_flags = self.build_reason_flags(user_id, poi_id, level)\n",
    "        \n",
    "        # Build explanation parts\n",
    "        parts = []\n",
    "        \n",
    "        # Introduction\n",
    "        if level == 0:\n",
    "            intro = f\"We recommend **{poi_name}** for you because:\"\n",
    "        else:\n",
    "            intro = f\"We suggest exploring **{poi_name}** because:\"\n",
    "        \n",
    "        # Main reasons (prioritized by importance)\n",
    "        \n",
    "        # 1. Visited before (strongest signal)\n",
    "        if reason_flags.get('visited_before'):\n",
    "            parts.append(\"âœ“ You've visited here before and seem to like it\")\n",
    "        \n",
    "        # 2. Very nearby (convenience)\n",
    "        elif reason_flags.get('very_nearby'):\n",
    "            parts.append(\"âœ“ It's very close to your home area\")\n",
    "        elif reason_flags.get('nearby'):\n",
    "            parts.append(\"âœ“ It's within a comfortable distance from you\")\n",
    "        \n",
    "        # 3. Interest match\n",
    "        if reason_flags.get('matches_interest'):\n",
    "            user_interests = user_row['interests']\n",
    "            if level == 0:\n",
    "                poi_category = poi_data['data'].get('category', '')\n",
    "                parts.append(f\"âœ“ It matches your interests ({user_interests}) - it's a {poi_category}\")\n",
    "            else:\n",
    "                parts.append(f\"âœ“ It has options matching your interests ({user_interests})\")\n",
    "        \n",
    "        # 4. Budget match\n",
    "        if reason_flags.get('matches_budget'):\n",
    "            parts.append(f\"âœ“ Prices fit your budget ({user_row['price_sensitivity']} spending)\")\n",
    "        \n",
    "        # 5. Popularity\n",
    "        if reason_flags.get('highly_popular'):\n",
    "            parts.append(\"âœ“ It's highly rated by other users (â­ 4.5+)\")\n",
    "        elif reason_flags.get('popular'):\n",
    "            parts.append(\"âœ“ It's popular among other users\")\n",
    "        \n",
    "        # 6. Similar to past\n",
    "        if reason_flags.get('similar_to_past') and not reason_flags.get('visited_before'):\n",
    "            similar_pois = self._get_similar_visited_pois(user_id, poi_id)\n",
    "            if similar_pois:\n",
    "                similar_name = similar_pois[0][0]\n",
    "                parts.append(f\"âœ“ It's similar to places you've enjoyed (like {similar_name})\")\n",
    "        \n",
    "        # 7. In popular venue (hierarchical context)\n",
    "        if reason_flags.get('in_popular_venue'):\n",
    "            parent_id = poi_data.get('parent')\n",
    "            if parent_id:\n",
    "                parent_name = self.poi_tree['level_1'][parent_id]['name']\n",
    "                parts.append(f\"âœ“ It's located in {parent_name}, which you might like\")\n",
    "        \n",
    "        # 8. Many options (for higher levels)\n",
    "        if reason_flags.get('has_many_options'):\n",
    "            num_children = len(poi_data.get('children', []))\n",
    "            parts.append(f\"âœ“ It offers {num_children}+ places to explore\")\n",
    "        \n",
    "        # Limit to top 3-4 reasons\n",
    "        parts = parts[:4]\n",
    "        \n",
    "        # Construct final explanation\n",
    "        if not parts:\n",
    "            explanation = intro + \"\\n  â€¢ It matches your overall preferences and location\"\n",
    "        else:\n",
    "            explanation = intro + \"\\n  \" + \"\\n  \".join(parts)\n",
    "        \n",
    "        # Add confidence/score context\n",
    "        if score_components:\n",
    "            total_score = score_components.get('total_score', 0)\n",
    "            if total_score > 80:\n",
    "                explanation += \"\\n\\nðŸŽ¯ **Strong match** - Highly recommended!\"\n",
    "            elif total_score > 50:\n",
    "                explanation += \"\\n\\nðŸ‘ **Good match** - Worth checking out\"\n",
    "            else:\n",
    "                explanation += \"\\n\\nðŸ’¡ **Potential match** - Might be interesting\"\n",
    "        \n",
    "        return explanation\n",
    "\n",
    "\n",
    "    def explain_recommendation_enhanced(self,\n",
    "                                    user_id: str,\n",
    "                                    poi_id: str,\n",
    "                                    level: int = 0) -> Dict[str, any]:\n",
    "        \"\"\"\n",
    "        Complete enhanced explanation combining:\n",
    "        - Technical score breakdown\n",
    "        - Interpretable reason flags\n",
    "        - Natural language explanation\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            poi_id: POI ID\n",
    "            level: Granularity level\n",
    "        \n",
    "        Returns:\n",
    "            Comprehensive explanation dictionary\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_id_to_idx or poi_id not in self.poi_id_to_idx[level]:\n",
    "            return {}\n",
    "        \n",
    "        user_idx = self.user_id_to_idx[user_id]\n",
    "        poi_idx = self.poi_id_to_idx[level][poi_id]\n",
    "        level_key = f'level_{level}'\n",
    "        \n",
    "        # 1. Get technical score components\n",
    "        feature_score = self.compute_feature_based_score(user_idx, poi_idx, level)\n",
    "        graph_score = self.compute_graph_based_score(user_idx, poi_idx, level)\n",
    "        hierarchical_score = self.compute_hierarchical_boost(poi_id, user_idx, level)\n",
    "        \n",
    "        if level == 0:\n",
    "            distance_penalty = self.compute_distance_penalty(user_id, poi_id)\n",
    "            interest_bonus = self.compute_interest_match(user_id, poi_id)\n",
    "        else:\n",
    "            distance_penalty = 1.0\n",
    "            interest_bonus = 0.0\n",
    "        \n",
    "        total_score = (0.25 * feature_score + \n",
    "                    0.15 * graph_score + \n",
    "                    0.10 * hierarchical_score +\n",
    "                    0.35 * distance_penalty * 100 +\n",
    "                    0.15 * interest_bonus * 100)\n",
    "        \n",
    "        score_components = {\n",
    "            'total_score': total_score,\n",
    "            'feature_based': {\n",
    "                'raw_score': feature_score,\n",
    "                'contribution': 0.25 * feature_score,\n",
    "                'weight': 0.25,\n",
    "                'description': 'Match between your profile and POI attributes'\n",
    "            },\n",
    "            'graph_based': {\n",
    "                'raw_score': graph_score,\n",
    "                'contribution': 0.15 * graph_score,\n",
    "                'weight': 0.15,\n",
    "                'description': 'Spatial context from places you\\'ve visited'\n",
    "            },\n",
    "            'hierarchical': {\n",
    "                'raw_score': hierarchical_score,\n",
    "                'contribution': 0.10 * hierarchical_score,\n",
    "                'weight': 0.10,\n",
    "                'description': 'Popularity of the surrounding area'\n",
    "            },\n",
    "            'distance': {\n",
    "                'raw_score': distance_penalty,\n",
    "                'contribution': 0.35 * distance_penalty * 100,\n",
    "                'weight': 0.35,\n",
    "                'description': 'How convenient it is to reach from your location'\n",
    "            },\n",
    "            'interest_match': {\n",
    "                'raw_score': interest_bonus,\n",
    "                'contribution': 0.15 * interest_bonus * 100,\n",
    "                'weight': 0.15,\n",
    "                'description': 'How well it matches your stated interests'\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Sort components by contribution\n",
    "        ranked_components = sorted(\n",
    "            score_components.items(),\n",
    "            key=lambda x: x[1]['contribution'] if isinstance(x[1], dict) else 0,\n",
    "            reverse=True\n",
    "        )\n",
    "        top_factors = [name for name, comp in ranked_components[1:4]]  # Skip 'total_score'\n",
    "        \n",
    "        # 2. Get reason flags (interpretable)\n",
    "        reason_flags = self.build_reason_flags(user_id, poi_id, level)\n",
    "        \n",
    "        # 3. Generate human explanation\n",
    "        human_explanation = self.build_human_explanation(\n",
    "            user_id, poi_id, level, reason_flags, score_components\n",
    "        )\n",
    "        \n",
    "        # 4. Get POI details\n",
    "        poi_data = self.poi_tree[level_key][poi_id]\n",
    "        user_data = self.users_df[self.users_df['uudi'] == user_id].iloc[0]\n",
    "        \n",
    "        # 5. Get similar visited POIs\n",
    "        similar_visited = []\n",
    "        if level == 0:\n",
    "            similar_visited = self._get_similar_visited_pois(user_id, poi_id)[:3]\n",
    "        \n",
    "        # 6. Construct complete explanation\n",
    "        explanation = {\n",
    "            # Technical breakdown (for developers/analysts)\n",
    "            'score_breakdown': score_components,\n",
    "            'top_contributing_factors': top_factors,\n",
    "            \n",
    "            # Interpretable reasons (for UI)\n",
    "            'reason_flags': reason_flags,\n",
    "            'active_reasons': [k for k, v in reason_flags.items() if v],\n",
    "            \n",
    "            # Natural language (for end users)\n",
    "            'human_explanation': human_explanation,\n",
    "            \n",
    "            # Context\n",
    "            'user_context': {\n",
    "                'name': user_data['name'],\n",
    "                'interests': user_data['interests'],\n",
    "                'area': user_data['area_of_residence'],\n",
    "                'price_sensitivity': user_data['price_sensitivity']\n",
    "            },\n",
    "            'poi_context': {\n",
    "                'name': poi_data['name'],\n",
    "                'type': 'Individual POI' if level == 0 else f'Level {level}',\n",
    "            },\n",
    "            \n",
    "            # Supporting evidence\n",
    "            'similar_visited_pois': similar_visited,\n",
    "        }\n",
    "        \n",
    "        if level == 0:\n",
    "            explanation['poi_context'].update({\n",
    "                'category': poi_data['data'].get('category', 'N/A'),\n",
    "                'price': poi_data['data'].get('price', 'N/A'),\n",
    "                'popularity': poi_data['data'].get('popularity', 'N/A'),\n",
    "                'characteristics': poi_data['data'].get('characteristic', ''),\n",
    "            })\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def _get_similar_visited_pois(self, user_id: str, candidate_poi: str) -> List[Tuple[str, float]]:\n",
    "        \"\"\"\n",
    "        Get user's visited POIs that are similar to candidate\n",
    "        \n",
    "        Args:\n",
    "            user_id: User ID\n",
    "            candidate_poi: Candidate POI ID\n",
    "        \n",
    "        Returns:\n",
    "            List of (poi_id, similarity) tuples\n",
    "        \"\"\"\n",
    "        visited_pois = self.user_history.get(user_id, [])\n",
    "        \n",
    "        if not visited_pois or candidate_poi not in self.poi_id_to_idx[0]:\n",
    "            return []\n",
    "        \n",
    "        candidate_idx = self.poi_id_to_idx[0][candidate_poi]\n",
    "        candidate_emb = self.Q_l['level_0'][candidate_idx]\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        for visited_poi in visited_pois:\n",
    "            if visited_poi not in self.poi_id_to_idx[0]:\n",
    "                continue\n",
    "            \n",
    "            visited_idx = self.poi_id_to_idx[0][visited_poi]\n",
    "            visited_emb = self.Q_l['level_0'][visited_idx]\n",
    "            \n",
    "            # Cosine similarity\n",
    "            min_len = min(len(candidate_emb), len(visited_emb))\n",
    "            sim = np.dot(candidate_emb[:min_len], visited_emb[:min_len])\n",
    "            sim /= (np.linalg.norm(candidate_emb[:min_len]) * np.linalg.norm(visited_emb[:min_len]) + 1e-10)\n",
    "            \n",
    "            poi_name = self.poi_tree['level_0'][visited_poi]['name']\n",
    "            similarities.append((poi_name, float(sim)))\n",
    "        \n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return similarities\n",
    "\n",
    "\n",
    "    def display_explanation(self, explanation: Dict[str, any], detailed: bool = False):\n",
    "        \"\"\"\n",
    "        Pretty print an explanation\n",
    "        \n",
    "        Args:\n",
    "            explanation: Explanation dictionary from explain_recommendation_enhanced()\n",
    "            detailed: Show technical details or just user-friendly explanation\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"RECOMMENDATION EXPLANATION\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Always show human explanation\n",
    "        print(\"\\n\" + explanation['human_explanation'])\n",
    "        \n",
    "        if detailed:\n",
    "            # Show technical breakdown\n",
    "            print(\"\\n\" + \"-\"*70)\n",
    "            print(\"TECHNICAL BREAKDOWN\")\n",
    "            print(\"-\"*70)\n",
    "            \n",
    "            print(f\"\\nTotal Score: {explanation['score_breakdown']['total_score']:.2f}/100\")\n",
    "            print(f\"Top Contributing Factors: {', '.join(explanation['top_contributing_factors'])}\")\n",
    "            \n",
    "            print(\"\\nScore Components:\")\n",
    "            for name, comp in explanation['score_breakdown'].items():\n",
    "                if name == 'total_score' or not isinstance(comp, dict):\n",
    "                    continue\n",
    "                print(f\"  â€¢ {name}:\")\n",
    "                print(f\"      Contribution: {comp['contribution']:.2f} (weight: {comp['weight']:.0%})\")\n",
    "                print(f\"      Description: {comp['description']}\")\n",
    "            \n",
    "            print(\"\\nActive Reasoning Flags:\")\n",
    "            for flag in explanation['active_reasons']:\n",
    "                print(f\"  âœ“ {flag}\")\n",
    "            \n",
    "            if explanation.get('similar_visited_pois'):\n",
    "                print(\"\\nSimilar Places You've Visited:\")\n",
    "                for poi_name, similarity in explanation['similar_visited_pois']:\n",
    "                    print(f\"  â€¢ {poi_name} (similarity: {similarity:.2f})\")\n",
    "\n",
    "    def explain_all_recommendations(self,\n",
    "                                    recommendations: Dict[int, List],\n",
    "                                    user_id: str,\n",
    "                                    detailed: bool = False,\n",
    "                                    top_n_detailed: int = 1) -> None:\n",
    "        \"\"\"\n",
    "        Display explanations for all recommendations across all levels\n",
    "        \n",
    "        Args:\n",
    "            recommendations: Dict mapping level -> list of recommendations\n",
    "            user_id: User ID\n",
    "            detailed: Show detailed technical breakdown\n",
    "            top_n_detailed: Number of recommendations per level to show detailed breakdown for\n",
    "        \"\"\"\n",
    "        level_names = {\n",
    "            0: \"INDIVIDUAL POIs\",\n",
    "            1: \"CONTAINERS/VENUES\",\n",
    "            2: \"DISTRICTS\",\n",
    "            3: \"REGIONS\"\n",
    "        }\n",
    "        \n",
    "        user_name = self.users_df[self.users_df['uudi'] == user_id].iloc[0]['name']\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(f\"EXPLANATIONS FOR ALL RECOMMENDATIONS - User: {user_name}\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        for level in sorted(recommendations.keys()):\n",
    "            recs = recommendations[level]\n",
    "            \n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"LEVEL {level}: {level_names[level]}\")\n",
    "            print(f\"{'='*70}\\n\")\n",
    "            \n",
    "            if not recs:\n",
    "                print(\"  No recommendations at this level\\n\")\n",
    "                continue\n",
    "            \n",
    "            for rank, (poi_id, score, poi_info) in enumerate(recs, 1):\n",
    "                print(f\"\\n{'-'*70}\")\n",
    "                print(f\"#{rank}. {poi_info['name']} (Score: {score:.2f})\")\n",
    "                print(f\"{'-'*70}\")\n",
    "                \n",
    "                # Get explanation\n",
    "                explanation = self.explain_recommendation_enhanced(user_id, poi_id, level)\n",
    "                \n",
    "                # Always show human explanation\n",
    "                print(explanation['human_explanation'])\n",
    "                \n",
    "                # Show detailed breakdown for top N recommendations\n",
    "                if detailed and rank <= top_n_detailed:\n",
    "                    print(f\"\\nðŸ“Š DETAILED SCORE BREAKDOWN:\")\n",
    "                    \n",
    "                    sb = explanation['score_breakdown']\n",
    "                    print(f\"   Total Score: {sb['total_score']:.2f}/100\")\n",
    "                    print(f\"   Top Contributing Factors: {', '.join(explanation['top_contributing_factors'])}\")\n",
    "                    \n",
    "                    print(f\"\\n   Components:\")\n",
    "                    for comp_name, comp_data in sb.items():\n",
    "                        if comp_name == 'total_score' or not isinstance(comp_data, dict):\n",
    "                            continue\n",
    "                        print(f\"      â€¢ {comp_name}: {comp_data['contribution']:.2f} \"\n",
    "                            f\"(weight: {comp_data['weight']:.0%})\")\n",
    "                    \n",
    "                    if explanation['active_reasons']:\n",
    "                        print(f\"\\n   Active Flags:\")\n",
    "                        for flag in explanation['active_reasons']:\n",
    "                            print(f\"      âœ“ {flag.replace('_', ' ').title()}\")\n",
    "                    \n",
    "                    if explanation.get('similar_visited_pois'):\n",
    "                        print(f\"\\n   Similar Places You've Visited:\")\n",
    "                        for poi_name, similarity in explanation['similar_visited_pois']:\n",
    "                            print(f\"      â€¢ {poi_name} (similarity: {similarity:.2f})\")\n",
    "                \n",
    "                # For non-detailed, just show quick summary\n",
    "                elif not detailed:\n",
    "                    print(f\"\\n   ðŸ“Œ Key factors: {', '.join(explanation['top_contributing_factors'][:3])}\")\n",
    "                \n",
    "                print()  # Spacing between recommendations\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(\"ALL EXPLANATIONS COMPLETE!\")\n",
    "        print(\"=\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf552d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING MULTI-GRANULARITY RECOMMENDATION FRAMEWORK\n",
      "======================================================================\n",
      "\n",
      "Loading attribute-based embeddings...\n",
      "Loading interaction-based components...\n",
      "Loading POI tree...\n",
      "Loading user profiles and interactions...\n",
      "\n",
      "======================================================================\n",
      "FRAMEWORK INITIALIZED SUCCESSFULLY\n",
      "======================================================================\n",
      "Users: 21\n",
      "POIs by level:\n",
      "  Level 0: 4696 POIs\n",
      "  Level 1: 1355 POIs\n",
      "  Level 2: 44 POIs\n",
      "  Level 3: 5 POIs\n",
      "Interactions: 529\n",
      "\n",
      "======================================================================\n",
      "MULTI-GRANULARITY RECOMMENDATIONS FOR USER: 966592ed-5bfd-4113-9c4d-d93cd3637b40\n",
      "======================================================================\n",
      "\n",
      "Generating Level 0 (INDIVIDUAL POIs) recommendations...\n",
      "Generating Level 1 (CONTAINERS/VENUES) recommendations...\n",
      "Generating Level 2 (DISTRICTS) recommendations...\n",
      "Generating Level 3 (REGIONS) recommendations...\n",
      "{'raw_prompt': 'I want coffee near Orchard', 'categories': ['cafe'], 'location_mentioned': 'Orchard', 'search_location': None, 'keywords': [], 'max_distance_km': 5.0}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    framework = MultiGranularityRecommendationFramework(\n",
    "        embeddings_file='embeddings.pkl',\n",
    "        interaction_learning_file='interaction_learning.pkl',\n",
    "        poi_tree_file='poi_tree_with_uuids.json',\n",
    "        users_file='user_preferences.csv',\n",
    "        interactions_file='user_poi_interactions.csv'\n",
    "    )\n",
    "\n",
    "    user_id = framework.users_df.iloc[0]['uudi']\n",
    "    user_name = framework.users_df.iloc[0]['name']\n",
    "\n",
    "    multi_gran_recs = framework.recommend_multi_granularity(\n",
    "        user_id=user_id,\n",
    "        levels=[0, 1, 2, 3],\n",
    "        top_k_per_level=5,\n",
    "        filter_visited=True\n",
    "    )\n",
    "\n",
    "    prompt = \"I want coffee near Orchard\"\n",
    "    result = framework.parse_user_prompt(prompt, None)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2726783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIALIZING MULTI-GRANULARITY RECOMMENDATION FRAMEWORK\n",
      "======================================================================\n",
      "\n",
      "Loading attribute-based embeddings...\n",
      "Loading interaction-based components...\n",
      "Loading POI tree...\n",
      "Loading user profiles and interactions...\n",
      "\n",
      "======================================================================\n",
      "FRAMEWORK INITIALIZED SUCCESSFULLY\n",
      "======================================================================\n",
      "Users: 21\n",
      "POIs by level:\n",
      "  Level 0: 4696 POIs\n",
      "  Level 1: 1355 POIs\n",
      "  Level 2: 44 POIs\n",
      "  Level 3: 5 POIs\n",
      "Interactions: 529\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 1: MULTI-GRANULARITY RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MULTI-GRANULARITY RECOMMENDATIONS FOR USER: 966592ed-5bfd-4113-9c4d-d93cd3637b40\n",
      "======================================================================\n",
      "\n",
      "Generating Level 0 (INDIVIDUAL POIs) recommendations...\n",
      "Generating Level 1 (CONTAINERS/VENUES) recommendations...\n",
      "Generating Level 2 (DISTRICTS) recommendations...\n",
      "Generating Level 3 (REGIONS) recommendations...\n",
      "\n",
      "======================================================================\n",
      "MULTI-GRANULARITY RECOMMENDATIONS\n",
      "======================================================================\n",
      "\n",
      "LEVEL 0: INDIVIDUAL POIs (Specific Entities)\n",
      "(Specific places you can visit right now)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. CHICHA San Chen\n",
      "   Score: 63.0056\n",
      "   Type: Individual POI\n",
      "   Category: cafe\n",
      "   Price: 14.38 - 21.94\n",
      "   Popularity: 4\n",
      "\n",
      "2. State Of Mind\n",
      "   Score: 57.0549\n",
      "   Type: Individual POI\n",
      "   Category: cafe\n",
      "   Price: 12.06 - 21.63\n",
      "   Popularity: 5\n",
      "\n",
      "3. Unicorn Kampung 1200\n",
      "   Score: 53.6066\n",
      "   Type: Individual POI\n",
      "   Category: cafe\n",
      "   Price: 11.73 - 20.71\n",
      "   Popularity: 4\n",
      "\n",
      "4. Pepper Lunch\n",
      "   Score: 33.6241\n",
      "   Type: Individual POI\n",
      "   Category: restaurant\n",
      "   Price: 37.22 - 50.38\n",
      "   Popularity: 5\n",
      "\n",
      "5. Tim Ho Wan\n",
      "   Score: 33.4169\n",
      "   Type: Individual POI\n",
      "   Category: restaurant\n",
      "   Price: 42.20 - 50.78\n",
      "   Popularity: 5\n",
      "\n",
      "LEVEL 1: CONTAINERS/VENUES (Malls, Buildings, etc.)\n",
      "(Venues containing multiple places of interest)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. Upper Dickson Road\n",
      "   Score: 49.6312\n",
      "   Type: Container/Venue\n",
      "   Contains: 7 POIs\n",
      "   Description: Upper Dickson Road Dakshaini Silks clothing_store #retail, #shopping Dhawals clothing_store #retail,\n",
      "\n",
      "2. Yio Chu Kang\n",
      "   Score: 49.4802\n",
      "   Type: Container/Venue\n",
      "   Contains: 99 POIs\n",
      "   Description: Yio Chu Kang bakery #chill, #dining S-Power Mini Supermarket supermarket #budget, #essentials 7-Elev\n",
      "\n",
      "3. Wishart Road\n",
      "   Score: 49.3410\n",
      "   Type: Container/Venue\n",
      "   Contains: 1 POIs\n",
      "   Description: Wishart Road Shipmart Pte Ltd supermarket #budget, #essentials\n",
      "\n",
      "4. Medical Drive\n",
      "   Score: 48.6349\n",
      "   Type: Container/Venue\n",
      "   Contains: 1 POIs\n",
      "   Description: Medical Drive Jewel Coffee cafe #bonding, #chill, #dining, #pet-friendly\n",
      "\n",
      "5. Serangoon Road\n",
      "   Score: 48.5504\n",
      "   Type: Container/Venue\n",
      "   Contains: 37 POIs\n",
      "   Description: Serangoon Road Auroma electronics_store #retail, #shopping Haniffa clothing_store #retail, #shopping\n",
      "\n",
      "LEVEL 2: DISTRICTS (Geographic Clusters)\n",
      "(Neighborhoods or districts to explore)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. ANG MO KIO\n",
      "   Score: 45.1192\n",
      "   Type: District\n",
      "   Contains: 23 venues\n",
      "   Description: ANG MO KIO Broadway Plaza shopping_mall #family, #lifestyle, #shopping Haig Road Putu Piring restaur\n",
      "\n",
      "2. SEMBAWANG\n",
      "   Score: 36.5308\n",
      "   Type: District\n",
      "   Contains: 17 venues\n",
      "   Description: SEMBAWANG Sun Plaza shopping_mall #family, #lifestyle, #shopping  Sembawang Shopping Centre shopping\n",
      "\n",
      "3. MANDAI\n",
      "   Score: 36.2385\n",
      "   Type: District\n",
      "   Contains: 1 venues\n",
      "   Description: MANDAI Sembawang Road Seoul Chicken restaurant #dining, #family, #pet-friendly, #social A&A Banana L\n",
      "\n",
      "4. SUNGEI KADUT\n",
      "   Score: 36.2195\n",
      "   Type: District\n",
      "   Contains: 3 venues\n",
      "   Description: SUNGEI KADUT Gain City Megastore electronics_store #retail, #shopping  Mandai Road Shell Select conv\n",
      "\n",
      "5. SELETAR\n",
      "   Score: 35.9650\n",
      "   Type: District\n",
      "   Contains: 4 venues\n",
      "   Description: SELETAR Park Lane Wheelers Market cafe #bonding, #chill, #dining, #work-friendly Wheelers Estate res\n",
      "\n",
      "LEVEL 3: REGIONS (Large Areas)\n",
      "(Broader regions for day trips)\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "1. NORTH-EAST\n",
      "   Score: 39.2197\n",
      "   Type: Region\n",
      "   Contains: 6 districts\n",
      "   Description: NORTH-EAST ANG MO KIO Broadway Plaza shopping_mall #family, #lifestyle, #shopping Haig Road Putu Pir\n",
      "Level 0 recommendations exported to: recommendations_Aiden_level0_Aiden.csv\n",
      "Level 1 recommendations exported to: recommendations_Aiden_level1_Aiden.csv\n",
      "Level 2 recommendations exported to: recommendations_Aiden_level2_Aiden.csv\n",
      "Level 3 recommendations exported to: recommendations_Aiden_level3_Aiden.csv\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 2: ADAPTIVE GRANULARITY (Context-Aware)\n",
      "======================================================================\n",
      "\n",
      "--- Context: SPECIFIC ---\n",
      "1. [Individual] CHICHA San Chen (score: 63.006)\n",
      "2. [Individual] State Of Mind (score: 57.055)\n",
      "3. [Individual] Unicorn Kampung 1200 (score: 53.607)\n",
      "4. [Venue] Upper Dickson Road (score: 49.631)\n",
      "5. [District] ANG MO KIO (score: 45.119)\n",
      "6. [Individual] Pepper Lunch (score: 33.624)\n",
      "7. [Individual] Tim Ho Wan (score: 33.417)\n",
      "8. [Individual] An Aai Affair (score: 32.487)\n",
      "9. [Individual] Fong Sheng Hao  (score: 32.409)\n",
      "10. [Individual] Paradise Hotpot  (score: 32.140)\n",
      "\n",
      "--- Context: VENUE ---\n",
      "1. [Individual] CHICHA San Chen (score: 63.006)\n",
      "2. [Individual] State Of Mind (score: 57.055)\n",
      "3. [Individual] Unicorn Kampung 1200 (score: 53.607)\n",
      "4. [Venue] Upper Dickson Road (score: 49.631)\n",
      "5. [Venue] Yio Chu Kang (score: 49.480)\n",
      "6. [Venue] Wishart Road (score: 49.341)\n",
      "7. [Venue] Medical Drive (score: 48.635)\n",
      "8. [Venue] Serangoon Road (score: 48.550)\n",
      "9. [District] ANG MO KIO (score: 45.119)\n",
      "10. [Region] NORTH-EAST (score: 39.220)\n",
      "\n",
      "--- Context: EXPLORATION ---\n",
      "1. [Individual] CHICHA San Chen (score: 63.006)\n",
      "2. [Individual] State Of Mind (score: 57.055)\n",
      "3. [Venue] Upper Dickson Road (score: 49.631)\n",
      "4. [Venue] Yio Chu Kang (score: 49.480)\n",
      "5. [Venue] Wishart Road (score: 49.341)\n",
      "6. [District] ANG MO KIO (score: 45.119)\n",
      "7. [Region] NORTH-EAST (score: 39.220)\n",
      "8. [District] SEMBAWANG (score: 36.531)\n",
      "9. [District] MANDAI (score: 36.238)\n",
      "\n",
      "--- Context: GENERAL ---\n",
      "1. [Individual] CHICHA San Chen (score: 63.006)\n",
      "2. [Individual] State Of Mind (score: 57.055)\n",
      "3. [Individual] Unicorn Kampung 1200 (score: 53.607)\n",
      "4. [Venue] Upper Dickson Road (score: 49.631)\n",
      "5. [Venue] Yio Chu Kang (score: 49.480)\n",
      "6. [Venue] Wishart Road (score: 49.341)\n",
      "7. [District] ANG MO KIO (score: 45.119)\n",
      "8. [Region] NORTH-EAST (score: 39.220)\n",
      "9. [Individual] Pepper Lunch (score: 33.624)\n",
      "10. [Individual] Tim Ho Wan (score: 33.417)\n",
      "\n",
      "======================================================================\n",
      "EXAMPLE 3: LEVEL-BY-LEVEL COMPARISON\n",
      "======================================================================\n",
      "\n",
      "--- Individual POIs (Level 0) ---\n",
      "1. CHICHA San Chen                                              (63.0056)\n",
      "2. State Of Mind                                                (57.0549)\n",
      "3. Unicorn Kampung 1200                                         (53.6066)\n",
      "4. Pepper Lunch                                                 (33.6241)\n",
      "5. Tim Ho Wan                                                   (33.4169)\n",
      "\n",
      "--- Containers/Venues (Level 1) ---\n",
      "1. Upper Dickson Road                                           (49.6312)\n",
      "2. Yio Chu Kang                                                 (49.4802)\n",
      "3. Wishart Road                                                 (49.3410)\n",
      "4. Medical Drive                                                (48.6349)\n",
      "5. Serangoon Road                                               (48.5504)\n",
      "\n",
      "--- Districts (Level 2) ---\n",
      "1. ANG MO KIO                                                   (45.1192)\n",
      "2. SEMBAWANG                                                    (36.5308)\n",
      "3. MANDAI                                                       (36.2385)\n",
      "4. SUNGEI KADUT                                                 (36.2195)\n",
      "5. SELETAR                                                      (35.9650)\n",
      "\n",
      "--- Regions (Level 3) ---\n",
      "1. NORTH-EAST                                                   (39.2197)\n",
      "\n",
      "======================================================================\n",
      "ALL EXAMPLES COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "MULTI-GRANULARITY RECOMMENDATIONS FOR USER: 966592ed-5bfd-4113-9c4d-d93cd3637b40\n",
      "======================================================================\n",
      "\n",
      "Generating Level 0 (INDIVIDUAL POIs) recommendations...\n",
      "Generating Level 1 (CONTAINERS/VENUES) recommendations...\n",
      "Generating Level 2 (DISTRICTS) recommendations...\n",
      "Generating Level 3 (REGIONS) recommendations...\n",
      "\n",
      "======================================================================\n",
      "EXPLANATIONS FOR ALL RECOMMENDATIONS - User: Aiden\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LEVEL 0: INDIVIDUAL POIs\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. CHICHA San Chen (Score: 63.01)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **CHICHA San Chen** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ‘ **Good match** - Worth checking out\n",
      "\n",
      "   ðŸ“Œ Key factors: distance, interest_match, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. State Of Mind (Score: 57.05)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **State Of Mind** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ‘ **Good match** - Worth checking out\n",
      "\n",
      "   ðŸ“Œ Key factors: distance, interest_match, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. Unicorn Kampung 1200 (Score: 53.61)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Unicorn Kampung 1200** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: interest_match, distance, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. Pepper Lunch (Score: 33.62)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Pepper Lunch** for you because:\n",
      "  âœ“ It's very close to your home area\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a restaurant\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: interest_match, feature_based, graph_based\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. Tim Ho Wan (Score: 33.42)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Tim Ho Wan** for you because:\n",
      "  âœ“ It's very close to your home area\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a restaurant\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: interest_match, feature_based, hierarchical\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 1: CONTAINERS/VENUES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. Upper Dickson Road (Score: 49.63)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Upper Dickson Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, total_score, interest_match\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. Yio Chu Kang (Score: 49.48)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Yio Chu Kang** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 99+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. Wishart Road (Score: 49.34)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Wishart Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, total_score, graph_based\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. Medical Drive (Score: 48.63)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Medical Drive** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, total_score, graph_based\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. Serangoon Road (Score: 48.55)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Serangoon Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 37+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, total_score, interest_match\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 2: DISTRICTS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. ANG MO KIO (Score: 45.12)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **ANG MO KIO** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 23+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. SEMBAWANG (Score: 36.53)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SEMBAWANG** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 17+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. MANDAI (Score: 36.24)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **MANDAI** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. SUNGEI KADUT (Score: 36.22)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SUNGEI KADUT** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. SELETAR (Score: 35.96)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SELETAR** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 3: REGIONS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. NORTH-EAST (Score: 39.22)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **NORTH-EAST** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "   ðŸ“Œ Key factors: feature_based, hierarchical, total_score\n",
      "\n",
      "======================================================================\n",
      "ALL EXPLANATIONS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "EXPLANATIONS FOR ALL RECOMMENDATIONS - User: Aiden\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "LEVEL 0: INDIVIDUAL POIs\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. CHICHA San Chen (Score: 63.01)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **CHICHA San Chen** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ‘ **Good match** - Worth checking out\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 56.55/100\n",
      "   Top Contributing Factors: distance, interest_match, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 45.97 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: -1.91 (weight: 10%)\n",
      "      â€¢ distance: 7.48 (weight: 35%)\n",
      "      â€¢ interest_match: 5.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Popular\n",
      "      âœ“ Matches Budget\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. State Of Mind (Score: 57.05)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **State Of Mind** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ‘ **Good match** - Worth checking out\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 51.30/100\n",
      "   Top Contributing Factors: distance, interest_match, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 41.14 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: -0.49 (weight: 10%)\n",
      "      â€¢ distance: 5.66 (weight: 35%)\n",
      "      â€¢ interest_match: 5.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Popular\n",
      "      âœ“ Highly Popular\n",
      "      âœ“ Matches Budget\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. Unicorn Kampung 1200 (Score: 53.61)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Unicorn Kampung 1200** for you because:\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a cafe\n",
      "  âœ“ Prices fit your budget (low spending)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. Pepper Lunch (Score: 33.62)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Pepper Lunch** for you because:\n",
      "  âœ“ It's very close to your home area\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a restaurant\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. Tim Ho Wan (Score: 33.42)\n",
      "----------------------------------------------------------------------\n",
      "We recommend **Tim Ho Wan** for you because:\n",
      "  âœ“ It's very close to your home area\n",
      "  âœ“ It matches your interests (food; shopping; movies) - it's a restaurant\n",
      "  âœ“ It's highly rated by other users (â­ 4.5+)\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 1: CONTAINERS/VENUES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. Upper Dickson Road (Score: 49.63)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Upper Dickson Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 47.12/100\n",
      "   Top Contributing Factors: feature_based, total_score, interest_match\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 12.54 (weight: 25%)\n",
      "      â€¢ graph_based: -0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: -0.41 (weight: 10%)\n",
      "      â€¢ distance: 35.00 (weight: 35%)\n",
      "      â€¢ interest_match: 0.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Nearby\n",
      "      âœ“ Popular\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. Yio Chu Kang (Score: 49.48)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Yio Chu Kang** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 99+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 47.60/100\n",
      "   Top Contributing Factors: feature_based, hierarchical, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 9.41 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: 3.19 (weight: 10%)\n",
      "      â€¢ distance: 35.00 (weight: 35%)\n",
      "      â€¢ interest_match: 0.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Nearby\n",
      "      âœ“ Popular\n",
      "      âœ“ Has Many Options\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. Wishart Road (Score: 49.34)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Wishart Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. Medical Drive (Score: 48.63)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Medical Drive** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. Serangoon Road (Score: 48.55)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **Serangoon Road** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 37+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 2: DISTRICTS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. ANG MO KIO (Score: 45.12)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **ANG MO KIO** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 23+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 43.52/100\n",
      "   Top Contributing Factors: feature_based, hierarchical, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 7.98 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: 0.54 (weight: 10%)\n",
      "      â€¢ distance: 35.00 (weight: 35%)\n",
      "      â€¢ interest_match: 0.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Nearby\n",
      "      âœ“ Popular\n",
      "      âœ“ Has Many Options\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#2. SEMBAWANG (Score: 36.53)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SEMBAWANG** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "  âœ“ It offers 17+ places to explore\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 36.34/100\n",
      "   Top Contributing Factors: feature_based, hierarchical, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 0.96 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: 0.38 (weight: 10%)\n",
      "      â€¢ distance: 35.00 (weight: 35%)\n",
      "      â€¢ interest_match: 0.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Nearby\n",
      "      âœ“ Popular\n",
      "      âœ“ Has Many Options\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#3. MANDAI (Score: 36.24)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **MANDAI** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#4. SUNGEI KADUT (Score: 36.22)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SUNGEI KADUT** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#5. SELETAR (Score: 35.96)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **SELETAR** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "\n",
      "======================================================================\n",
      "LEVEL 3: REGIONS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "#1. NORTH-EAST (Score: 39.22)\n",
      "----------------------------------------------------------------------\n",
      "We suggest exploring **NORTH-EAST** because:\n",
      "  âœ“ It's within a comfortable distance from you\n",
      "  âœ“ It has options matching your interests (food; shopping; movies)\n",
      "  âœ“ It's popular among other users\n",
      "\n",
      "ðŸ’¡ **Potential match** - Might be interesting\n",
      "\n",
      "ðŸ“Š DETAILED SCORE BREAKDOWN:\n",
      "   Total Score: 38.63/100\n",
      "   Top Contributing Factors: feature_based, hierarchical, total_score\n",
      "\n",
      "   Components:\n",
      "      â€¢ feature_based: 2.96 (weight: 25%)\n",
      "      â€¢ graph_based: 0.00 (weight: 15%)\n",
      "      â€¢ hierarchical: 0.67 (weight: 10%)\n",
      "      â€¢ distance: 35.00 (weight: 35%)\n",
      "      â€¢ interest_match: 0.00 (weight: 15%)\n",
      "\n",
      "   Active Flags:\n",
      "      âœ“ Matches Interest\n",
      "      âœ“ Nearby\n",
      "      âœ“ Popular\n",
      "\n",
      "======================================================================\n",
      "ALL EXPLANATIONS COMPLETE!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize framework\n",
    "    framework = MultiGranularityRecommendationFramework(\n",
    "        embeddings_file='embeddings.pkl',\n",
    "        interaction_learning_file='interaction_learning.pkl',\n",
    "        poi_tree_file='poi_tree_with_uuids.json',\n",
    "        users_file='user_preferences.csv',\n",
    "        interactions_file='user_poi_interactions.csv'\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 1: Multi-Granularity Recommendations (ALL LEVELS)\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 1: MULTI-GRANULARITY RECOMMENDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    user_id = framework.users_df.iloc[0]['uudi']\n",
    "    user_name = framework.users_df.iloc[0]['name']\n",
    "    \n",
    "    # Generate recommendations at all levels\n",
    "    multi_gran_recs = framework.recommend_multi_granularity(\n",
    "        user_id=user_id,\n",
    "        levels=[0, 1, 2, 3],\n",
    "        top_k_per_level=5,\n",
    "        filter_visited=True\n",
    "    )\n",
    "    \n",
    "    # Display\n",
    "    framework.display_multi_granularity_recommendations(multi_gran_recs)\n",
    "    \n",
    "    # Export\n",
    "    framework.export_multi_granularity_recommendations(\n",
    "        multi_gran_recs, \n",
    "        user_id, \n",
    "        output_prefix=f'recommendations_{user_name}'\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 2: Context-Aware Adaptive Granularity\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 2: ADAPTIVE GRANULARITY (Context-Aware)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    contexts = ['specific', 'venue', 'exploration', 'general']\n",
    "    \n",
    "    for context in contexts:\n",
    "        print(f\"\\n--- Context: {context.upper()} ---\")\n",
    "        \n",
    "        adaptive_recs = framework.recommend_adaptive_granularity(\n",
    "            user_id=user_id,\n",
    "            context=context,\n",
    "            top_k=10\n",
    "        )\n",
    "        \n",
    "        level_names = {0: 'Individual', 1: 'Venue', 2: 'District', 3: 'Region'}\n",
    "        \n",
    "        for rank, (poi_id, score, poi_info, level) in enumerate(adaptive_recs, 1):\n",
    "            print(f\"{rank}. [{level_names[level]}] {poi_info['name'][:50]} (score: {score:.3f})\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EXAMPLE 3: Compare Recommendations Across Levels\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXAMPLE 3: LEVEL-BY-LEVEL COMPARISON\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for level in [0, 1, 2, 3]:\n",
    "        level_names = {\n",
    "            0: \"Individual POIs\",\n",
    "            1: \"Containers/Venues\",\n",
    "            2: \"Districts\",\n",
    "            3: \"Regions\"\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n--- {level_names[level]} (Level {level}) ---\")\n",
    "        \n",
    "        recs = framework.recommend_at_level(\n",
    "            user_id=user_id,\n",
    "            level=level,\n",
    "            top_k=5,\n",
    "            filter_visited=True\n",
    "        )\n",
    "        \n",
    "        for rank, (poi_id, score, poi_info) in enumerate(recs, 1):\n",
    "            print(f\"{rank}. {poi_info['name'][:60]:60s} ({score:.4f})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ALL EXAMPLES COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # ========================================================================\n",
    "    # EXAMPLE 4: Explain All Recommendations at All Levels\n",
    "    # ========================================================================\n",
    "    # Generate recommendations\n",
    "    multi_gran_recs = framework.recommend_multi_granularity(\n",
    "        user_id=user_id,\n",
    "        levels=[0, 1, 2, 3],\n",
    "        top_k_per_level=5,\n",
    "        filter_visited=True\n",
    "    )\n",
    "\n",
    "    # Explain all recommendations (brief)\n",
    "    framework.explain_all_recommendations(multi_gran_recs, user_id, detailed=False)\n",
    "\n",
    "    # Or with detailed breakdown for top 2 per level\n",
    "    framework.explain_all_recommendations(multi_gran_recs, user_id, detailed=True, top_n_detailed=2)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7673c3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
