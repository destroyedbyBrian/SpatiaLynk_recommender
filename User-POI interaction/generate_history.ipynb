{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a64a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from typing import Dict, List, Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab569128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserPOIInteractionGenerator:\n",
    "    def __init__(self, poi_tree_file: str, users_file: str):\n",
    "        \"\"\"\n",
    "        Initialize interaction generator\n",
    "        \n",
    "        Args:\n",
    "            poi_tree_file: Path to POI tree JSON file\n",
    "            users_file: Path to user preferences CSV\n",
    "        \"\"\"\n",
    "        # Load POI tree\n",
    "        with open(poi_tree_file, 'r', encoding='utf-8') as f:\n",
    "            self.poi_tree = json.load(f)\n",
    "        \n",
    "        # Load users\n",
    "        self.users_df = pd.read_csv(users_file)\n",
    "        \n",
    "        # Get geocoded locations for user residences\n",
    "        self.residence_locations = self._get_residence_coordinates()\n",
    "        \n",
    "        # Interest to POI characteristic mapping\n",
    "        self.interest_mapping = {\n",
    "            'food': ['dining', 'restaurant', 'food', 'hawker', 'cafe', 'eatery', 'cuisine'],\n",
    "            'shopping': ['shopping', 'retail', 'fashion', 'mall', 'store', 'boutique'],\n",
    "            'movies': ['cinema', 'movie', 'film', 'theatre', 'entertainment'],\n",
    "            'cafes': ['cafe', 'coffee', 'tea', 'bakery', 'dessert'],\n",
    "            'cycling': ['cycling', 'bike', 'sports', 'outdoor', 'park'],\n",
    "            'photography': ['scenic', 'park', 'nature', 'attraction', 'view'],\n",
    "            'museums': ['museum', 'gallery', 'art', 'culture', 'heritage', 'exhibition'],\n",
    "            'books': ['book', 'library', 'store', 'reading'],\n",
    "            'nightlife': ['bar', 'pub', 'club', 'nightlife', 'lounge'],\n",
    "            'bars': ['bar', 'pub', 'lounge', 'drinks', 'alcohol'],\n",
    "            'concerts': ['music', 'entertainment', 'venue', 'performance'],\n",
    "            'family activities': ['family', 'kid', 'playground', 'park', 'entertainment'],\n",
    "            'playgrounds': ['playground', 'park', 'family', 'children'],\n",
    "            'malls': ['mall', 'shopping', 'retail'],\n",
    "            'sports': ['sports', 'gym', 'fitness', 'athletic'],\n",
    "            'gyms': ['gym', 'fitness', 'sports', 'workout'],\n",
    "            'healthy eating': ['healthy', 'salad', 'organic', 'wellness', 'fresh'],\n",
    "            'gaming': ['gaming', 'arcade', 'entertainment', 'game'],\n",
    "            'arcades': ['arcade', 'game', 'entertainment'],\n",
    "            'budget food': ['hawker', 'food court', 'budget', 'cheap', 'affordable'],\n",
    "            'tech stores': ['tech', 'electronics', 'gadget', 'computer', 'mobile'],\n",
    "            'coworking': ['coworking', 'cafe', 'workspace', 'work'],\n",
    "            'local food': ['hawker', 'local', 'traditional', 'food court'],\n",
    "            'parks': ['park', 'nature', 'outdoor', 'garden'],\n",
    "            'community events': ['community', 'event', 'recreation', 'centre']\n",
    "        }\n",
    "        \n",
    "        # Transportation mode to max distance mapping (km)\n",
    "        self.transport_distance = {\n",
    "            'MRT': 15.0,\n",
    "            'bus': 10.0,\n",
    "            'car': 25.0,\n",
    "            'walking': 2.0,\n",
    "            'bicycle': 5.0,\n",
    "            'ride-hailing': 20.0\n",
    "        }\n",
    "        \n",
    "        # Price sensitivity to price range mapping\n",
    "        self.price_ranges = {\n",
    "            'low': (0, 20),\n",
    "            'medium': (10, 40),\n",
    "            'high': (20, 100)\n",
    "        }\n",
    "        \n",
    "    def _get_residence_coordinates(self) -> Dict[str, Tuple[float, float]]:\n",
    "        \"\"\"\n",
    "        Get approximate coordinates for common Singapore residential areas\n",
    "        \"\"\"\n",
    "        # Approximate coordinates for major residential areas\n",
    "        locations = {\n",
    "            'Jurong East': (1.3329, 103.7436),\n",
    "            'Yishun': (1.4304, 103.8354),\n",
    "            'Bishan': (1.3526, 103.8352),\n",
    "            'Bukit Timah': (1.3294, 103.8008),\n",
    "            'Ang Mo Kio': (1.3691, 103.8454),\n",
    "            'Clementi': (1.3152, 103.7649),\n",
    "            'Bedok': (1.3236, 103.9273),\n",
    "            'Toa Payoh': (1.3343, 103.8563),\n",
    "            'Sengkang': (1.3868, 103.8914),\n",
    "            'Punggol': (1.4043, 103.9021),\n",
    "            'Serangoon': (1.3554, 103.8679),\n",
    "            'Tampines': (1.3496, 103.9568),\n",
    "            'Woodlands': (1.4382, 103.7891),\n",
    "            'Hougang': (1.3612, 103.8863),\n",
    "            'Pasir Ris': (1.3721, 103.9474)\n",
    "        }\n",
    "        return locations\n",
    "    \n",
    "    def _haversine_distance(self, lat1: float, lon1: float, \n",
    "                           lat2: float, lon2: float) -> float:\n",
    "        \"\"\"Calculate distance between coordinates in km\"\"\"\n",
    "        R = 6371\n",
    "        lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])\n",
    "        dlat = lat2 - lat1\n",
    "        dlon = lon2 - lon1\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon/2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "        return R * c\n",
    "    \n",
    "    def _get_max_travel_distance(self, transport_modes: str) -> float:\n",
    "        \"\"\"Get maximum travel distance based on transportation modes\"\"\"\n",
    "        modes = [m.strip() for m in transport_modes.split(';')]\n",
    "        # Return max distance among all modes\n",
    "        distances = [self.transport_distance.get(mode, 10.0) for mode in modes]\n",
    "        return max(distances)\n",
    "    \n",
    "    def _match_interest_score(self, user_interests: str, poi_text: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate how well a POI matches user interests\n",
    "        Returns score from 0 to 1\n",
    "        \"\"\"\n",
    "        interests = [i.strip().lower() for i in user_interests.split(';')]\n",
    "        poi_text_lower = poi_text.lower()\n",
    "        \n",
    "        total_matches = 0\n",
    "        total_keywords = 0\n",
    "        \n",
    "        for interest in interests:\n",
    "            if interest in self.interest_mapping:\n",
    "                keywords = self.interest_mapping[interest]\n",
    "                total_keywords += len(keywords)\n",
    "                matches = sum(1 for keyword in keywords if keyword in poi_text_lower)\n",
    "                total_matches += matches\n",
    "        \n",
    "        if total_keywords == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return min(total_matches / (total_keywords * 0.3), 1.0)  # Normalize\n",
    "    \n",
    "    def _match_price_sensitivity(self, user_price_sens: str, poi_price: str) -> bool:\n",
    "        \"\"\"Check if POI price matches user's price sensitivity\"\"\"\n",
    "        if pd.isna(poi_price) or poi_price == '':\n",
    "            return True  # Assume affordable if no price info\n",
    "        \n",
    "        try:\n",
    "            # Parse price range (e.g., \"25.85 - 30.99\")\n",
    "            if '-' in str(poi_price):\n",
    "                prices = str(poi_price).split('-')\n",
    "                avg_price = (float(prices[0].strip()) + float(prices[1].strip())) / 2\n",
    "            else:\n",
    "                avg_price = float(poi_price)\n",
    "            \n",
    "            price_range = self.price_ranges.get(user_price_sens.lower(), (0, 100))\n",
    "            return price_range[0] <= avg_price <= price_range[1]\n",
    "        except:\n",
    "            return True\n",
    "    \n",
    "    def _get_candidate_pois(self, user: pd.Series) -> List[Tuple[str, Dict, float]]:\n",
    "        \"\"\"\n",
    "        Get candidate POIs for a user based on their preferences\n",
    "        \n",
    "        Returns:\n",
    "            List of (poi_id, poi_data, score) tuples\n",
    "        \"\"\"\n",
    "        user_location = self.residence_locations.get(user['area_of_residence'])\n",
    "        if not user_location:\n",
    "            print(f\"Warning: Location not found for {user['area_of_residence']}\")\n",
    "            return []\n",
    "        \n",
    "        max_distance = self._get_max_travel_distance(user['transportation_modes'])\n",
    "        user_interests = user['interests']\n",
    "        user_price_sens = user['price_sensitivity']\n",
    "        \n",
    "        candidates = []\n",
    "        \n",
    "        # Iterate through Level 0 POIs (individual POIs)\n",
    "        for poi_id, poi_data in self.poi_tree['level_0'].items():\n",
    "            # Get POI coordinates\n",
    "            poi_spatial = poi_data['spatial']\n",
    "            if isinstance(poi_spatial, str):\n",
    "                poi_spatial = eval(poi_spatial)  # Convert string tuple to tuple\n",
    "            \n",
    "            poi_lat, poi_lon = poi_spatial\n",
    "            \n",
    "            # Calculate distance\n",
    "            distance = self._haversine_distance(\n",
    "                user_location[0], user_location[1],\n",
    "                poi_lat, poi_lon\n",
    "            )\n",
    "            \n",
    "            # Filter by distance\n",
    "            if distance > max_distance:\n",
    "                continue\n",
    "            \n",
    "            # Calculate interest match score\n",
    "            poi_text = poi_data.get('textual', '')\n",
    "            interest_score = self._match_interest_score(user_interests, poi_text)\n",
    "            \n",
    "            if interest_score < 0.1:  # Skip if very low interest match\n",
    "                continue\n",
    "            \n",
    "            # Check price sensitivity\n",
    "            poi_price = poi_data['data'].get('price', '')\n",
    "            if not self._match_price_sensitivity(user_price_sens, poi_price):\n",
    "                continue\n",
    "            \n",
    "            # Get popularity\n",
    "            try:\n",
    "                popularity = float(poi_data['data'].get('popularity', 3))\n",
    "            except:\n",
    "                popularity = 3.0\n",
    "            \n",
    "            # Calculate overall score\n",
    "            # Formula: interest_match * 3 + popularity * 0.5 - distance * 0.2\n",
    "            score = (interest_score * 3.0) + (popularity * 0.5) - (distance * 0.2)\n",
    "            \n",
    "            candidates.append((poi_id, poi_data, score, distance, interest_score))\n",
    "        \n",
    "        # Sort by score\n",
    "        candidates.sort(key=lambda x: x[2], reverse=True)\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def generate_interactions(self, \n",
    "                            min_interactions_per_user: int = 5,\n",
    "                            max_interactions_per_user: int = 20,\n",
    "                            days_back: int = 90) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate synthetic user-POI interactions\n",
    "        \n",
    "        Args:\n",
    "            min_interactions_per_user: Minimum number of interactions per user\n",
    "            max_interactions_per_user: Maximum number of interactions per user\n",
    "            days_back: Generate interactions for past N days\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with columns: interaction_id, user_id, poi_id, \n",
    "                                   interaction_type, value, timestamp\n",
    "        \"\"\"\n",
    "        interactions = []\n",
    "        interaction_counter = 0\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(\"Generating User-POI Interactions\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for idx, user in self.users_df.iterrows():\n",
    "            user_id = user['uudi']\n",
    "            user_name = user['name']\n",
    "            \n",
    "            print(f\"\\nProcessing user {idx+1}/{len(self.users_df)}: {user_name} ({user['area_of_residence']})\")\n",
    "            \n",
    "            # Get candidate POIs\n",
    "            candidates = self._get_candidate_pois(user)\n",
    "            \n",
    "            if not candidates:\n",
    "                print(f\"  No suitable POIs found for {user_name}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Found {len(candidates)} candidate POIs\")\n",
    "            \n",
    "            # Determine number of interactions\n",
    "            num_interactions = random.randint(\n",
    "                min_interactions_per_user,\n",
    "                min(max_interactions_per_user, len(candidates))\n",
    "            )\n",
    "            \n",
    "            # Select POIs using weighted random (higher score = higher probability)\n",
    "            selected_pois = []\n",
    "            candidate_pool = candidates.copy()\n",
    "            \n",
    "            for _ in range(num_interactions):\n",
    "                if not candidate_pool:\n",
    "                    break\n",
    "                \n",
    "                # Calculate weights (exponential to favor high scores)\n",
    "                scores = [c[2] for c in candidate_pool]\n",
    "                weights = [math.exp(score) for score in scores]\n",
    "                weight_sum = sum(weights)\n",
    "                weights = [w/weight_sum for w in weights]\n",
    "                \n",
    "                # Select POI\n",
    "                selected_idx = random.choices(range(len(candidate_pool)), weights=weights)[0]\n",
    "                selected = candidate_pool.pop(selected_idx)\n",
    "                selected_pois.append(selected)\n",
    "            \n",
    "            print(f\"  Generated {len(selected_pois)} interactions\")\n",
    "            \n",
    "            # Generate interactions for selected POIs\n",
    "            for poi_id, poi_data, score, distance, interest_score in selected_pois:\n",
    "                # Generate visit timestamp (random in past 90 days)\n",
    "                days_ago = random.randint(0, days_back)\n",
    "                hours = random.randint(8, 22)  # Between 8am and 10pm\n",
    "                minutes = random.randint(0, 59)\n",
    "                \n",
    "                visit_time = datetime.now() - timedelta(days=days_ago, hours=hours, minutes=minutes)\n",
    "                \n",
    "                # Visit interaction\n",
    "                interactions.append({\n",
    "                    'interaction_id': f'int_{interaction_counter:06d}',\n",
    "                    'user_id': user_id,\n",
    "                    'user_name': user_name,\n",
    "                    'poi_id': poi_id,\n",
    "                    'poi_name': poi_data['name'],\n",
    "                    'interaction_type': 'visit',\n",
    "                    'value': 1,\n",
    "                    'timestamp': visit_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'distance_km': round(distance, 2),\n",
    "                    'interest_match_score': round(interest_score, 2)\n",
    "                })\n",
    "                interaction_counter += 1\n",
    "                \n",
    "                # Generate rating (80% chance)\n",
    "                if random.random() < 0.8:\n",
    "                    # Rating influenced by interest match and distance\n",
    "                    # Higher interest match and closer = better rating\n",
    "                    base_rating = 3.0\n",
    "                    interest_bonus = interest_score * 2.0  # 0 to 2\n",
    "                    distance_penalty = min(distance / 10.0, 1.0)  # 0 to 1\n",
    "                    \n",
    "                    rating = base_rating + interest_bonus - distance_penalty\n",
    "                    rating = max(1, min(5, int(round(rating))))\n",
    "                    \n",
    "                    # Add some randomness\n",
    "                    if random.random() < 0.2:\n",
    "                        rating = max(1, rating - 1) if random.random() < 0.5 else min(5, rating + 1)\n",
    "                    \n",
    "                    # Rating timestamp (shortly after visit)\n",
    "                    rating_time = visit_time + timedelta(minutes=random.randint(5, 120))\n",
    "                    \n",
    "                    interactions.append({\n",
    "                        'interaction_id': f'int_{interaction_counter:06d}',\n",
    "                        'user_id': user_id,\n",
    "                        'user_name': user_name,\n",
    "                        'poi_id': poi_id,\n",
    "                        'poi_name': poi_data['name'],\n",
    "                        'interaction_type': 'rating',\n",
    "                        'value': rating,\n",
    "                        'timestamp': rating_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'distance_km': round(distance, 2),\n",
    "                        'interest_match_score': round(interest_score, 2)\n",
    "                    })\n",
    "                    interaction_counter += 1\n",
    "                \n",
    "                # Generate click/search (30% chance, happens before visit)\n",
    "                if random.random() < 0.3:\n",
    "                    click_time = visit_time - timedelta(hours=random.randint(1, 48))\n",
    "                    \n",
    "                    interactions.append({\n",
    "                        'interaction_id': f'int_{interaction_counter:06d}',\n",
    "                        'user_id': user_id,\n",
    "                        'user_name': user_name,\n",
    "                        'poi_id': poi_id,\n",
    "                        'poi_name': poi_data['name'],\n",
    "                        'interaction_type': 'search',\n",
    "                        'value': 1,\n",
    "                        'timestamp': click_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        'distance_km': round(distance, 2),\n",
    "                        'interest_match_score': round(interest_score, 2)\n",
    "                    })\n",
    "                    interaction_counter += 1\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(f\"Generated {len(interactions)} total interactions\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Convert to DataFrame and sort by timestamp\n",
    "        interactions_df = pd.DataFrame(interactions)\n",
    "        interactions_df = interactions_df.sort_values('timestamp')\n",
    "        \n",
    "        return interactions_df\n",
    "    \n",
    "    def generate_summary_stats(self, interactions_df: pd.DataFrame):\n",
    "        \"\"\"Print summary statistics of generated interactions\"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"INTERACTION SUMMARY STATISTICS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        print(f\"\\nTotal interactions: {len(interactions_df)}\")\n",
    "        print(f\"Total users: {interactions_df['user_id'].nunique()}\")\n",
    "        print(f\"Total POIs: {interactions_df['poi_id'].nunique()}\")\n",
    "        \n",
    "        print(\"\\nInteractions per user:\")\n",
    "        user_counts = interactions_df.groupby('user_id').size()\n",
    "        print(f\"  Mean: {user_counts.mean():.1f}\")\n",
    "        print(f\"  Median: {user_counts.median():.1f}\")\n",
    "        print(f\"  Min: {user_counts.min()}\")\n",
    "        print(f\"  Max: {user_counts.max()}\")\n",
    "        \n",
    "        print(\"\\nInteraction types:\")\n",
    "        type_counts = interactions_df['interaction_type'].value_counts()\n",
    "        for itype, count in type_counts.items():\n",
    "            print(f\"  {itype}: {count} ({count/len(interactions_df)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nRating distribution:\")\n",
    "        ratings = interactions_df[interactions_df['interaction_type'] == 'rating']['value']\n",
    "        if len(ratings) > 0:\n",
    "            print(f\"  Mean rating: {ratings.mean():.2f}\")\n",
    "            print(f\"  Rating counts:\")\n",
    "            for rating in sorted(ratings.unique()):\n",
    "                count = (ratings == rating).sum()\n",
    "                print(f\"    {int(rating)} stars: {count} ({count/len(ratings)*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nDistance statistics:\")\n",
    "        print(f\"  Mean distance: {interactions_df['distance_km'].mean():.2f} km\")\n",
    "        print(f\"  Median distance: {interactions_df['distance_km'].median():.2f} km\")\n",
    "        print(f\"  Max distance: {interactions_df['distance_km'].max():.2f} km\")\n",
    "        \n",
    "        print(\"\\nInterest match statistics:\")\n",
    "        print(f\"  Mean match score: {interactions_df['interest_match_score'].mean():.2f}\")\n",
    "        print(f\"  Median match score: {interactions_df['interest_match_score'].median():.2f}\")\n",
    "        \n",
    "        print(\"\\nTop 10 most visited POIs:\")\n",
    "        top_pois = interactions_df[interactions_df['interaction_type'] == 'visit'].groupby('poi_name').size().sort_values(ascending=False).head(10)\n",
    "        for poi, count in top_pois.items():\n",
    "            print(f\"  {poi}: {count} visits\")\n",
    "        \n",
    "        print(\"\\nMost active users:\")\n",
    "        top_users = interactions_df.groupby('user_name').size().sort_values(ascending=False).head(5)\n",
    "        for user, count in top_users.items():\n",
    "            print(f\"  {user}: {count} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f011a955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generating User-POI Interactions\n",
      "============================================================\n",
      "\n",
      "Processing user 1/21: Aiden (Jurong East)\n",
      "  Found 463 candidate POIs\n",
      "  Generated 8 interactions\n",
      "\n",
      "Processing user 2/21: Chloe (Yishun)\n",
      "  Found 126 candidate POIs\n",
      "  Generated 5 interactions\n",
      "\n",
      "Processing user 3/21: Lucas (Jurong East)\n",
      "  Found 115 candidate POIs\n",
      "  Generated 5 interactions\n",
      "\n",
      "Processing user 4/21: Ethan (Yishun)\n",
      "  Found 424 candidate POIs\n",
      "  Generated 19 interactions\n",
      "\n",
      "Processing user 5/21: Maya (Bishan)\n",
      "  Found 579 candidate POIs\n",
      "  Generated 18 interactions\n",
      "\n",
      "Processing user 6/21: Sophia (Bukit Timah)\n",
      "  Found 577 candidate POIs\n",
      "  Generated 14 interactions\n",
      "\n",
      "Processing user 7/21: Maya (Ang Mo Kio)\n",
      "  Found 55 candidate POIs\n",
      "  Generated 19 interactions\n",
      "\n",
      "Processing user 8/21: Kai (Clementi)\n",
      "  Found 497 candidate POIs\n",
      "  Generated 5 interactions\n",
      "\n",
      "Processing user 9/21: Isla (Bukit Timah)\n",
      "  Found 93 candidate POIs\n",
      "  Generated 17 interactions\n",
      "\n",
      "Processing user 10/21: Noah (Bedok)\n",
      "  Found 166 candidate POIs\n",
      "  Generated 12 interactions\n",
      "\n",
      "Processing user 11/21: Zara (Jurong East)\n",
      "  Found 33 candidate POIs\n",
      "  Generated 11 interactions\n",
      "\n",
      "Processing user 12/21: Liam (Toa Payoh)\n",
      "  Found 1789 candidate POIs\n",
      "  Generated 8 interactions\n",
      "\n",
      "Processing user 13/21: Kai (Jurong East)\n",
      "  Found 928 candidate POIs\n",
      "  Generated 18 interactions\n",
      "\n",
      "Processing user 14/21: Brian (Sengkang)\n",
      "  Found 1074 candidate POIs\n",
      "  Generated 11 interactions\n",
      "\n",
      "Processing user 15/21: Sam (Yishun)\n",
      "  Found 406 candidate POIs\n",
      "  Generated 5 interactions\n",
      "\n",
      "Processing user 16/21: David (Punggol)\n",
      "  Found 635 candidate POIs\n",
      "  Generated 13 interactions\n",
      "\n",
      "Processing user 17/21: Noah (Jurong East)\n",
      "  Found 717 candidate POIs\n",
      "  Generated 18 interactions\n",
      "\n",
      "Processing user 18/21: Freya (Yishun)\n",
      "  Found 435 candidate POIs\n",
      "  Generated 14 interactions\n",
      "\n",
      "Processing user 19/21: Elise (Clementi)\n",
      "  Found 588 candidate POIs\n",
      "  Generated 11 interactions\n",
      "\n",
      "Processing user 20/21: Jayden (Sengkang)\n",
      "  Found 287 candidate POIs\n",
      "  Generated 8 interactions\n",
      "\n",
      "Processing user 21/21: Bobby (Serangoon)\n",
      "  Found 587 candidate POIs\n",
      "  Generated 10 interactions\n",
      "\n",
      "============================================================\n",
      "Generated 529 total interactions\n",
      "============================================================\n",
      "\n",
      "Saved full interactions to: user_poi_interactions_full.csv\n",
      "Saved minimal interactions to: user_poi_interactions.csv\n",
      "\n",
      "============================================================\n",
      "INTERACTION SUMMARY STATISTICS\n",
      "============================================================\n",
      "\n",
      "Total interactions: 529\n",
      "Total users: 21\n",
      "Total POIs: 224\n",
      "\n",
      "Interactions per user:\n",
      "  Mean: 25.2\n",
      "  Median: 25.0\n",
      "  Min: 9\n",
      "  Max: 43\n",
      "\n",
      "Interaction types:\n",
      "  visit: 249 (47.1%)\n",
      "  rating: 195 (36.9%)\n",
      "  search: 85 (16.1%)\n",
      "\n",
      "Rating distribution:\n",
      "  Mean rating: 3.07\n",
      "  Rating counts:\n",
      "    1 stars: 2 (1.0%)\n",
      "    2 stars: 27 (13.8%)\n",
      "    3 stars: 127 (65.1%)\n",
      "    4 stars: 34 (17.4%)\n",
      "    5 stars: 5 (2.6%)\n",
      "\n",
      "Distance statistics:\n",
      "  Mean distance: 7.16 km\n",
      "  Median distance: 6.94 km\n",
      "  Max distance: 14.65 km\n",
      "\n",
      "Interest match statistics:\n",
      "  Mean match score: 0.37\n",
      "  Median match score: 0.37\n",
      "\n",
      "Top 10 most visited POIs:\n",
      "  UOB: 8 visits\n",
      "  Starbucks: 7 visits\n",
      "  7-Eleven: 6 visits\n",
      "  Dominos: 5 visits\n",
      "  Malabar: 4 visits\n",
      "  CHICHA San Chen: 3 visits\n",
      "  Toast Box: 3 visits\n",
      "  McDonalds: 3 visits\n",
      "  Cheers: 3 visits\n",
      "  The Coffee Bean & Tea Leaf: 2 visits\n",
      "\n",
      "Most active users:\n",
      "  Maya: 85 interactions\n",
      "  Noah: 65 interactions\n",
      "  Kai: 45 interactions\n",
      "  Ethan: 40 interactions\n",
      "  Isla: 35 interactions\n",
      "\n",
      "============================================================\n",
      "SAMPLE INTERACTIONS (first 10)\n",
      "============================================================\n",
      "interaction_id                              user_id user_name                                  poi_id                       poi_name interaction_type  value           timestamp  distance_km  interest_match_score\n",
      "    int_000107 ed4d4ddf-8829-49c2-b540-b0c8aa36dfcf      Maya                     poi_467_ALFA_H_MART                    ALFA H MART           search      1 2025-09-08 13:20:38         8.60                  0.44\n",
      "    int_000083 ed4d4ddf-8829-49c2-b540-b0c8aa36dfcf      Maya                          poi_529_Cheers                         Cheers           search      1 2025-09-08 13:37:38         5.49                  0.22\n",
      "    int_000423 da4ea5cf-d90f-4105-9a6e-f9f38252d01c      Noah                      poi_1447_Clap_Cafe                      Clap Cafe            visit      1 2025-09-08 19:26:38        12.63                  0.51\n",
      "    int_000424 da4ea5cf-d90f-4105-9a6e-f9f38252d01c      Noah                      poi_1447_Clap_Cafe                      Clap Cafe           rating      3 2025-09-08 19:57:38        12.63                  0.51\n",
      "    int_000052 4fbee9f0-804a-4e5d-834e-553670746410     Ethan poi_4010_Parkway_Shenton_Medical_Clinic Parkway Shenton Medical Clinic            visit      1 2025-09-08 22:39:38        14.05                  0.44\n",
      "    int_000053 4fbee9f0-804a-4e5d-834e-553670746410     Ethan poi_4010_Parkway_Shenton_Medical_Clinic Parkway Shenton Medical Clinic           rating      3 2025-09-08 23:08:38        14.05                  0.44\n",
      "    int_000314 bc6799a8-00d1-4ab5-80bf-eeffc36ba029       Kai                          poi_331_Cheers                         Cheers            visit      1 2025-09-08 23:51:38         4.69                  0.26\n",
      "    int_000407 da4ea5cf-d90f-4105-9a6e-f9f38252d01c      Noah                     poi_933_Nana_&_Bird                    Nana & Bird            visit      1 2025-09-09 01:26:38        11.17                  0.26\n",
      "    int_000408 da4ea5cf-d90f-4105-9a6e-f9f38252d01c      Noah                     poi_933_Nana_&_Bird                    Nana & Bird           rating      3 2025-09-09 01:45:38        11.17                  0.26\n",
      "    int_000315 bc6799a8-00d1-4ab5-80bf-eeffc36ba029       Kai                          poi_331_Cheers                         Cheers           rating      3 2025-09-09 01:51:38         4.69                  0.26\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate interactions\n",
    "    generator = UserPOIInteractionGenerator(\n",
    "        poi_tree_file='poi_tree_with_uuids.json',\n",
    "        users_file='user_preferences.csv' \n",
    "    )\n",
    "    \n",
    "    interactions_df = generator.generate_interactions(\n",
    "        min_interactions_per_user=5,\n",
    "        max_interactions_per_user=20,\n",
    "        days_back=90\n",
    "    )\n",
    "    \n",
    "    # Save to CSV\n",
    "    # Full version with metadata\n",
    "    interactions_df.to_csv('user_poi_interactions_full.csv', index=False)\n",
    "    print(\"\\nSaved full interactions to: user_poi_interactions_full.csv\")\n",
    "    \n",
    "    # Minimal version (just the essential columns)\n",
    "    interactions_minimal = interactions_df[['user_id', 'poi_id', 'interaction_type', 'value', 'timestamp']]\n",
    "    interactions_minimal.to_csv('user_poi_interactions.csv', index=False)\n",
    "    print(\"Saved minimal interactions to: user_poi_interactions.csv\")\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    generator.generate_summary_stats(interactions_df)\n",
    "    \n",
    "    # Show sample interactions\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"SAMPLE INTERACTIONS (first 10)\")\n",
    "    print(\"=\"*60)\n",
    "    print(interactions_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
