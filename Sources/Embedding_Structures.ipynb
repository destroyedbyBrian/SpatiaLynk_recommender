{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4cf2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da76cda",
   "metadata": {},
   "source": [
    "## user_embeddings.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3902f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "USER EMBEDDINGS STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['user_embeddings', 'poi_embeddings']\n",
      "\n",
      "user_embeddings:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['966592ed-5bfd-4113-9c4d-d93cd3637b40', '6fea97cb-757c-47f2-9e34-3ccbb6714c80', '91d45a60-1f23-45f2-a343-a51017f818d9', '4fbee9f0-804a-4e5d-834e-553670746410', 'ed4d4ddf-8829-49c2-b540-b0c8aa36dfcf', '6b60d5cf-63cc-4dc4-9bbe-74da03df19db', '13e7ba11-c5a9-4f73-86d2-0f2c058891c7', 'af0e718d-4cca-4308-a72e-221b3f2fbe9e', '11069943-47a6-46e4-87ca-fa7d38142abc', '84273d4e-1e2c-4baf-8f0d-7b4f2ef833d0']\n",
      "  Length: 21\n",
      "\n",
      "poi_embeddings:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: []\n",
      "  Length: 0\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/user_embeddings.pkl', 'rb') as f:\n",
    "    user_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"USER EMBEDDINGS STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(user_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(user_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in user_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c434e12e",
   "metadata": {},
   "source": [
    "## poi_embeddings.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d30fa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POI EMBEDDINGS STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['poi_embeddings', 'encoders', 'poi_tree', 'metadata', 'poi_id_to_idx', 'feature_names']\n",
      "\n",
      "poi_embeddings:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "encoders:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: [0, 'user_interests_encoder', 'user_age_encoder', 'user_price_encoder', 1, 2, 3]\n",
      "  Length: 7\n",
      "\n",
      "poi_tree:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "metadata:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['levels', 'n_users', 'n_interactions', 'created_at', 'embedding_dimensions']\n",
      "  Length: 5\n",
      "\n",
      "poi_id_to_idx:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "feature_names:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MultiLabelBinarizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Windows\\Temp\\ipykernel_14180\\2408943392.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  poi_data = pickle.load(f)\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "c:\\Users\\brian\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator TfidfVectorizer from version 1.0.2 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/poi_embeddings.pkl', 'rb') as f:\n",
    "    poi_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POI EMBEDDINGS STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(poi_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(poi_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in poi_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f62139a",
   "metadata": {},
   "source": [
    "## feature_checkin_matrices.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c249fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FEATURE CHECKIN MATRICES STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['S_matrices', 'P_components', 'Q_components', 'dimension_info', 'metadata']\n",
      "\n",
      "S_matrices:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "P_components:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "Q_components:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "dimension_info:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "metadata:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['formula', 'P_l_formula', 'Q_l_formula', 'X_A_dims', 'X_T_dims', 'user_embedding_dims', 'created_at', 'levels']\n",
      "  Length: 8\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/feature_checkin_matrices.pkl', 'rb') as f:\n",
    "    feature_checkin = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"FEATURE CHECKIN MATRICES STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(feature_checkin)}\")\n",
    "print(f\"\\nTop-level keys: {list(feature_checkin.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in feature_checkin.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceae9d5",
   "metadata": {},
   "source": [
    "## interactions.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb3c898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INTERACTIONS STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['interactions', 'negative_samples', 'dimensions', 'info']\n",
      "\n",
      "interactions:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "negative_samples:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "dimensions:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "info:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['created_at', 'negative_ratio', 'split_ratios', 'levels', 'level_names']\n",
      "  Length: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_14180\\1233991104.py:2: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  interaction_data = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/interactions.pkl', 'rb') as f:\n",
    "    interaction_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"INTERACTIONS STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(interaction_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(interaction_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in interaction_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b5310",
   "metadata": {},
   "source": [
    "## metadata.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1631d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "META DATA STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['mappings', 'counts', 'user_ids', 'poi_ids', 'level_names', 'info']\n",
      "\n",
      "mappings:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['user', 'poi']\n",
      "  Length: 2\n",
      "\n",
      "counts:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['users', 'pois_level_0', 'pois_level_1', 'pois_level_2', 'pois_level_3', 'pois_total']\n",
      "  Length: 6\n",
      "\n",
      "user_ids:\n",
      "  Type: <class 'list'>\n",
      "  Length: 21\n",
      "  Sample: ['966592ed-5bfd-4113-9c4d-d93cd3637b40', '6fea97cb-757c-47f2-9e34-3ccbb6714c80', '91d45a60-1f23-45f2-a343-a51017f818d9']\n",
      "\n",
      "poi_ids:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: [0, 1, 2, 3]\n",
      "  Length: 4\n",
      "\n",
      "level_names:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: [0, 1, 2, 3]\n",
      "  Length: 4\n",
      "\n",
      "info:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['created_at', 'source_files', 'version']\n",
      "  Length: 3\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/metadata.pkl', 'rb') as f:\n",
    "    meta_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"META DATA STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(meta_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(meta_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in meta_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3974e0",
   "metadata": {},
   "source": [
    "## poi_context_graph.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0a76fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POI CONTEXT GRAPH STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'networkx.classes.multidigraph.MultiDiGraph'>\n",
      "Graph class: MultiDiGraph\n",
      "\n",
      "======================================================================\n",
      "BASIC PROPERTIES\n",
      "======================================================================\n",
      "\n",
      "Directed: True\n",
      "Multi-graph: True\n",
      "Number of nodes: 235\n",
      "Number of edges: 5613\n",
      "\n",
      "======================================================================\n",
      "NODE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Sample nodes (first 5):\n",
      "  90b50920-882b-4df6-a70d-4b9bcf9aa42a\n",
      "  f40189c1-b6b6-453a-ba65-6bc52c8c792c\n",
      "  384a83da-08bc-4ecd-9ffd-ccf66e6149f5\n",
      "  069623a0-c82e-44a7-8a22-197231216fc8\n",
      "  43538592-12b9-4856-b87e-bcb12ee42d11\n",
      "\n",
      "Node attributes:\n",
      "  No node attributes found\n",
      "\n",
      "======================================================================\n",
      "EDGE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Sample edges (first 5):\n",
      "  90b50920-882b-4df6-a70d-4b9bcf... -> 61dafe9b-b16f-49e1-9cd4-389e7c...\n",
      "    Attributes: {'edge_type': 'geospatial', 'weight': 0.4279097667469145}\n",
      "  90b50920-882b-4df6-a70d-4b9bcf... -> 470a61bc-e973-4e18-8031-18d72f...\n",
      "    Attributes: {'edge_type': 'geospatial', 'weight': 0.48927258864638934}\n",
      "  90b50920-882b-4df6-a70d-4b9bcf... -> cf175d95-329e-42ee-adbd-267cae...\n",
      "    Attributes: {'edge_type': 'geospatial', 'weight': 0.37922681145741416}\n",
      "  90b50920-882b-4df6-a70d-4b9bcf... -> ad198034-f994-4c51-98de-ec1bf8...\n",
      "    Attributes: {'edge_type': 'geospatial', 'weight': 0.5206513331560226}\n",
      "  90b50920-882b-4df6-a70d-4b9bcf... -> 176cf445-fc02-4549-aa5a-257283...\n",
      "    Attributes: {'edge_type': 'geospatial', 'weight': 0.3354440844927084}\n",
      "\n",
      "Edge types distribution:\n",
      "  geospatial: 5608 edges\n",
      "    Weight stats: min=0.3333, max=0.9931, mean=0.5097, median=0.4703\n",
      "  co-visit: 4 edges\n",
      "    Weight stats: min=1.0000, max=1.0000, mean=1.0000, median=1.0000\n",
      "  co-search: 1 edges\n",
      "    Weight stats: min=1.0000, max=1.0000, mean=1.0000, median=1.0000\n",
      "\n",
      "======================================================================\n",
      "EDGE ATTRIBUTES\n",
      "======================================================================\n",
      "\n",
      "All edge attributes found: ['edge_type', 'raw_count', 'weight']\n",
      "\n",
      "'edge_type' attribute:\n",
      "  Sample values: ['geospatial', 'geospatial', 'geospatial', 'geospatial', 'geospatial']\n",
      "\n",
      "'raw_count' attribute:\n",
      "  Sample values: [1, 1, 1, 1, 1]\n",
      "\n",
      "'weight' attribute:\n",
      "  Sample values: [0.4279097667469145, 0.48927258864638934, 0.37922681145741416, 0.5206513331560226, 0.3354440844927084]\n",
      "  Stats: min=0.3333, max=1.0000, mean=0.5101\n",
      "\n",
      "======================================================================\n",
      "DEGREE ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "In-degree statistics:\n",
      "  Mean: 23.89\n",
      "  Median: 18\n",
      "  Max: 67\n",
      "  Min: 0\n",
      "\n",
      "Out-degree statistics:\n",
      "  Mean: 23.89\n",
      "  Median: 17\n",
      "  Max: 67\n",
      "  Min: 0\n",
      "\n",
      "Top 5 nodes by in-degree:\n",
      "  d8606059-6e36-451d-bc28-89b3d3024bd6... : 67\n",
      "  ca050f5f-3385-482c-a0ab-91506f9d3b0f... : 65\n",
      "  ca22458b-13f2-432d-8803-e9b81b78a500... : 64\n",
      "  16fdc55c-38ca-4eac-ba7f-38ecabb35560... : 64\n",
      "  5262a3a7-4b74-4d82-9fa5-d41503252888... : 64\n",
      "\n",
      "Top 5 nodes by out-degree:\n",
      "  d8606059-6e36-451d-bc28-89b3d3024bd6... : 67\n",
      "  ca050f5f-3385-482c-a0ab-91506f9d3b0f... : 65\n",
      "  ca22458b-13f2-432d-8803-e9b81b78a500... : 64\n",
      "  16fdc55c-38ca-4eac-ba7f-38ecabb35560... : 64\n",
      "  5262a3a7-4b74-4d82-9fa5-d41503252888... : 64\n",
      "\n",
      "======================================================================\n",
      "CONNECTIVITY ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "Weakly connected components: 15\n",
      "Strongly connected components: 15\n",
      "Largest weakly connected component: 183 nodes (77.9%)\n",
      "\n",
      "======================================================================\n",
      "GRAPH METRICS\n",
      "======================================================================\n",
      "\n",
      "Graph density: 0.102073\n",
      "  (0 = no edges, 1 = complete graph)\n",
      "\n",
      "======================================================================\n",
      "SAMPLE NEIGHBORHOOD\n",
      "======================================================================\n",
      "\n",
      "Node: d8606059-6e36-451d-bc28-89b3d3024bd6\n",
      "Degree: 134\n",
      "\n",
      "Successors (first 5):\n",
      "  -> 5262a3a7-4b74-4d82-9fa5-d41503... | {0: {'edge_type': 'geospatial', 'weight': 0.6926120632469429}}\n",
      "  -> fb2e9ef7-38bc-4429-9a4e-2aa58c... | {0: {'edge_type': 'geospatial', 'weight': 0.3701520752465049}}\n",
      "  -> 61dafe9b-b16f-49e1-9cd4-389e7c... | {0: {'edge_type': 'geospatial', 'weight': 0.3520955891011394}}\n",
      "  -> 470a61bc-e973-4e18-8031-18d72f... | {0: {'edge_type': 'geospatial', 'weight': 0.3340848388928397}}\n",
      "  -> cf175d95-329e-42ee-adbd-267cae... | {0: {'edge_type': 'geospatial', 'weight': 0.3957724589638636}}\n",
      "\n",
      "Predecessors (first 5):\n",
      "  5262a3a7-4b74-4d82-9fa5-d41503... -> | {0: {'edge_type': 'geospatial', 'weight': 0.6926120632469429}}\n",
      "  fb2e9ef7-38bc-4429-9a4e-2aa58c... -> | {0: {'edge_type': 'geospatial', 'weight': 0.3701520752465049}}\n",
      "  61dafe9b-b16f-49e1-9cd4-389e7c... -> | {0: {'edge_type': 'geospatial', 'weight': 0.3520955891011394}}\n",
      "  470a61bc-e973-4e18-8031-18d72f... -> | {0: {'edge_type': 'geospatial', 'weight': 0.3340848388928397}}\n",
      "  cf175d95-329e-42ee-adbd-267cae... -> | {0: {'edge_type': 'geospatial', 'weight': 0.3957724589638636}}\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('./Embeddings/poi_context_graph.pkl', 'rb') as f:\n",
    "    poi_context_graph = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POI CONTEXT GRAPH STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(poi_context_graph)}\")\n",
    "print(f\"Graph class: {poi_context_graph.__class__.__name__}\")\n",
    "\n",
    "# ============================================================================\n",
    "# BASIC GRAPH PROPERTIES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BASIC PROPERTIES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nDirected: {poi_context_graph.is_directed()}\")\n",
    "print(f\"Multi-graph: {poi_context_graph.is_multigraph()}\")\n",
    "print(f\"Number of nodes: {poi_context_graph.number_of_nodes()}\")\n",
    "print(f\"Number of edges: {poi_context_graph.number_of_edges()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# NODE INSPECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NODE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get sample nodes\n",
    "sample_nodes = list(poi_context_graph.nodes())[:5]\n",
    "print(f\"\\nSample nodes (first 5):\")\n",
    "for node in sample_nodes:\n",
    "    print(f\"  {node}\")\n",
    "\n",
    "# Check if nodes have attributes\n",
    "print(f\"\\nNode attributes:\")\n",
    "if poi_context_graph.number_of_nodes() > 0:\n",
    "    sample_node = list(poi_context_graph.nodes())[0]\n",
    "    node_attrs = poi_context_graph.nodes[sample_node]\n",
    "    if node_attrs:\n",
    "        print(f\"  Sample node: {sample_node}\")\n",
    "        print(f\"  Attributes: {dict(node_attrs)}\")\n",
    "    else:\n",
    "        print(f\"  No node attributes found\")\n",
    "\n",
    "# ============================================================================\n",
    "# EDGE INSPECTION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EDGE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get sample edges\n",
    "sample_edges = list(poi_context_graph.edges(data=True))[:5]\n",
    "print(f\"\\nSample edges (first 5):\")\n",
    "for u, v, data in sample_edges:\n",
    "    print(f\"  {u[:30]}... -> {v[:30]}...\")\n",
    "    print(f\"    Attributes: {data}\")\n",
    "\n",
    "# Count edge types\n",
    "edge_types = defaultdict(int)\n",
    "edge_weights = defaultdict(list)\n",
    "\n",
    "for u, v, data in poi_context_graph.edges(data=True):\n",
    "    edge_type = data.get('edge_type', 'unknown')\n",
    "    edge_types[edge_type] += 1\n",
    "    \n",
    "    if 'weight' in data:\n",
    "        edge_weights[edge_type].append(data['weight'])\n",
    "\n",
    "print(f\"\\nEdge types distribution:\")\n",
    "for edge_type, count in sorted(edge_types.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {edge_type}: {count} edges\")\n",
    "    \n",
    "    if edge_type in edge_weights and edge_weights[edge_type]:\n",
    "        weights = edge_weights[edge_type]\n",
    "        print(f\"    Weight stats: min={min(weights):.4f}, max={max(weights):.4f}, \"\n",
    "              f\"mean={np.mean(weights):.4f}, median={np.median(weights):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# EDGE ATTRIBUTES\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EDGE ATTRIBUTES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get all unique edge attributes\n",
    "all_edge_attrs = set()\n",
    "for u, v, data in poi_context_graph.edges(data=True):\n",
    "    all_edge_attrs.update(data.keys())\n",
    "\n",
    "print(f\"\\nAll edge attributes found: {sorted(all_edge_attrs)}\")\n",
    "\n",
    "# Show examples for each attribute\n",
    "for attr in sorted(all_edge_attrs):\n",
    "    print(f\"\\n'{attr}' attribute:\")\n",
    "    sample_values = []\n",
    "    for u, v, data in poi_context_graph.edges(data=True):\n",
    "        if attr in data:\n",
    "            sample_values.append(data[attr])\n",
    "        if len(sample_values) >= 5:\n",
    "            break\n",
    "    \n",
    "    print(f\"  Sample values: {sample_values}\")\n",
    "    \n",
    "    if attr == 'weight':\n",
    "        all_weights = [data[attr] for u, v, data in poi_context_graph.edges(data=True) if attr in data]\n",
    "        print(f\"  Stats: min={min(all_weights):.4f}, max={max(all_weights):.4f}, mean={np.mean(all_weights):.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DEGREE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DEGREE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# In-degree and out-degree\n",
    "in_degrees = dict(poi_context_graph.in_degree())\n",
    "out_degrees = dict(poi_context_graph.out_degree())\n",
    "\n",
    "print(f\"\\nIn-degree statistics:\")\n",
    "in_deg_values = list(in_degrees.values())\n",
    "print(f\"  Mean: {np.mean(in_deg_values):.2f}\")\n",
    "print(f\"  Median: {np.median(in_deg_values):.0f}\")\n",
    "print(f\"  Max: {max(in_deg_values)}\")\n",
    "print(f\"  Min: {min(in_deg_values)}\")\n",
    "\n",
    "print(f\"\\nOut-degree statistics:\")\n",
    "out_deg_values = list(out_degrees.values())\n",
    "print(f\"  Mean: {np.mean(out_deg_values):.2f}\")\n",
    "print(f\"  Median: {np.median(out_deg_values):.0f}\")\n",
    "print(f\"  Max: {max(out_deg_values)}\")\n",
    "print(f\"  Min: {min(out_deg_values)}\")\n",
    "\n",
    "# Top nodes by degree\n",
    "print(f\"\\nTop 5 nodes by in-degree:\")\n",
    "top_in = sorted(in_degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for node, degree in top_in:\n",
    "    print(f\"  {node[:40]}... : {degree}\")\n",
    "\n",
    "print(f\"\\nTop 5 nodes by out-degree:\")\n",
    "top_out = sorted(out_degrees.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "for node, degree in top_out:\n",
    "    print(f\"  {node[:40]}... : {degree}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONNECTIVITY ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONNECTIVITY ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if poi_context_graph.is_directed():\n",
    "    num_weakly = nx.number_weakly_connected_components(poi_context_graph)\n",
    "    num_strongly = nx.number_strongly_connected_components(poi_context_graph)\n",
    "    print(f\"\\nWeakly connected components: {num_weakly}\")\n",
    "    print(f\"Strongly connected components: {num_strongly}\")\n",
    "    \n",
    "    # Get largest component\n",
    "    largest_wcc = max(nx.weakly_connected_components(poi_context_graph), key=len)\n",
    "    print(f\"Largest weakly connected component: {len(largest_wcc)} nodes \"\n",
    "          f\"({len(largest_wcc)/poi_context_graph.number_of_nodes()*100:.1f}%)\")\n",
    "else:\n",
    "    num_components = nx.number_connected_components(poi_context_graph)\n",
    "    print(f\"\\nConnected components: {num_components}\")\n",
    "\n",
    "# ============================================================================\n",
    "# GRAPH DENSITY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GRAPH METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "density = nx.density(poi_context_graph)\n",
    "print(f\"\\nGraph density: {density:.6f}\")\n",
    "print(f\"  (0 = no edges, 1 = complete graph)\")\n",
    "\n",
    "# ============================================================================\n",
    "# SAMPLE NEIGHBORHOOD\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAMPLE NEIGHBORHOOD\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Pick a high-degree node\n",
    "high_degree_node = max(poi_context_graph.degree(), key=lambda x: x[1])[0]\n",
    "print(f\"\\nNode: {high_degree_node}\")\n",
    "print(f\"Degree: {poi_context_graph.degree(high_degree_node)}\")\n",
    "\n",
    "# Get successors (outgoing edges)\n",
    "successors = list(poi_context_graph.successors(high_degree_node))[:5]\n",
    "print(f\"\\nSuccessors (first 5):\")\n",
    "for successor in successors:\n",
    "    edge_data = poi_context_graph[high_degree_node][successor]\n",
    "    \n",
    "    # Handle MultiDiGraph (may have multiple edges)\n",
    "    if isinstance(edge_data, dict):\n",
    "        for key, data in edge_data.items():\n",
    "            print(f\"  -> {successor[:30]}... | {data.get('edge_type', 'unknown')} \"\n",
    "                f\"(weight: {data.get('weight', 'N/A')})\")\n",
    "    else:\n",
    "        print(f\"  -> {successor[:30]}... | {edge_data}\")\n",
    "\n",
    "# Get predecessors (incoming edges)\n",
    "predecessors = list(poi_context_graph.predecessors(high_degree_node))[:5]\n",
    "print(f\"\\nPredecessors (first 5):\")\n",
    "for predecessor in predecessors:\n",
    "    edge_data = poi_context_graph[predecessor][high_degree_node]\n",
    "    \n",
    "    if isinstance(edge_data, dict):\n",
    "        for key, data in edge_data.items():\n",
    "            print(f\"  {predecessor[:30]}... -> | {data.get('edge_type', 'unknown')} \"\n",
    "                f\"(weight: {data.get('weight', 'N/A')})\")\n",
    "    else:\n",
    "        print(f\"  {predecessor[:30]}... -> | {edge_data}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97587399",
   "metadata": {},
   "source": [
    "## poi_interlevel_features.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68ca1fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "POI INTER-LEVEL FEATURES STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['A_lp', 'Q_l', 'attention_weights', 'aggregator_weights', 'aggregator_config', 'dimensions', 'info']\n",
      "\n",
      "A_lp:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "Q_l:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "attention_weights:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "aggregator_weights:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: [1, 2, 3]\n",
      "  Length: 3\n",
      "\n",
      "aggregator_config:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['hidden_dim', 'dropout_rate']\n",
      "  Length: 2\n",
      "\n",
      "dimensions:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "info:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['created_at', 'formula', 'aggregation', 'hidden_dim', 'framework', 'tf_version']\n",
      "  Length: 6\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/poi_interlevel_features.pkl', 'rb') as f:\n",
    "    poi_interlevel_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"POI INTER-LEVEL FEATURES STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(poi_interlevel_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(poi_interlevel_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in poi_interlevel_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdbaa1",
   "metadata": {},
   "source": [
    "## user_personalized_preferences.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918cc6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "USER PERSONALISED PREFERENCES STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['A_lu', 'P_l', 'dimensions', 'info']\n",
      "\n",
      "A_lu:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "P_l:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "dimensions:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "info:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['created_at', 'aggregation_method', 'components']\n",
      "  Length: 3\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/user_personalized_preferences.pkl', 'rb') as f:\n",
    "    user_personalised_preferences = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"USER PERSONALISED PREFERENCES STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(user_personalised_preferences)}\")\n",
    "print(f\"\\nTop-level keys: {list(user_personalised_preferences.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in user_personalised_preferences.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c011de",
   "metadata": {},
   "source": [
    "## historical_checkin_matrices.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d18efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HISTORICAL CHECKIN MATRICES STRUCTURE INSPECTION\n",
      "======================================================================\n",
      "\n",
      "Type: <class 'dict'>\n",
      "\n",
      "Top-level keys: ['H_matrices', 'U_matrices', 'G_matrices', 'base_matrices', 'poi_ids', 'user_ids', 'metadata']\n",
      "\n",
      "H_matrices:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "U_matrices:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "G_matrices:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "base_matrices:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "poi_ids:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['level_0', 'level_1', 'level_2', 'level_3']\n",
      "  Length: 4\n",
      "\n",
      "user_ids:\n",
      "  Type: <class 'list'>\n",
      "  Length: 21\n",
      "  Sample: ['966592ed-5bfd-4113-9c4d-d93cd3637b40', '6fea97cb-757c-47f2-9e34-3ccbb6714c80', '91d45a60-1f23-45f2-a343-a51017f818d9']\n",
      "\n",
      "metadata:\n",
      "  Type: <class 'dict'>\n",
      "  Keys: ['formula', 'U_l_components', 'G_l_components', 'created_at']\n",
      "  Length: 4\n"
     ]
    }
   ],
   "source": [
    "with open('./Embeddings/historical_checkin_matrices.pkl', 'rb') as f:\n",
    "    historical_checkin_data = pickle.load(f)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"HISTORICAL CHECKIN MATRICES STRUCTURE INSPECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nType: {type(historical_checkin_data)}\")\n",
    "print(f\"\\nTop-level keys: {list(historical_checkin_data.keys())}\")\n",
    "\n",
    "# Show structure of each key\n",
    "for key, value in historical_checkin_data.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  Type: {type(value)}\")\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"  Keys: {list(value.keys())[:10]}\")  # First 10 keys\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "    elif isinstance(value, list):\n",
    "        print(f\"  Length: {len(value)}\")\n",
    "        print(f\"  Sample: {value[:3]}\")\n",
    "    else:\n",
    "        print(f\"  Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7bd7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
